{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouxbm40nx9cX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import csv\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZUrHp7UPz4f"
      },
      "source": [
        "# MPPI-generated dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2zT2XJCClON",
        "outputId": "694f90bc-a675-4d12-dcb2-b023425ca9c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18141\n",
            "12\n",
            "3\n",
            "[5.777871131896973, 5.185089111328125, 0.07156264781951904, -2.3166010123532033e-06, -4.786302270076703e-06, 1.2341823094175197e-05, 5.419728755950928, 4.25071907043457, -0.0075306277722120285, 0.18873652815818787, -0.25466179847717285, -0.0004365821660030633]\n",
            "[0.6062203049659729, 0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "# Data processing with limit filters\n",
        "filename_input = '/content/states_from_mppi.csv'\n",
        "\n",
        "input = []\n",
        "with open(filename_input, mode='r', newline='') as file:\n",
        "    reader = csv.reader(file)\n",
        "    headers = next(reader)\n",
        "    for row in reader:\n",
        "        input.append([float(r) for r in row])\n",
        "inputs = [input[i][4:-3] for i in range(len(input))]\n",
        "quality = [input[i][-3:] for i in range(len(input))]\n",
        "print(len(inputs))\n",
        "print(len(inputs[0]))\n",
        "print(len(quality[0]))\n",
        "print(inputs[0])\n",
        "print(quality[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR62JbxVXM6Y",
        "outputId": "5684c3d9-7360-47db-b25b-a65fc6aeeba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18141\n",
            "5.921210886591475e-06\n"
          ]
        }
      ],
      "source": [
        "# Data processing with limit filters\n",
        "filename_input = '/content/ao_est.csv'\n",
        "label = []\n",
        "with open(filename_input, mode='r', newline='') as file:\n",
        "    reader = csv.reader(file)\n",
        "    headers = next(reader)\n",
        "    for row in reader:\n",
        "        label.append([float(r) for r in row])\n",
        "\n",
        "success_labels = [label[i][-2] for i in range(len(label))]\n",
        "maneuver_labels = [label[i][-1] for i in range(len(label))]\n",
        "print(len(success_labels))\n",
        "print(success_labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMirfj4QG3hj",
        "outputId": "a5234a43-3806-4c66-f22e-93305ccce2e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[347.8937072753906, 311.1250915527344, 297.3718566894531, 281.4647216796875, 279.0978088378906, 252.55519104003906, 195.56863403320312, 188.1468505859375, 181.9153594970703, 166.5492401123047, 150.75465393066406, 139.209716796875, 138.70654296875, 134.4258270263672, 132.79295349121094, 124.02455139160156, 123.90391540527344, 116.97223663330078, 89.43507385253906, 80.06819915771484, 63.33731460571289, 62.67109298706055, 59.50260543823242, 56.250267028808594, 46.282772064208984, 43.65011215209961, 41.3482780456543, 32.07596206665039, 30.884151458740234, 30.846742630004883, 29.599044799804688, 27.236591339111328, 25.180545806884766, 24.496471405029297, 19.496564865112305, 19.354162216186523, 19.217042922973633, 19.13922119140625, 19.04962730407715, 18.92469596862793, 18.726829528808594, 18.566875457763672, 18.511306762695312, 17.984643936157227, 16.134342193603516, 15.66304874420166, 15.278175354003906, 15.143542289733887, 15.128437995910645, 15.083898544311523, 15.052336692810059, 13.684684753417969, 13.469538688659668, 12.000130653381348, 11.594366073608398, 11.484781265258789, 11.098546028137207, 10.371733665466309, 9.88942813873291, 9.803400039672852, 9.385005950927734, 9.046344757080078, 8.49950885772705, 8.42866039276123, 8.181498527526855, 8.122710227966309, 7.970349311828613, 7.833683490753174, 7.826498985290527, 7.689995288848877, 7.591825485229492, 7.489893436431885, 7.394394397735596, 7.268177032470703, 7.183539867401123, 6.903169631958008, 6.849684238433838, 6.795381546020508, 6.711065769195557, 6.704437732696533, 6.699197292327881, 6.6506547927856445, 6.625067710876465, 6.469492435455322, 6.362700462341309, 6.3411173820495605, 6.339478015899658, 6.297800540924072, 5.977828025817871, 5.551236629486084, 5.335783004760742, 5.2049641609191895, 5.117477893829346, 5.070716857910156, 5.037686347961426, 5.001862049102783, 4.819858551025391, 4.743152618408203, 4.566308975219727, 4.4578399658203125]\n",
            "0.0\n",
            "0.3621155107287078\n"
          ]
        }
      ],
      "source": [
        "import heapq\n",
        "import numpy as np\n",
        "\n",
        "xo = [q[1] for q in quality]\n",
        "ten_largest_values = heapq.nlargest(100, xo)\n",
        "print(ten_largest_values)\n",
        "print(np.median(xo))\n",
        "print(np.mean(xo))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "J6Zw-HqRHE69",
        "outputId": "c1727780-0f18-4a17-9dc8-4e2ecd558b85"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFAElEQVR4nO3de3zP9f//8ft7Ywc7mpmRYSGHkI+JlvOh5lRE5BMZrXQYJalPPpVDlBApRCdD6ZNUOpDDQihymGMOc27C5hCbTWaH1+8P371+3jZss+29ed2ul8v7Uu/n6/l+vh/v1+u97e71er5eL5thGIYAAAAszMnRBQAAADgagQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgFolq1aurfv7+jy7jlTZw4UbfffrucnZ3VsGHDmxrryJEjstlsmj17doHUdqubPXu2bDabNm/e7OhSYGFZ38MjR444upRbDoEI2dzoF3/r1q1Vr169m36fn376SaNGjbrpcaxi+fLlevnll9WsWTNFRUXprbfeumbf/v37y2az5fhYunRpkdW8e/dujRo1Kte/vEeNGiWbzaYKFSrowoUL2ZZXq1ZNXbp0KeAqby1Xb/tSpUopKChIvXv31u7du/M15oULFzRq1Cj98ssvBVtsMXPs2DH16tVLvr6+8vb2VteuXXXo0CFHl5UvWb/Hc3rEx8c7urxiqZSjC8CtITY2Vk5OecvXP/30k6ZPn04oyqWVK1fKyclJn376qVxcXG7Y39XVVZ988km29rvuuqswysvR7t27NXr0aLVu3VrVqlXL9etOnjypGTNm6MUXXyy84m5hV2779PR0HTx4UDNnztTSpUu1e/duVapUKU/jXbhwQaNHj5Z0+R9Et6Lk5GS1adNGiYmJ+u9//6vSpUvr3XffVatWrbRt2zaVK1fO0SXmyxtvvKHg4GC7Nl9fX8cUU8wRiFAgXF1dHV1CnqWkpMjDw8PRZeTayZMn5e7unqswJEmlSpVS3759C7mqwtGwYUNNnDhRzz77rNzd3R1dTpEqiO9lTtv+nnvuUZcuXbR48WI9+eSTNzX+reiDDz7Q/v37tXHjRt19992SpI4dO6pevXqaNGnSdffIFmcdO3ZU48aNHV1GicAhMxSIq+cQpaWlafTo0apZs6bc3NxUrlw5NW/eXNHR0ZIu79afPn26JNntys2SkpKiF198UUFBQXJ1dVWtWrX0zjvvyDAMu/f9559/9Nxzz8nf319eXl568MEHdezYMdlsNrs9T1mHYnbv3q1HH31UZcuWVfPmzSVJO3bsUP/+/XX77bfLzc1NgYGBevzxx3XmzBm798oaY9++ferbt698fHxUvnx5vf766zIMQ0ePHlXXrl3l7e2twMBATZo0KVfrLj09XWPGjFH16tXl6uqqatWq6b///a9SU1PNPjabTVFRUUpJSTHXVWHN/Vm5cqVatGghDw8P+fr6qmvXrtqzZ49dnz///FPPPvusatWqJXd3d5UrV049e/a0OzQ2e/Zs9ezZU5LUpk0bs+7cHHYZMWKEEhISNGPGjOv2++WXX3IcM6f5Uf3795enp6fi4uLUpUsXeXp66rbbbjO/hzt37lTbtm3l4eGhqlWr6osvvsjxPS9cuKCnnnpK5cqVk7e3t/r166ezZ89m67dkyRJzPXp5ealz587atWuXXZ+smg4ePKhOnTrJy8tLffr0kSTt379fPXr0UGBgoNzc3FS5cmX17t1biYmJN1p9OQoMDJR0OSxd6dy5cxoyZIj5s1ajRg2NHz9emZmZ5rosX768JGn06NHmdhw1apR++OEH2Ww27dixwxzvm2++kc1mU/fu3e3ep06dOnrkkUfs2j7//HOFhITI3d1dfn5+6t27t44ePZqt9g0bNqhDhw7y8fFRmTJl1KpVK/322292fbJ+Pg8cOKD+/fvL19dXPj4+GjBgQI6HX6/29ddf6+677zbDkCTVrl1b7dq101dffXXD10dFRalt27YKCAiQq6ur6tatm+P3N+uw76+//qomTZrIzc1Nt99+u+bOnZut765du9S2bVu5u7urcuXKGjt2rLld8uL8+fPKyMjI8+ushj1EuKbExESdPn06W3taWtoNXztq1CiNGzdOTzzxhJo0aaKkpCRt3rxZW7Zs0X333aennnpKx48fV3R0tD777DO71xqGoQcffFCrVq1SRESEGjZsqGXLlumll17SsWPH9O6775p9+/fvr6+++kqPPfaY7rnnHq1evVqdO3e+Zl09e/ZUzZo19dZbb5nhKjo6WocOHdKAAQMUGBioXbt26aOPPtKuXbv0+++/2wU1SXrkkUdUp04dvf3221q8eLHGjh0rPz8/ffjhh2rbtq3Gjx+vefPmadiwYbr77rvVsmXL666rJ554QnPmzNHDDz+sF198URs2bNC4ceO0Z88eLVy4UJL02Wef6aOPPtLGjRvNQyH33nvvDbfD1duvdOnS8vHxuWb/n3/+WR07dtTtt9+uUaNG6Z9//tHUqVPVrFkzbdmyxTzstWnTJq1bt069e/dW5cqVdeTIEc2YMUOtW7fW7t27VaZMGbVs2VLPPfec3n//ff33v/9VnTp1JMn87/W0aNFCbdu21YQJE/TMM88U2F6ijIwMdezYUS1bttSECRM0b948DRo0SB4eHnr11VfVp08fde/eXTNnzlS/fv0UGhqa7XDDoEGD5Ovrq1GjRik2NlYzZszQn3/+aYYz6fL2Cg8PV1hYmMaPH68LFy5oxowZat68ubZu3Wp3+DA9PV1hYWFq3ry53nnnHZUpU0aXLl1SWFiYUlNTNXjwYAUGBurYsWNatGiRzp07d91tmCVr22dkZOjQoUP6z3/+o3LlytnNwbpw4YJatWqlY8eO6amnnlKVKlW0bt06DR8+XCdOnNCUKVNUvnx5zZgxQ88884weeughM+g0aNBAlStXls1m05o1a9SgQQNJ0tq1a+Xk5KRff/3VfJ9Tp05p7969GjRokNn25ptv6vXXX1evXr30xBNP6NSpU5o6dapatmyprVu3mod1Vq5cqY4dOyokJEQjR46Uk5OTGT7Wrl2rJk2a2H3uXr16KTg4WOPGjdOWLVv0ySefKCAgQOPHj7/musrMzNSOHTv0+OOPZ1vWpEkTLV++XOfPn5eXl9c1x5gxY4buvPNOPfjggypVqpR+/PFHPfvss8rMzFRkZKRd3wMHDujhhx9WRESEwsPDNWvWLPXv318hISG68847JUnx8fFq06aN0tPT9corr8jDw0MfffRRnn8W2rRpo+TkZLm4uCgsLEyTJk1SzZo18zSGZRjAVaKiogxJ133ceeeddq+pWrWqER4ebj6/6667jM6dO1/3fSIjI42cvoLfffedIckYO3asXfvDDz9s2Gw248CBA4ZhGEZMTIwhyRgyZIhdv/79+xuSjJEjR5ptI0eONCQZ//73v7O934ULF7K1/e9//zMkGWvWrMk2xsCBA8229PR0o3LlyobNZjPefvtts/3s2bOGu7u73TrJybZt2wxJxhNPPGHXPmzYMEOSsXLlSrMtPDzc8PDwuO54V/bNabu1atXK7HP48GFDkhEVFWW2NWzY0AgICDDOnDljtm3fvt1wcnIy+vXrZ7bltM7Wr19vSDLmzp1rti1YsMCQZKxatSpXdWet41OnThmrV682JBmTJ082l1etWtXue7Vq1aocx8/ps2Wtk7feestsy9pONpvN+PLLL832vXv3ZvsOZf1chISEGJcuXTLbJ0yYYEgyvv/+e8MwDOP8+fOGr6+v8eSTT9rVFB8fb/j4+Ni1Z9X0yiuv2PXdunWrIclYsGBBLtaavWtt+9tuu82IiYmx6ztmzBjDw8PD2Ldvn137K6+8Yjg7OxtxcXGGYRjGqVOnsq2PLHfeeafRq1cv83mjRo2Mnj17GpKMPXv2GIZhGN9++60hydi+fbthGIZx5MgRw9nZ2XjzzTftxtq5c6dRqlQpsz0zM9OoWbOmERYWZmRmZpr9Lly4YAQHBxv33Xef2Zb13Xn88cftxnzooYeMcuXKXXedZX2+N954I9uy6dOnG5KMvXv3XneMnH4mwsLCjNtvv92urWrVqtl+t5w8edJwdXU1XnzxRbNtyJAhhiRjw4YNdv18fHwMScbhw4evW8/8+fON/v37G3PmzDEWLlxovPbaa0aZMmUMf39/c7vCHofMcE3Tp09XdHR0tkfWvwSvx9fXV7t27dL+/fvz/L4//fSTnJ2d9dxzz9m1v/jiizIMQ0uWLJEk82ypZ5991q7f4MGDrzn2008/na3tyn9xXbx4UadPn9Y999wjSdqyZUu2/k888YT5/87OzmrcuLEMw1BERITZ7uvrq1q1at3wDJWffvpJkjR06FC79qzJxIsXL77u66/Hzc0t27a73mG8EydOaNu2berfv7/8/PzM9gYNGui+++4za5Xs11laWprOnDmjGjVqyNfXN8d1lh8tW7ZUmzZtNGHCBP3zzz8FMqZkv/2ytpOHh4d69epltteqVUu+vr45br+BAweqdOnS5vNnnnlGpUqVMtdPdHS0zp07p3//+986ffq0+XB2dlbTpk21atWqbGM+88wzds+z9gAtW7YsV4d7rnbltl+2bJk+/PBDeXp6qlOnTtq3b5/Zb8GCBWrRooXKli1rV2v79u2VkZGhNWvW3PC9WrRoobVr10q6fGhm+/btGjhwoPz9/c32tWvXytfX1zw79dtvv1VmZqZ69epl976BgYGqWbOmuY62bdum/fv369FHH9WZM2fMfikpKWrXrp3WrFmT7RDS1T/jLVq00JkzZ5SUlHTNz5D1/cppLqSbm5tdn2u58mcia+96q1atdOjQoWyHOevWrasWLVqYz8uXL5/t98VPP/2ke+65x24PWPny5c1DqjfSq1cvRUVFqV+/furWrZvGjBmjZcuW6cyZM3rzzTdzNYbVcMgM19SkSZMcJ+Nl/fK8njfeeENdu3bVHXfcoXr16qlDhw567LHHchWm/vzzT1WqVCnb7umsQy1//vmn+V8nJ6dshzRq1KhxzbGv7itJf//9t0aPHq0vv/xSJ0+etFuW03yNKlWq2D338fGRm5ub/P39s7VfPQ/palmf4eqaAwMD5evra37W/HB2dlb79u1z3T/rvWrVqpVtWZ06dbRs2TJzwu8///yjcePGKSoqSseOHbOb25XfOS45GTVqlFq1aqWZM2fqhRdeuOnx3NzczPkwWXx8fMxDP1e35zQ36OrDDZ6enqpYsaI5fyrrHwFt27bNsQZvb2+756VKlVLlypXt2oKDgzV06FBNnjxZ8+bNU4sWLfTggw+ac9duJKdt36lTJ9WsWVPDhw/XN998Y9a6Y8eObOsky9U/Dzlp0aKFZs6cqQMHDujgwYOy2WwKDQ01g9KTTz6ptWvXqlmzZuaZqPv375dhGNc8dJMVOLPWZXh4+DXfPzExUWXLljWfX/3zmbXs7Nmz2dZ9lqwwc+W8vSwXL16063Mtv/32m0aOHKn169dnC7GJiYl22+3qGrPqvPL79ueff6pp06bZ+uX085lbzZs3V9OmTfXzzz/ne4xbGYEIhaJly5Y6ePCgvv/+ey1fvlyffPKJ3n33Xc2cOdPuX+hFLadfar169dK6dev00ksvqWHDhvL09FRmZqY6dOiQ4wRGZ2fnXLVJyjYJ/Fqu/mNc3A0ePFhRUVEaMmSIQkND5ePjI5vNpt69e+dr0ue1tGzZUq1bt9aECRNy3Lt3rfV2rQmk19pON7v9rpT1+T/77DNzIvOVrp7U7OrqmuMlKyZNmqT+/fubP0PPPfecxo0bp99//z1bgMqNypUrq1atWnZ7fTIzM3Xffffp5ZdfzvE1d9xxxw3HzTo5Yc2aNTp06JAaNWokDw8PtWjRQu+//76Sk5O1detWu70SmZmZstlsWrJkSY7r3tPT0+wnXb4g6bUuRJrVN0t+tqWfn59cXV114sSJbMuy2q53qYKDBw+qXbt2ql27tiZPnqygoCC5uLjop59+0rvvvpvtZ6Igv295FRQUpNjY2EJ/n5KIQIRC4+fnpwEDBmjAgAFKTk5Wy5YtNWrUKDMQXeuPWdWqVfXzzz9nm8S4d+9ec3nWfzMzM3X48GG7f2keOHAg1zWePXtWK1as0OjRozVixAizPT+H+vIj6zPs37/fbrJxQkKCzp07Z37WoqpFUo6/LPfu3St/f3/zdPCvv/5a4eHhdofgLl68qHPnztm9riCC3qhRo9S6dWt9+OGH2ZZl/ev/6ve9mT1rN7J//361adPGfJ6cnKwTJ06oU6dOkqTq1atLkgICAvK0hy4n9evXV/369fXaa69p3bp1atasmWbOnKmxY8fma7z09HQlJyebz6tXr67k5OQb1nm97VilShVVqVJFa9eu1aFDh8xDQS1bttTQoUO1YMECZWRk2J1cUL16dRmGoeDg4OuGrqx16e3tfdPr8nqcnJxUv379HC9Gu2HDBt1+++3XnVD9448/KjU1VT/88IPd3p+cDo/mVtWqVXP8PXSzYebQoUPX3CNodcwhQqG4+lCRp6enatSoYbdLOuuP69V/zDp16qSMjAxNmzbNrv3dd9+VzWZTx44dJUlhYWGSLl8/5EpTp07NdZ1Z/1K7+l9mU6ZMyfUYNyPrj+jV7zd58mRJuu4ZcwWtYsWKatiwoebMmWO3Tf744w8tX77crFW6vN6uXmdTp07NtmfmWts4L1q1aqXWrVtr/Pjx5uGLLFWrVpWzs3O2uS5XfycK0kcffWR3puWMGTOUnp5u97309vbWW2+9leMZmadOnbrheyQlJSk9Pd2urX79+nJycsrxsE5u7Nu3T7GxsXYX5uzVq5fWr1+vZcuWZet/7tw5s4YyZcqYbTlp0aKFVq5cqY0bN5qBqGHDhvLy8tLbb78td3d3hYSEmP27d+8uZ2dnjR49Otv3yDAM8/dHSEiIqlevrnfeeccuyGXJzbrMrYcfflibNm2yC0WxsbFauXKlefmIa8np90hiYqKioqLyXU+nTp30+++/a+PGjWbbqVOnNG/evFy9Pqd189NPPykmJkYdOnTId123MvYQoVDUrVtXrVu3VkhIiPz8/LR582Z9/fXXdqfdZv2CfO655xQWFiZnZ2f17t1bDzzwgNq0aaNXX31VR44c0V133aXly5fr+++/15AhQ8x/NYaEhKhHjx6aMmWKzpw5Y552nzVpNDd7J7y9vc1TsNPS0nTbbbdp+fLlOnz4cCGslezuuusuhYeH66OPPtK5c+fUqlUrbdy4UXPmzFG3bt3s9kQUhYkTJ6pjx44KDQ1VRESEedq9j4+P3XWdunTpos8++0w+Pj6qW7eu1q9fr59//jnb1XwbNmwoZ2dnjR8/XomJiXJ1dTWv1ZIXI0eOzHFd+Pj4qGfPnpo6dapsNpuqV6+uRYsW5WruS35dunRJ7dq1U69evRQbG6sPPvhAzZs314MPPijp8ndqxowZeuyxx9SoUSP17t1b5cuXV1xcnBYvXqxmzZplC/tXW7lypQYNGqSePXvqjjvuUHp6uj777DM5OzurR48eN6wxPT1dn3/+uaTLh52OHDmimTNnKjMzUyNHjjT7vfTSS/rhhx/UpUsX87TvlJQU7dy5U19//bWOHDkif39/ubu7q27dupo/f77uuOMO+fn5qV69euYk6RYtWmjevHmy2WzmITRnZ2fde++9WrZsmVq3bm13QdHq1atr7NixGj58uI4cOaJu3brJy8tLhw8f1sKFCzVw4EANGzZMTk5O+uSTT9SxY0fdeeedGjBggG677TYdO3ZMq1atkre3t3788ce8bcBrePbZZ/Xxxx+rc+fOGjZsmEqXLq3JkyerQoUKN7xi+v333y8XFxc98MADeuqpp5ScnKyPP/5YAQEBOR6Gy42XX35Zn332mTp06KDnn3/ePO2+atWqdtd9upZ7771X//rXv9S4cWP5+Phoy5YtmjVrloKCgvTf//43XzXd8hxxahuKt6zTizdt2pTj8latWt3wtPuxY8caTZo0MXx9fQ13d3ejdu3axptvvml3unJ6eroxePBgo3z58obNZrM7Bf/8+fPGCy+8YFSqVMkoXbq0UbNmTWPixIl2p94ahmGkpKQYkZGRhp+fn+Hp6Wl069bNiI2NNSTZnQZ/5encV/vrr7+Mhx56yPD19TV8fHyMnj17GsePH7/mqftXj3Gt0+FzWk85SUtLM0aPHm0EBwcbpUuXNoKCgozhw4cbFy9ezNX75CQ3fXM6Nd0wDOPnn382mjVrZri7uxve3t7GAw88YOzevduuz9mzZ40BAwYY/v7+hqenpxEWFmbs3bs32/fAMAzj448/Nm6//XbD2dn5hqfgX287tWrVypCU7XIOp06dMnr06GGUKVPGKFu2rPHUU08Zf/zxR46n3edlO119in/Wz8Xq1auNgQMHGmXLljU8PT2NPn362F2mIMuqVauMsLAww8fHx3BzczOqV69u9O/f39i8efMNazp06JDx+OOPG9WrVzfc3NwMPz8/o02bNsbPP/+c84q7Qk6n3Xt7exvt2rXL8fXnz583hg8fbtSoUcNwcXEx/P39jXvvvdd455137H5e161bZ4SEhBguLi7ZfjZ27dplSDLq1KljN/bYsWMNScbrr7+eY63ffPON0bx5c8PDw8Pw8PAwateubURGRhqxsbF2/bZu3Wp0797dKFeunOHq6mpUrVrV6NWrl7FixQqzz7W+O1nb7UanqRuGYRw9etR4+OGHDW9vb8PT09Po0qWLsX///hu+zjAM44cffjAaNGhguLm5GdWqVTPGjx9vzJo1K9t7X/29ytKqVSu7y2IYhmHs2LHDaNWqleHm5mbcdtttxpgxY4xPP/00V5/n1VdfNRo2bGj4+PgYpUuXNqpUqWI888wzRnx8fK4+jxXZDKMIZnEBRWjbtm3617/+pc8//zzXp6gCAKyNOUQo0XK6NsiUKVPk5OR0wytEAwCQhTlEKNEmTJigmJgYtWnTRqVKldKSJUu0ZMkSDRw4UEFBQY4uDwBQQnDIDCVadHS0Ro8erd27dys5OVlVqlTRY489pldffTXb9V4AALgWAhEAALA85hABAADLIxABAADLY5JFLmRmZur48ePy8vIqcfecAgDAqgzD0Pnz51WpUqUc7xl4JQJRLhw/fpwzlgAAKKGOHj16w5siE4hyIeumfkePHpW3t7eDqwEAALmRlJSkoKCg696cNwuBKBeyDpN5e3sTiAAAKGFyM92FSdUAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDySjm6AEhxcXE6ffp0rvr6+/urSpUqhVwRAADWQiBysLi4ONWqXUcX/7mQq/5u7mUUu3cPoQgAgAJEIHKw06dP6+I/F1Suy4sqXS7oun3TzhzVmUWTdPr0aQIRAAAFiEBUTJQuFyTXwBqOLgMAAEtiUjUAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8AhEAALA8hwaijIwMvf766woODpa7u7uqV6+uMWPGyDAMs49hGBoxYoQqVqwod3d3tW/fXvv377cb5++//1afPn3k7e0tX19fRUREKDk52a7Pjh071KJFC7m5uSkoKEgTJkwoks8IAACKP4cGovHjx2vGjBmaNm2a9uzZo/Hjx2vChAmaOnWq2WfChAl6//33NXPmTG3YsEEeHh4KCwvTxYsXzT59+vTRrl27FB0drUWLFmnNmjUaOHCguTwpKUn333+/qlatqpiYGE2cOFGjRo3SRx99VKSfFwAAFE+lHPnm69atU9euXdW5c2dJUrVq1fS///1PGzdulHR579CUKVP02muvqWvXrpKkuXPnqkKFCvruu+/Uu3dv7dmzR0uXLtWmTZvUuHFjSdLUqVPVqVMnvfPOO6pUqZLmzZunS5cuadasWXJxcdGdd96pbdu2afLkyXbBCQAAWJND9xDde++9WrFihfbt2ydJ2r59u3799Vd17NhRknT48GHFx8erffv25mt8fHzUtGlTrV+/XpK0fv16+fr6mmFIktq3by8nJydt2LDB7NOyZUu5uLiYfcLCwhQbG6uzZ89mqys1NVVJSUl2DwAAcOty6B6iV155RUlJSapdu7acnZ2VkZGhN998U3369JEkxcfHS5IqVKhg97oKFSqYy+Lj4xUQEGC3vFSpUvLz87PrExwcnG2MrGVly5a1WzZu3DiNHj26gD4lAAAo7hy6h+irr77SvHnz9MUXX2jLli2aM2eO3nnnHc2ZM8eRZWn48OFKTEw0H0ePHnVoPQAAoHA5dA/RSy+9pFdeeUW9e/eWJNWvX19//vmnxo0bp/DwcAUGBkqSEhISVLFiRfN1CQkJatiwoSQpMDBQJ0+etBs3PT1df//9t/n6wMBAJSQk2PXJep7V50qurq5ydXUtmA8JAACKPYfuIbpw4YKcnOxLcHZ2VmZmpiQpODhYgYGBWrFihbk8KSlJGzZsUGhoqCQpNDRU586dU0xMjNln5cqVyszMVNOmTc0+a9asUVpamtknOjpatWrVyna4DAAAWI9DA9EDDzygN998U4sXL9aRI0e0cOFCTZ48WQ899JAkyWazaciQIRo7dqx++OEH7dy5U/369VOlSpXUrVs3SVKdOnXUoUMHPfnkk9q4caN+++03DRo0SL1791alSpUkSY8++qhcXFwUERGhXbt2af78+Xrvvfc0dOhQR310AABQjDj0kNnUqVP1+uuv69lnn9XJkydVqVIlPfXUUxoxYoTZ5+WXX1ZKSooGDhyoc+fOqXnz5lq6dKnc3NzMPvPmzdOgQYPUrl07OTk5qUePHnr//ffN5T4+Plq+fLkiIyMVEhIif39/jRgxglPuAQCAJMlmXHlZaOQoKSlJPj4+SkxMlLe3d4GOvWXLFoWEhCgwfIpcA2tct29q/AHFzxmimJgYNWrUqEDrAADgVpOXv9/cywwAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFiewwPRsWPH1LdvX5UrV07u7u6qX7++Nm/ebC43DEMjRoxQxYoV5e7urvbt22v//v12Y/z999/q06ePvL295evrq4iICCUnJ9v12bFjh1q0aCE3NzcFBQVpwoQJRfL5AABA8efQQHT27Fk1a9ZMpUuX1pIlS7R7925NmjRJZcuWNftMmDBB77//vmbOnKkNGzbIw8NDYWFhunjxotmnT58+2rVrl6Kjo7Vo0SKtWbNGAwcONJcnJSXp/vvvV9WqVRUTE6OJEydq1KhR+uijj4r08wIAgOKplCPffPz48QoKClJUVJTZFhwcbP6/YRiaMmWKXnvtNXXt2lWSNHfuXFWoUEHfffedevfurT179mjp0qXatGmTGjduLEmaOnWqOnXqpHfeeUeVKlXSvHnzdOnSJc2aNUsuLi668847tW3bNk2ePNkuOAEAAGty6B6iH374QY0bN1bPnj0VEBCgf/3rX/r444/N5YcPH1Z8fLzat29vtvn4+Khp06Zav369JGn9+vXy9fU1w5AktW/fXk5OTtqwYYPZp2XLlnJxcTH7hIWFKTY2VmfPns1WV2pqqpKSkuweAADg1uXQQHTo0CHNmDFDNWvW1LJly/TMM8/oueee05w5cyRJ8fHxkqQKFSrYva5ChQrmsvj4eAUEBNgtL1WqlPz8/Oz65DTGle9xpXHjxsnHx8d8BAUFFcCnBQAAxZVDA1FmZqYaNWqkt956S//61780cOBAPfnkk5o5c6Yjy9Lw4cOVmJhoPo4ePerQegAAQOFyaCCqWLGi6tata9dWp04dxcXFSZICAwMlSQkJCXZ9EhISzGWBgYE6efKk3fL09HT9/fffdn1yGuPK97iSq6urvL297R4AAODW5dBA1KxZM8XGxtq17du3T1WrVpV0eYJ1YGCgVqxYYS5PSkrShg0bFBoaKkkKDQ3VuXPnFBMTY/ZZuXKlMjMz1bRpU7PPmjVrlJaWZvaJjo5WrVq17M5oAwAA1uTQQPTCCy/o999/11tvvaUDBw7oiy++0EcffaTIyEhJks1m05AhQzR27Fj98MMP2rlzp/r166dKlSqpW7duki7vUerQoYOefPJJbdy4Ub/99psGDRqk3r17q1KlSpKkRx99VC4uLoqIiNCuXbs0f/58vffeexo6dKijPjoAAChGHHra/d13362FCxdq+PDheuONNxQcHKwpU6aoT58+Zp+XX35ZKSkpGjhwoM6dO6fmzZtr6dKlcnNzM/vMmzdPgwYNUrt27eTk5KQePXro/fffN5f7+Pho+fLlioyMVEhIiPz9/TVixAhOuQcAAJIkm2EYhqOLKO6SkpLk4+OjxMTEAp9PtGXLFoWEhCgwfIpcA2tct29q/AHFzxmimJgYNWrUqEDrAADgVpOXv98Ov3UHAACAoxGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5eUrEB06dKig6wAAAHCYfAWiGjVqqE2bNvr888918eLFgq4JAACgSOUrEG3ZskUNGjTQ0KFDFRgYqKeeekobN24s6NoAAACKRL4CUcOGDfXee+/p+PHjmjVrlk6cOKHmzZurXr16mjx5sk6dOlXQdQIAABSam5pUXapUKXXv3l0LFizQ+PHjdeDAAQ0bNkxBQUHq16+fTpw4UVB1AgAAFJqbCkSbN2/Ws88+q4oVK2ry5MkaNmyYDh48qOjoaB0/flxdu3YtqDoBAAAKTan8vGjy5MmKiopSbGysOnXqpLlz56pTp05ycrqcr4KDgzV79mxVq1atIGsFAAAoFPkKRDNmzNDjjz+u/v37q2LFijn2CQgI0KeffnpTxQEAABSFfAWi/fv337CPi4uLwsPD8zM8AABAkcrXHKKoqCgtWLAgW/uCBQs0Z86cmy4KAACgKOUrEI0bN07+/v7Z2gMCAvTWW2/ddFEAAABFKV+BKC4uTsHBwdnaq1atqri4uJsuCgAAoCjlKxAFBARox44d2dq3b9+ucuXK3XRRAAAARSlfgejf//63nnvuOa1atUoZGRnKyMjQypUr9fzzz6t3794FXSMAAEChytdZZmPGjNGRI0fUrl07lSp1eYjMzEz169ePOUQAAKDEyVcgcnFx0fz58zVmzBht375d7u7uql+/vqpWrVrQ9QEAABS6fAWiLHfccYfuuOOOgqoFAADAIfIViDIyMjR79mytWLFCJ0+eVGZmpt3ylStXFkhxAAAARSFfgej555/X7Nmz1blzZ9WrV082m62g6wIAACgy+QpEX375pb766it16tSpoOsBAAAocvk67d7FxUU1atQo6FoAAAAcIl+B6MUXX9R7770nwzAKuh4AAIAil69DZr/++qtWrVqlJUuW6M4771Tp0qXtln/77bcFUhwAAEBRyFcg8vX11UMPPVTQtQAAADhEvgJRVFRUQdcBAADgMPmaQyRJ6enp+vnnn/Xhhx/q/PnzkqTjx48rOTm5wIoDAAAoCvnaQ/Tnn3+qQ4cOiouLU2pqqu677z55eXlp/PjxSk1N1cyZMwu6TgAAgEKTrz1Ezz//vBo3bqyzZ8/K3d3dbH/ooYe0YsWKAisOAACgKORrD9HatWu1bt06ubi42LVXq1ZNx44dK5DCAAAAikq+9hBlZmYqIyMjW/tff/0lLy+vmy4KAACgKOUrEN1///2aMmWK+dxmsyk5OVkjR47kdh4AAKDEydchs0mTJiksLEx169bVxYsX9eijj2r//v3y9/fX//73v4KuEQAAoFDlKxBVrlxZ27dv15dffqkdO3YoOTlZERER6tOnj90kawAAgJIgX4FIkkqVKqW+ffsWZC0AAAAOka9ANHfu3Osu79evX76KAQAAcIR8BaLnn3/e7nlaWpouXLggFxcXlSlThkAEAABKlHydZXb27Fm7R3JysmJjY9W8eXMmVQMAgBIn3/cyu1rNmjX19ttvZ9t7BAAAUNwVWCCSLk+0Pn78eEEOCQAAUOjyNYfohx9+sHtuGIZOnDihadOmqVmzZgVSGAAAQFHJVyDq1q2b3XObzaby5curbdu2mjRpUkHUBQAAUGTyFYgyMzMLug4AAACHKdA5RAAAACVRvvYQDR06NNd9J0+enJ+3AAAAKDL5CkRbt27V1q1blZaWplq1akmS9u3bJ2dnZzVq1MjsZ7PZCqZKAACAQpSvQPTAAw/Iy8tLc+bMUdmyZSVdvljjgAED1KJFC7344osFWiQAAEBhytccokmTJmncuHFmGJKksmXLauzYsZxlBgAASpx8BaKkpCSdOnUqW/upU6d0/vz5my4KAACgKOUrED300EMaMGCAvv32W/3111/666+/9M033ygiIkLdu3cv6BoBAAAKVb7mEM2cOVPDhg3To48+qrS0tMsDlSqliIgITZw4sUALBAAAKGz5CkRlypTRBx98oIkTJ+rgwYOSpOrVq8vDw6NAiwMAACgKN3VhxhMnTujEiROqWbOmPDw8ZBhGvsd6++23ZbPZNGTIELPt4sWLioyMVLly5eTp6akePXooISHB7nVxcXHq3LmzypQpo4CAAL300ktKT0+36/PLL7+oUaNGcnV1VY0aNTR79ux81wkAAG49+QpEZ86cUbt27XTHHXeoU6dOOnHihCQpIiIiX6fcb9q0SR9++KEaNGhg1/7CCy/oxx9/1IIFC7R69WodP37cbo5SRkaGOnfurEuXLmndunWaM2eOZs+erREjRph9Dh8+rM6dO6tNmzbatm2bhgwZoieeeELLli3Lz0cHAAC3oHwFohdeeEGlS5dWXFycypQpY7Y/8sgjWrp0aZ7GSk5OVp8+ffTxxx/bncafmJioTz/9VJMnT1bbtm0VEhKiqKgorVu3Tr///rskafny5dq9e7c+//xzNWzYUB07dtSYMWM0ffp0Xbp0SdLl+U7BwcGaNGmS6tSpo0GDBunhhx/Wu+++m5+PDgAAbkH5CkTLly/X+PHjVblyZbv2mjVr6s8//8zTWJGRkercubPat29v1x4TE6O0tDS79tq1a6tKlSpav369JGn9+vWqX7++KlSoYPYJCwtTUlKSdu3aZfa5euywsDBzjJykpqYqKSnJ7gEAAG5d+ZpUnZKSYrdnKMvff/8tV1fXXI/z5ZdfasuWLdq0aVO2ZfHx8XJxcZGvr69de4UKFRQfH2/2uTIMZS3PWna9PklJSfrnn3/k7u6e7b3HjRun0aNH5/pzAACAki1fe4hatGihuXPnms9tNpsyMzM1YcIEtWnTJldjHD16VM8//7zmzZsnNze3/JRRaIYPH67ExETzcfToUUeXBAAAClG+9hBNmDBB7dq10+bNm3Xp0iW9/PLL2rVrl/7++2/99ttvuRojJiZGJ0+etLsZbEZGhtasWaNp06Zp2bJlunTpks6dO2e3lyghIUGBgYGSpMDAQG3cuNFu3Kyz0K7sc/WZaQkJCfL29s5x75Akubq65mlPFwAAKNnytYeoXr162rdvn5o3b66uXbsqJSVF3bt319atW1W9evVcjdGuXTvt3LlT27ZtMx+NGzdWnz59zP8vXbq0VqxYYb4mNjZWcXFxCg0NlSSFhoZq586dOnnypNknOjpa3t7eqlu3rtnnyjGy+mSNAQAAkOc9RGlpaerQoYNmzpypV199Nd9v7OXlpXr16tm1eXh4qFy5cmZ7RESEhg4dKj8/P3l7e2vw4MEKDQ3VPffcI0m6//77VbduXT322GOaMGGC4uPj9dprrykyMtLcw/P0009r2rRpevnll/X4449r5cqV+uqrr7R48eJ81w4AAG4teQ5EpUuX1o4dOwqjlmzeffddOTk5qUePHkpNTVVYWJg++OADc7mzs7MWLVqkZ555RqGhofLw8FB4eLjeeOMNs09wcLAWL16sF154Qe+9954qV66sTz75RGFhYUXyGQAAQPFnM/JxeekXXnhBrq6uevvttwujpmInKSlJPj4+SkxMlLe3d4GOvWXLFoWEhCgwfIpcA2tct29q/AHFzxmimJgYu7lXAAAgu7z8/c7XpOr09HTNmjVLP//8s0JCQrLdw2zy5Mn5GRYAAMAh8hSIDh06pGrVqumPP/4w91Ds27fPro/NZiu46gAAAIpAngJRzZo1deLECa1atUrS5Vt1vP/++9kufAgAAFCS5Om0+6unGy1ZskQpKSkFWhAAAEBRy9d1iLLkYz42AABAsZOnQGSz2bLNEWLOEAAAKOnyNIfIMAz179/fvOjhxYsX9fTTT2c7y+zbb78tuAoBAAAKWZ4CUXh4uN3zvn37FmgxAAAAjpCnQBQVFVVYdQAAADjMTU2qBgAAuBUQiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOURiAAAgOU5NBCNGzdOd999t7y8vBQQEKBu3bopNjbWrs/FixcVGRmpcuXKydPTUz169FBCQoJdn7i4OHXu3FllypRRQECAXnrpJaWnp9v1+eWXX9SoUSO5urqqRo0amj17dmF/PAAAUEI4NBCtXr1akZGR+v333xUdHa20tDTdf//9SklJMfu88MIL+vHHH7VgwQKtXr1ax48fV/fu3c3lGRkZ6ty5sy5duqR169Zpzpw5mj17tkaMGGH2OXz4sDp37qw2bdpo27ZtGjJkiJ544gktW7asSD8vAAAonmyGYRiOLiLLqVOnFBAQoNWrV6tly5ZKTExU+fLl9cUXX+jhhx+WJO3du1d16tTR+vXrdc8992jJkiXq0qWLjh8/rgoVKkiSZs6cqf/85z86deqUXFxc9J///EeLFy/WH3/8Yb5X7969de7cOS1duvSGdSUlJcnHx0eJiYny9vYu0M+8ZcsWhYSEKDB8ilwDa1y3b2r8AcXPGaKYmBg1atSoQOsAAOBWk5e/38VqDlFiYqIkyc/PT5IUExOjtLQ0tW/f3uxTu3ZtValSRevXr5ckrV+/XvXr1zfDkCSFhYUpKSlJu3btMvtcOUZWn6wxAACAtZVydAFZMjMzNWTIEDVr1kz16tWTJMXHx8vFxUW+vr52fStUqKD4+Hizz5VhKGt51rLr9UlKStI///wjd3d3u2WpqalKTU01nyclJd38BwQAAMVWsdlDFBkZqT/++ENffvmlo0vRuHHj5OPjYz6CgoIcXRIAAChExSIQDRo0SIsWLdKqVatUuXJlsz0wMFCXLl3SuXPn7PonJCQoMDDQ7HP1WWdZz2/Ux9vbO9veIUkaPny4EhMTzcfRo0dv+jMCAIDiy6GByDAMDRo0SAsXLtTKlSsVHBxstzwkJESlS5fWihUrzLbY2FjFxcUpNDRUkhQaGqqdO3fq5MmTZp/o6Gh5e3urbt26Zp8rx8jqkzXG1VxdXeXt7W33AAAAty6HziGKjIzUF198oe+//15eXl7mnB8fHx+5u7vLx8dHERERGjp0qPz8/OTt7a3BgwcrNDRU99xzjyTp/vvvV926dfXYY49pwoQJio+P12uvvabIyEi5urpKkp5++mlNmzZNL7/8sh5//HGtXLlSX331lRYvXuywzw4AAIoPh+4hmjFjhhITE9W6dWtVrFjRfMyfP9/s8+6776pLly7q0aOHWrZsqcDAQH377bfmcmdnZy1atEjOzs4KDQ1V37591a9fP73xxhtmn+DgYC1evFjR0dG66667NGnSJH3yyScKCwsr0s8LAACKJ4fuIcrNJZDc3Nw0ffp0TZ8+/Zp9qlatqp9++um647Ru3Vpbt27Nc40AAODWVywmVQMAADgSgQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFgegQgAAFieQ2/uivzZs2dPrvr5+/urSpUqhVwNAAAlH4GoBMlIPivZbOrbt2+u+ru5l1Hs3j2EIgAAboBAVIJkpiZLhqFyXV5U6XJB1+2bduaoziyapNOnTxOIAAC4AQJRCVS6XJBcA2s4ugwAAG4ZTKoGAACWRyACAACWRyACAACWRyACAACWx6TqW1xur1kkcd0iAIB1EYhuUXm9ZpHEdYsAANZFILpF5eWaRRLXLQIAWBuB6BaX12sWcVsQAIAVEYggiduCAACsjUAESdwWBABgbQQi2OG2IAAAK+I6RAAAwPLYQ4R8YwI2AOBWQSBCnjEBGwBwqyEQIc+YgA0AuNUQiJBvTMAGANwqmFQNAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj+sQoUjk9jYfErf6AAAUPQIRClVeb/MhcasPAEDRIxChUOXlNh8St/oAADgGgQhFgtt8AACKMyZVAwAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAy+NK1SiWcnszWG4ECwAoCAQiFCt5vRksN4IFABQEAhGKlbzcDDbrRrBr165VnTp1bjg2e5MAANdCIEKxlJubwbI3CQBQUAhEKLHyszfp9OnTBCIAQDYEIpR4udmbBADA9XDaPQAAsDz2EMFSCut0/ri4OJ0+fbpQxgYAFD4CESwhrxOwXV3d9M03X6tixYo37HvixAn1eLinUi/+k6uxmdwNAMUPgQiWkJcJ2Bf/2qVzKz9Rly5d8vQeTO4GgJKLQARLyc0E7LQzR3MdniTpn0Oblbj2cyZ3A0AJRiACriG3ASftzNE8j82tSQCgeCEQAUWIi0kCQPFEIAKKEBeTBIDiiUAEOADzjQCgeCEQAcVcbucbpaamytXVNdfjMj8JAP4/AhFQTOV1vpFsTpKRmevxmZ8EAP8fgQgopvIy3yjr1P/cXiqA+UkAYM9SgWj69OmaOHGi4uPjddddd2nq1Klq0qSJo8sCrivX107KZV8AQHaWCUTz58/X0KFDNXPmTDVt2lRTpkxRWFiYYmNjFRAQ4OjyAIcojPlJzGWyl5f73OVl3d3q6w0oapYJRJMnT9aTTz6pAQMGSJJmzpypxYsXa9asWXrllVccXB1QtAp1flIe5zLl5b5xhRUY8hJa8lJHXu9zl5d1l5f1JhGggBuxRCC6dOmSYmJiNHz4cLPNyclJ7du31/r16x1YGeAYhTU/Ka9zmfJ837hCCAx5Di15rEPK3X3u8rLu8nO/vcIKnnndI1hYY5fEmgsztBOA884Sgej06dPKyMhQhQoV7NorVKigvXv3Zuufmpqq1NRU83liYqIkKSkpqcBrS05Ovvye8QeUeenidftmzRMp6L6FOXZJrMNKNWempd6wv5F+qVD6SlLmhUTJMOR9d3c5+5S/bt9Lx/cpZfeqXPVNO3VEyduX5Skw5GbcvNaR1beg111e1puUn/Vhk2QUQt/CHLvk1ezi6qbPP5ub7W/T1RISEtT3sX66lHrjn6m8ji1d3kGQmZm7gJ+XvnntHxgYqMDAwFyPnRtZf7cNIxfbxLCAY8eOGZKMdevW2bW/9NJLRpMmTbL1HzlypKHL32gePHjw4MGDRwl/HD169IZZwRJ7iPz9/eXs7KyEhAS79oSEhBzT6PDhwzV06FDzeWZmpv7++2+VK1dONputQGtLSkpSUFCQjh49Km9v7wIdGzeP7VO8sX2KL7ZN8WaV7WMYhs6fP69KlSrdsK8lApGLi4tCQkK0YsUKdevWTdLlkLNixQoNGjQoW39XV9dsx4B9fX0LtUZvb+9b+ktZ0rF9ije2T/HFtinerLB9fHx8ctXPEoFIkoYOHarw8HA1btxYTZo00ZQpU5SSkmKedQYAAKzLMoHokUce0alTpzRixAjFx8erYcOGWrp0aa4mnAEAgFubZQKRJA0aNCjHQ2SO5OrqqpEjR+bpFFAUHbZP8cb2Kb7YNsUb2yc7m2Hk5lw0AACAW5eTowsAAABwNAIRAACwPAIRAACwPAIRAACwPAKRA02fPl3VqlWTm5ubmjZtqo0bNzq6JPyfNWvW6IEHHlClSpVks9n03XffObok/J9x48bp7rvvlpeXlwICAtStWzfFxsY6uiz8nxkzZqhBgwbmBf9CQ0O1ZMkSR5eFHLz99tuy2WwaMmSIo0spFghEDjJ//nwNHTpUI0eO1JYtW3TXXXcpLCxMJ0+edHRpkJSSkqK77rpL06dPd3QpuMrq1asVGRmp33//XdHR0UpLS9P999+vlJQUR5cGSZUrV9bbb7+tmJgYbd68WW3btlXXrl21a9cuR5eGK2zatEkffvihGjRo4OhSig1Ou3eQpk2b6u6779a0adMkXb6VSFBQkAYPHqxXXnnFwdXhSjabTQsXLjRv+4Li5dSpUwoICNDq1avVsmVLR5eDHPj5+WnixImKiIhwdCmQlJycrEaNGumDDz7Q2LFj1bBhQ02ZMsXRZTkce4gc4NKlS4qJiVH79u3NNicnJ7Vv317r1693YGVAyZOYmCjp8h9dFC8ZGRn68ssvlZKSotDQUEeXg/8TGRmpzp072/0NgsWuVF1cnD59WhkZGdluG1KhQgXt3bvXQVUBJU9mZqaGDBmiZs2aqV69eo4uB/9n586dCg0N1cWLF+Xp6amFCxeqbt26ji4Lkr788ktt2bJFmzZtcnQpxQ6BCECJFRkZqT/++EO//vqro0vBFWrVqqVt27YpMTFRX3/9tcLDw7V69WpCkYMdPXpUzz//vKKjo+Xm5ubocoodApED+Pv7y9nZWQkJCXbtCQkJCgwMdFBVQMkyaNAgLVq0SGvWrFHlypUdXQ6u4OLioho1akiSQkJCtGnTJr333nv68MMPHVyZtcXExOjkyZNq1KiR2ZaRkaE1a9Zo2rRpSk1NlbOzswMrdCzmEDmAi4uLQkJCtGLFCrMtMzNTK1as4Dg7cAOGYWjQoEFauHChVq5cqeDgYEeXhBvIzMxUamqqo8uwvHbt2mnnzp3atm2b+WjcuLH69Omjbdu2WToMSewhcpihQ4cqPDxcjRs3VpMmTTRlyhSlpKRowIABji4NunwWxoEDB8znhw8f1rZt2+Tn56cqVao4sDJERkbqiy++0Pfffy8vLy/Fx8dLknx8fOTu7u7g6jB8+HB17NhRVapU0fnz5/XFF1/ol19+0bJlyxxdmuV5eXllm2vn4eGhcuXKMQdPBCKHeeSRR3Tq1CmNGDFC8fHxatiwoZYuXZptojUcY/PmzWrTpo35fOjQoZKk8PBwzZ4920FVQbp84T9Jat26tV17VFSU+vfvX/QFwc7JkyfVr18/nThxQj4+PmrQoIGWLVum++67z9GlAdfFdYgAAIDlMYcIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIgGW1bt1aQ4YMcXQZAIoBAhGAEumBBx5Qhw4dcly2du1a2Ww27dixo4irAlBSEYgAlEgRERGKjo7WX3/9lW1ZVFSUGjdurAYNGjigMgAlEYEIQInUpUsXlS9fPtu95ZKTk7VgwQJ169ZN//73v3XbbbepTJkyql+/vv73v/9dd0ybzabvvvvOrs3X19fuPY4ePapevXrJ19dXfn5+6tq1q44cOVIwHwqAwxCIAJRIpUqVUr9+/TR79mxdeUvGBQsWKCMjQ3379lVISIgWL16sP/74QwMHDtRjjz2mjRs35vs909LSFBYWJi8vL61du1a//fabPD091aFDB126dKkgPhYAByEQASixHn/8cR08eFCrV68226KiotSjRw9VrVpVw4YNU8OGDXX77bdr8ODB6tChg7766qt8v9/8+fOVmZmpTz75RPXr11edOnUUFRWluLg4/fLLLwXwiQA4CoEIQIlVu3Zt3XvvvZo1a5Yk6cCBA1q7dq0iIiKUkZGhMWPGqH79+vLz85Onp6eWLVumuLi4fL/f9u3bdeDAAXl5ecnT01Oenp7y8/PTxYsXdfDgwYL6WAAcoJSjCwCAmxEREaHBgwdr+vTpioqKUvXq1dWqVSuNHz9e7733nqZMmaL69evLw8NDQ4YMue6hLZvNZnf4Tbp8mCxLcnKyQkJCNG/evGyvLV++fMF9KABFjkAEoETr1auXnn/+eX3xxReaO3eunnnmGdlsNv3222/q2rWr+vbtK0nKzMzUvn37VLdu3WuOVb58eZ04ccJ8vn//fl24cMF83qhRI82fP18BAQHy9vYuvA8FoMhxyAxAiebp6alHHnlEw4cP14kTJ9S/f39JUs2aNRUdHa1169Zpz549euqpp5SQkHDdsdq2batp06Zp69at2rx5s55++mmVLl3aXN6nTx/5+/ura9euWrt2rQ4fPqxffvlFzz33XI6n/wMoOQhEAEq8iIgInT17VmFhYapUqZIk6bXXXlOjRo0UFham1q1bKzAwUN26dbvuOJMmTVJQUJBatGihRx99VMOGDVOZMmXM5WXKlNGaNWtUpUoVde/eXXXq1FFERIQuXrzIHiOghLMZVx8wBwAAsBj2EAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMv7fx/LgdkYWnbaAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# xo = [inputs[i][0] for i in range(len(inputs))]\n",
        "# xo = [success_labels[i] for i in range(len(success_labels))]\n",
        "xo = [q[0] for q in quality]\n",
        "\n",
        "# Create the histogram\n",
        "plt.hist(xo, bins=40, edgecolor='black')  # You can adjust the number of bins\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Float Numbers Between 0 and 5')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qeBv36fri5L"
      },
      "source": [
        "# TENSORFLOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yi4fyPzkg43"
      },
      "outputs": [],
      "source": [
        "# Assuming X is your input data and y is your output data\n",
        "labels = [[s,m] for s,m in zip(success_labels, maneuver_labels)]\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Min-Max Scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
        "X_test_minmax = min_max_scaler.transform(X_test)\n",
        "joblib.dump(min_max_scaler, 'scaler_minmax.pkl')\n",
        "\n",
        "# Standardization\n",
        "standard_scaler = StandardScaler()\n",
        "X_train_standard = standard_scaler.fit_transform(X_train)\n",
        "X_test_standard = standard_scaler.transform(X_test)\n",
        "\n",
        "# # Normalize the data\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit(X_train)\n",
        "# X_test = scaler.transform(X_test[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZnawUnZkGH5",
        "outputId": "f644e8d7-1e0b-4716-b768-9bf0420583cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['scaler_minmax.pkl']"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(min_max_scaler, 'scaler_minmax.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI9KS0OgkaWX",
        "outputId": "cb5472c6-f9a5-43c2-c363-40ec73d83228"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-1.63852813, -0.50929621,  0.08382842, -0.13254498, -1.53643876,\n",
              "        -0.48864586,  0.00356794,  1.42156081,  0.02362815, -0.37003961],\n",
              "       [-1.4017682 , -0.41107987, -0.19069578,  0.03995952, -1.37368982,\n",
              "        -0.38683071,  0.00732365,  1.2256062 ,  0.1998657 ,  0.13719381]])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # Load the scaler\n",
        "# scaler0 = joblib.load('my_scaler.pkl')\n",
        "\n",
        "# # Apply the scaler to new data\n",
        "# X_new_transformed = scaler0.transform(X_test[:2])\n",
        "# X_new_transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGG6dugcxzEw",
        "outputId": "7a7012c2-aab9-4a4f-e4ad-e665be825fe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "65/65 - 2s - loss: 0.8649 - val_loss: 0.5981 - 2s/epoch - 35ms/step\n",
            "Epoch 2/300\n",
            "65/65 - 0s - loss: 0.5417 - val_loss: 0.5303 - 294ms/epoch - 5ms/step\n",
            "Epoch 3/300\n",
            "65/65 - 0s - loss: 0.4823 - val_loss: 0.4703 - 255ms/epoch - 4ms/step\n",
            "Epoch 4/300\n",
            "65/65 - 0s - loss: 0.4376 - val_loss: 0.4331 - 250ms/epoch - 4ms/step\n",
            "Epoch 5/300\n",
            "65/65 - 0s - loss: 0.4111 - val_loss: 0.4090 - 262ms/epoch - 4ms/step\n",
            "Epoch 6/300\n",
            "65/65 - 0s - loss: 0.3882 - val_loss: 0.3820 - 247ms/epoch - 4ms/step\n",
            "Epoch 7/300\n",
            "65/65 - 0s - loss: 0.3647 - val_loss: 0.3586 - 251ms/epoch - 4ms/step\n",
            "Epoch 8/300\n",
            "65/65 - 0s - loss: 0.3376 - val_loss: 0.3466 - 261ms/epoch - 4ms/step\n",
            "Epoch 9/300\n",
            "65/65 - 0s - loss: 0.3149 - val_loss: 0.3181 - 306ms/epoch - 5ms/step\n",
            "Epoch 10/300\n",
            "65/65 - 0s - loss: 0.2921 - val_loss: 0.3065 - 258ms/epoch - 4ms/step\n",
            "Epoch 11/300\n",
            "65/65 - 0s - loss: 0.2702 - val_loss: 0.3079 - 365ms/epoch - 6ms/step\n",
            "Epoch 12/300\n",
            "65/65 - 0s - loss: 0.2528 - val_loss: 0.2541 - 377ms/epoch - 6ms/step\n",
            "Epoch 13/300\n",
            "65/65 - 0s - loss: 0.2378 - val_loss: 0.2461 - 397ms/epoch - 6ms/step\n",
            "Epoch 14/300\n",
            "65/65 - 0s - loss: 0.2206 - val_loss: 0.2379 - 388ms/epoch - 6ms/step\n",
            "Epoch 15/300\n",
            "65/65 - 0s - loss: 0.2079 - val_loss: 0.2212 - 424ms/epoch - 7ms/step\n",
            "Epoch 16/300\n",
            "65/65 - 0s - loss: 0.1967 - val_loss: 0.2304 - 421ms/epoch - 6ms/step\n",
            "Epoch 17/300\n",
            "65/65 - 0s - loss: 0.1879 - val_loss: 0.2054 - 373ms/epoch - 6ms/step\n",
            "Epoch 18/300\n",
            "65/65 - 0s - loss: 0.1802 - val_loss: 0.2107 - 369ms/epoch - 6ms/step\n",
            "Epoch 19/300\n",
            "65/65 - 0s - loss: 0.1786 - val_loss: 0.2091 - 418ms/epoch - 6ms/step\n",
            "Epoch 20/300\n",
            "65/65 - 0s - loss: 0.1737 - val_loss: 0.1832 - 284ms/epoch - 4ms/step\n",
            "Epoch 21/300\n",
            "65/65 - 0s - loss: 0.1654 - val_loss: 0.1985 - 257ms/epoch - 4ms/step\n",
            "Epoch 22/300\n",
            "65/65 - 0s - loss: 0.1587 - val_loss: 0.2069 - 256ms/epoch - 4ms/step\n",
            "Epoch 23/300\n",
            "65/65 - 0s - loss: 0.1539 - val_loss: 0.1742 - 254ms/epoch - 4ms/step\n",
            "Epoch 24/300\n",
            "65/65 - 0s - loss: 0.1479 - val_loss: 0.1726 - 258ms/epoch - 4ms/step\n",
            "Epoch 25/300\n",
            "65/65 - 0s - loss: 0.1473 - val_loss: 0.1896 - 247ms/epoch - 4ms/step\n",
            "Epoch 26/300\n",
            "65/65 - 0s - loss: 0.1412 - val_loss: 0.1852 - 247ms/epoch - 4ms/step\n",
            "Epoch 27/300\n",
            "65/65 - 0s - loss: 0.1378 - val_loss: 0.2029 - 287ms/epoch - 4ms/step\n",
            "Epoch 28/300\n",
            "65/65 - 0s - loss: 0.1360 - val_loss: 0.1785 - 304ms/epoch - 5ms/step\n",
            "Epoch 29/300\n",
            "65/65 - 0s - loss: 0.1337 - val_loss: 0.1562 - 262ms/epoch - 4ms/step\n",
            "Epoch 30/300\n",
            "65/65 - 0s - loss: 0.1319 - val_loss: 0.1718 - 251ms/epoch - 4ms/step\n",
            "Epoch 31/300\n",
            "65/65 - 0s - loss: 0.1250 - val_loss: 0.1688 - 266ms/epoch - 4ms/step\n",
            "Epoch 32/300\n",
            "65/65 - 0s - loss: 0.1220 - val_loss: 0.1624 - 256ms/epoch - 4ms/step\n",
            "Epoch 33/300\n",
            "65/65 - 0s - loss: 0.1277 - val_loss: 0.2058 - 259ms/epoch - 4ms/step\n",
            "Epoch 34/300\n",
            "65/65 - 0s - loss: 0.1255 - val_loss: 0.1559 - 272ms/epoch - 4ms/step\n",
            "Epoch 35/300\n",
            "65/65 - 0s - loss: 0.1192 - val_loss: 0.1464 - 323ms/epoch - 5ms/step\n",
            "Epoch 36/300\n",
            "65/65 - 0s - loss: 0.1210 - val_loss: 0.1522 - 303ms/epoch - 5ms/step\n",
            "Epoch 37/300\n",
            "65/65 - 0s - loss: 0.1148 - val_loss: 0.1477 - 264ms/epoch - 4ms/step\n",
            "Epoch 38/300\n",
            "65/65 - 0s - loss: 0.1116 - val_loss: 0.1493 - 270ms/epoch - 4ms/step\n",
            "Epoch 39/300\n",
            "65/65 - 0s - loss: 0.1149 - val_loss: 0.1510 - 314ms/epoch - 5ms/step\n",
            "Epoch 40/300\n",
            "65/65 - 0s - loss: 0.1119 - val_loss: 0.1526 - 248ms/epoch - 4ms/step\n",
            "Epoch 41/300\n",
            "65/65 - 0s - loss: 0.1060 - val_loss: 0.1445 - 291ms/epoch - 4ms/step\n",
            "Epoch 42/300\n",
            "65/65 - 0s - loss: 0.1107 - val_loss: 0.1482 - 281ms/epoch - 4ms/step\n",
            "Epoch 43/300\n",
            "65/65 - 0s - loss: 0.1043 - val_loss: 0.1501 - 260ms/epoch - 4ms/step\n",
            "Epoch 44/300\n",
            "65/65 - 0s - loss: 0.1035 - val_loss: 0.1382 - 255ms/epoch - 4ms/step\n",
            "Epoch 45/300\n",
            "65/65 - 0s - loss: 0.0980 - val_loss: 0.1353 - 295ms/epoch - 5ms/step\n",
            "Epoch 46/300\n",
            "65/65 - 0s - loss: 0.0982 - val_loss: 0.1744 - 301ms/epoch - 5ms/step\n",
            "Epoch 47/300\n",
            "65/65 - 0s - loss: 0.0977 - val_loss: 0.1501 - 247ms/epoch - 4ms/step\n",
            "Epoch 48/300\n",
            "65/65 - 0s - loss: 0.0974 - val_loss: 0.1497 - 295ms/epoch - 5ms/step\n",
            "Epoch 49/300\n",
            "65/65 - 0s - loss: 0.0938 - val_loss: 0.1805 - 270ms/epoch - 4ms/step\n",
            "Epoch 50/300\n",
            "65/65 - 0s - loss: 0.0986 - val_loss: 0.1592 - 258ms/epoch - 4ms/step\n",
            "Epoch 51/300\n",
            "65/65 - 0s - loss: 0.0918 - val_loss: 0.1361 - 277ms/epoch - 4ms/step\n",
            "Epoch 52/300\n",
            "65/65 - 0s - loss: 0.0895 - val_loss: 0.1317 - 300ms/epoch - 5ms/step\n",
            "Epoch 53/300\n",
            "65/65 - 0s - loss: 0.0951 - val_loss: 0.1417 - 264ms/epoch - 4ms/step\n",
            "Epoch 54/300\n",
            "65/65 - 0s - loss: 0.0923 - val_loss: 0.1400 - 252ms/epoch - 4ms/step\n",
            "Epoch 55/300\n",
            "65/65 - 0s - loss: 0.0873 - val_loss: 0.1426 - 254ms/epoch - 4ms/step\n",
            "Epoch 56/300\n",
            "65/65 - 0s - loss: 0.0900 - val_loss: 0.1407 - 374ms/epoch - 6ms/step\n",
            "Epoch 57/300\n",
            "65/65 - 0s - loss: 0.0843 - val_loss: 0.1365 - 414ms/epoch - 6ms/step\n",
            "Epoch 58/300\n",
            "65/65 - 0s - loss: 0.0851 - val_loss: 0.1262 - 391ms/epoch - 6ms/step\n",
            "Epoch 59/300\n",
            "65/65 - 0s - loss: 0.0804 - val_loss: 0.1342 - 363ms/epoch - 6ms/step\n",
            "Epoch 60/300\n",
            "65/65 - 0s - loss: 0.0852 - val_loss: 0.1474 - 388ms/epoch - 6ms/step\n",
            "Epoch 61/300\n",
            "65/65 - 0s - loss: 0.0811 - val_loss: 0.1391 - 367ms/epoch - 6ms/step\n",
            "Epoch 62/300\n",
            "65/65 - 0s - loss: 0.0786 - val_loss: 0.1302 - 396ms/epoch - 6ms/step\n",
            "Epoch 63/300\n",
            "65/65 - 0s - loss: 0.0810 - val_loss: 0.1505 - 383ms/epoch - 6ms/step\n",
            "Epoch 64/300\n",
            "65/65 - 0s - loss: 0.0807 - val_loss: 0.1371 - 388ms/epoch - 6ms/step\n",
            "Epoch 65/300\n",
            "65/65 - 0s - loss: 0.0773 - val_loss: 0.1339 - 312ms/epoch - 5ms/step\n",
            "Epoch 66/300\n",
            "65/65 - 0s - loss: 0.0775 - val_loss: 0.1238 - 259ms/epoch - 4ms/step\n",
            "Epoch 67/300\n",
            "65/65 - 0s - loss: 0.0777 - val_loss: 0.1539 - 277ms/epoch - 4ms/step\n",
            "Epoch 68/300\n",
            "65/65 - 0s - loss: 0.0827 - val_loss: 0.1303 - 255ms/epoch - 4ms/step\n",
            "Epoch 69/300\n",
            "65/65 - 0s - loss: 0.0741 - val_loss: 0.1339 - 283ms/epoch - 4ms/step\n",
            "Epoch 70/300\n",
            "65/65 - 0s - loss: 0.0745 - val_loss: 0.1576 - 239ms/epoch - 4ms/step\n",
            "Epoch 71/300\n",
            "65/65 - 0s - loss: 0.0779 - val_loss: 0.1333 - 280ms/epoch - 4ms/step\n",
            "Epoch 72/300\n",
            "65/65 - 0s - loss: 0.0750 - val_loss: 0.1441 - 255ms/epoch - 4ms/step\n",
            "Epoch 73/300\n",
            "65/65 - 0s - loss: 0.0736 - val_loss: 0.1359 - 251ms/epoch - 4ms/step\n",
            "Epoch 74/300\n",
            "65/65 - 0s - loss: 0.0683 - val_loss: 0.1484 - 290ms/epoch - 4ms/step\n",
            "Epoch 75/300\n",
            "65/65 - 0s - loss: 0.0695 - val_loss: 0.1323 - 246ms/epoch - 4ms/step\n",
            "Epoch 76/300\n",
            "65/65 - 0s - loss: 0.0673 - val_loss: 0.1255 - 256ms/epoch - 4ms/step\n",
            "Epoch 77/300\n",
            "65/65 - 0s - loss: 0.0662 - val_loss: 0.1475 - 250ms/epoch - 4ms/step\n",
            "Epoch 78/300\n",
            "65/65 - 0s - loss: 0.0648 - val_loss: 0.1268 - 246ms/epoch - 4ms/step\n",
            "Epoch 79/300\n",
            "65/65 - 0s - loss: 0.0688 - val_loss: 0.1226 - 267ms/epoch - 4ms/step\n",
            "Epoch 80/300\n",
            "65/65 - 0s - loss: 0.0655 - val_loss: 0.1256 - 256ms/epoch - 4ms/step\n",
            "Epoch 81/300\n",
            "65/65 - 0s - loss: 0.0661 - val_loss: 0.1260 - 284ms/epoch - 4ms/step\n",
            "Epoch 82/300\n",
            "65/65 - 0s - loss: 0.0622 - val_loss: 0.1318 - 288ms/epoch - 4ms/step\n",
            "Epoch 83/300\n",
            "65/65 - 0s - loss: 0.0709 - val_loss: 0.1313 - 286ms/epoch - 4ms/step\n",
            "Epoch 84/300\n",
            "65/65 - 0s - loss: 0.0648 - val_loss: 0.1188 - 285ms/epoch - 4ms/step\n",
            "Epoch 85/300\n",
            "65/65 - 0s - loss: 0.0640 - val_loss: 0.1352 - 269ms/epoch - 4ms/step\n",
            "Epoch 86/300\n",
            "65/65 - 0s - loss: 0.0622 - val_loss: 0.1245 - 292ms/epoch - 4ms/step\n",
            "Epoch 87/300\n",
            "65/65 - 0s - loss: 0.0658 - val_loss: 0.1255 - 254ms/epoch - 4ms/step\n",
            "Epoch 88/300\n",
            "65/65 - 0s - loss: 0.0612 - val_loss: 0.1272 - 267ms/epoch - 4ms/step\n",
            "Epoch 89/300\n",
            "65/65 - 0s - loss: 0.0633 - val_loss: 0.1544 - 262ms/epoch - 4ms/step\n",
            "Epoch 90/300\n",
            "65/65 - 0s - loss: 0.0587 - val_loss: 0.1278 - 261ms/epoch - 4ms/step\n",
            "Epoch 91/300\n",
            "65/65 - 0s - loss: 0.0623 - val_loss: 0.1312 - 257ms/epoch - 4ms/step\n",
            "Epoch 92/300\n",
            "65/65 - 0s - loss: 0.0595 - val_loss: 0.1279 - 256ms/epoch - 4ms/step\n",
            "Epoch 93/300\n",
            "65/65 - 0s - loss: 0.0597 - val_loss: 0.1400 - 261ms/epoch - 4ms/step\n",
            "Epoch 94/300\n",
            "65/65 - 0s - loss: 0.0616 - val_loss: 0.1231 - 257ms/epoch - 4ms/step\n",
            "Epoch 95/300\n",
            "65/65 - 0s - loss: 0.0568 - val_loss: 0.1226 - 303ms/epoch - 5ms/step\n",
            "Epoch 96/300\n",
            "65/65 - 0s - loss: 0.0579 - val_loss: 0.1183 - 269ms/epoch - 4ms/step\n",
            "Epoch 97/300\n",
            "65/65 - 0s - loss: 0.0598 - val_loss: 0.1263 - 291ms/epoch - 4ms/step\n",
            "Epoch 98/300\n",
            "65/65 - 0s - loss: 0.0549 - val_loss: 0.1302 - 304ms/epoch - 5ms/step\n",
            "Epoch 99/300\n",
            "65/65 - 0s - loss: 0.0543 - val_loss: 0.1313 - 258ms/epoch - 4ms/step\n",
            "Epoch 100/300\n",
            "65/65 - 0s - loss: 0.0524 - val_loss: 0.1312 - 262ms/epoch - 4ms/step\n",
            "Epoch 101/300\n",
            "65/65 - 0s - loss: 0.0520 - val_loss: 0.1678 - 265ms/epoch - 4ms/step\n",
            "Epoch 102/300\n",
            "65/65 - 0s - loss: 0.0641 - val_loss: 0.1358 - 432ms/epoch - 7ms/step\n",
            "Epoch 103/300\n",
            "65/65 - 0s - loss: 0.0515 - val_loss: 0.1257 - 418ms/epoch - 6ms/step\n",
            "Epoch 104/300\n",
            "65/65 - 0s - loss: 0.0530 - val_loss: 0.1276 - 370ms/epoch - 6ms/step\n",
            "Epoch 105/300\n",
            "65/65 - 0s - loss: 0.0520 - val_loss: 0.1202 - 365ms/epoch - 6ms/step\n",
            "Epoch 106/300\n",
            "65/65 - 0s - loss: 0.0517 - val_loss: 0.1307 - 396ms/epoch - 6ms/step\n",
            "Epoch 107/300\n",
            "65/65 - 0s - loss: 0.0488 - val_loss: 0.1290 - 410ms/epoch - 6ms/step\n",
            "Epoch 108/300\n",
            "65/65 - 0s - loss: 0.0506 - val_loss: 0.1236 - 375ms/epoch - 6ms/step\n",
            "Epoch 109/300\n",
            "65/65 - 0s - loss: 0.0507 - val_loss: 0.1301 - 389ms/epoch - 6ms/step\n",
            "Epoch 110/300\n",
            "65/65 - 0s - loss: 0.0479 - val_loss: 0.1249 - 397ms/epoch - 6ms/step\n",
            "Epoch 111/300\n",
            "65/65 - 0s - loss: 0.0535 - val_loss: 0.1242 - 239ms/epoch - 4ms/step\n",
            "Epoch 112/300\n",
            "65/65 - 0s - loss: 0.0527 - val_loss: 0.1207 - 240ms/epoch - 4ms/step\n",
            "Epoch 113/300\n",
            "65/65 - 0s - loss: 0.0453 - val_loss: 0.1224 - 253ms/epoch - 4ms/step\n",
            "Epoch 114/300\n",
            "65/65 - 0s - loss: 0.0503 - val_loss: 0.1212 - 250ms/epoch - 4ms/step\n",
            "Epoch 115/300\n",
            "65/65 - 0s - loss: 0.0503 - val_loss: 0.1219 - 281ms/epoch - 4ms/step\n",
            "Epoch 116/300\n",
            "65/65 - 0s - loss: 0.0497 - val_loss: 0.1149 - 246ms/epoch - 4ms/step\n",
            "Epoch 117/300\n",
            "65/65 - 0s - loss: 0.0440 - val_loss: 0.1183 - 290ms/epoch - 4ms/step\n",
            "Epoch 118/300\n",
            "65/65 - 0s - loss: 0.0487 - val_loss: 0.1121 - 280ms/epoch - 4ms/step\n",
            "Epoch 119/300\n",
            "65/65 - 0s - loss: 0.0444 - val_loss: 0.1122 - 248ms/epoch - 4ms/step\n",
            "Epoch 120/300\n",
            "65/65 - 0s - loss: 0.0434 - val_loss: 0.1331 - 244ms/epoch - 4ms/step\n",
            "Epoch 121/300\n",
            "65/65 - 0s - loss: 0.0474 - val_loss: 0.1171 - 296ms/epoch - 5ms/step\n",
            "Epoch 122/300\n",
            "65/65 - 0s - loss: 0.0438 - val_loss: 0.1189 - 287ms/epoch - 4ms/step\n",
            "Epoch 123/300\n",
            "65/65 - 0s - loss: 0.0448 - val_loss: 0.1305 - 251ms/epoch - 4ms/step\n",
            "Epoch 124/300\n",
            "65/65 - 0s - loss: 0.0438 - val_loss: 0.1120 - 254ms/epoch - 4ms/step\n",
            "Epoch 125/300\n",
            "65/65 - 0s - loss: 0.0506 - val_loss: 0.1168 - 250ms/epoch - 4ms/step\n",
            "Epoch 126/300\n",
            "65/65 - 0s - loss: 0.0489 - val_loss: 0.1255 - 287ms/epoch - 4ms/step\n",
            "Epoch 127/300\n",
            "65/65 - 0s - loss: 0.0404 - val_loss: 0.1463 - 246ms/epoch - 4ms/step\n",
            "Epoch 128/300\n",
            "65/65 - 0s - loss: 0.0473 - val_loss: 0.1156 - 254ms/epoch - 4ms/step\n",
            "Epoch 129/300\n",
            "65/65 - 0s - loss: 0.0434 - val_loss: 0.1290 - 259ms/epoch - 4ms/step\n",
            "Epoch 130/300\n",
            "65/65 - 0s - loss: 0.0409 - val_loss: 0.1214 - 286ms/epoch - 4ms/step\n",
            "Epoch 131/300\n",
            "65/65 - 0s - loss: 0.0382 - val_loss: 0.1157 - 253ms/epoch - 4ms/step\n",
            "Epoch 132/300\n",
            "65/65 - 0s - loss: 0.0383 - val_loss: 0.1258 - 261ms/epoch - 4ms/step\n",
            "Epoch 133/300\n",
            "65/65 - 0s - loss: 0.0404 - val_loss: 0.1218 - 295ms/epoch - 5ms/step\n",
            "Epoch 134/300\n",
            "65/65 - 0s - loss: 0.0475 - val_loss: 0.1191 - 251ms/epoch - 4ms/step\n",
            "Epoch 135/300\n",
            "65/65 - 0s - loss: 0.0399 - val_loss: 0.1175 - 246ms/epoch - 4ms/step\n",
            "Epoch 136/300\n",
            "65/65 - 0s - loss: 0.0406 - val_loss: 0.1221 - 256ms/epoch - 4ms/step\n",
            "Epoch 137/300\n",
            "65/65 - 0s - loss: 0.0403 - val_loss: 0.1140 - 271ms/epoch - 4ms/step\n",
            "Epoch 138/300\n",
            "65/65 - 0s - loss: 0.0391 - val_loss: 0.1175 - 265ms/epoch - 4ms/step\n",
            "Epoch 139/300\n",
            "65/65 - 0s - loss: 0.0425 - val_loss: 0.1290 - 256ms/epoch - 4ms/step\n",
            "Epoch 140/300\n",
            "65/65 - 0s - loss: 0.0401 - val_loss: 0.1187 - 275ms/epoch - 4ms/step\n",
            "Epoch 141/300\n",
            "65/65 - 0s - loss: 0.0390 - val_loss: 0.1143 - 253ms/epoch - 4ms/step\n",
            "Epoch 142/300\n",
            "65/65 - 0s - loss: 0.0375 - val_loss: 0.1168 - 246ms/epoch - 4ms/step\n",
            "Epoch 143/300\n",
            "65/65 - 0s - loss: 0.0404 - val_loss: 0.1365 - 250ms/epoch - 4ms/step\n",
            "Epoch 144/300\n",
            "65/65 - 0s - loss: 0.0419 - val_loss: 0.1215 - 259ms/epoch - 4ms/step\n",
            "Epoch 145/300\n",
            "65/65 - 0s - loss: 0.0382 - val_loss: 0.1255 - 290ms/epoch - 4ms/step\n",
            "Epoch 146/300\n",
            "65/65 - 0s - loss: 0.0369 - val_loss: 0.1229 - 247ms/epoch - 4ms/step\n",
            "Epoch 147/300\n",
            "65/65 - 0s - loss: 0.0399 - val_loss: 0.1166 - 255ms/epoch - 4ms/step\n",
            "Epoch 148/300\n",
            "65/65 - 0s - loss: 0.0396 - val_loss: 0.1263 - 361ms/epoch - 6ms/step\n",
            "Epoch 149/300\n",
            "65/65 - 0s - loss: 0.0429 - val_loss: 0.1275 - 393ms/epoch - 6ms/step\n",
            "Epoch 150/300\n",
            "65/65 - 0s - loss: 0.0397 - val_loss: 0.1193 - 366ms/epoch - 6ms/step\n",
            "Epoch 151/300\n",
            "65/65 - 0s - loss: 0.0385 - val_loss: 0.1160 - 349ms/epoch - 5ms/step\n",
            "Epoch 152/300\n",
            "65/65 - 0s - loss: 0.0352 - val_loss: 0.1160 - 378ms/epoch - 6ms/step\n",
            "Epoch 153/300\n",
            "65/65 - 0s - loss: 0.0341 - val_loss: 0.1166 - 401ms/epoch - 6ms/step\n",
            "Epoch 154/300\n",
            "65/65 - 0s - loss: 0.0339 - val_loss: 0.1165 - 385ms/epoch - 6ms/step\n",
            "Epoch 155/300\n",
            "65/65 - 0s - loss: 0.0393 - val_loss: 0.1202 - 367ms/epoch - 6ms/step\n",
            "Epoch 156/300\n",
            "65/65 - 0s - loss: 0.0366 - val_loss: 0.1225 - 382ms/epoch - 6ms/step\n",
            "Epoch 157/300\n",
            "65/65 - 0s - loss: 0.0375 - val_loss: 0.1121 - 331ms/epoch - 5ms/step\n",
            "Epoch 158/300\n",
            "65/65 - 0s - loss: 0.0344 - val_loss: 0.1140 - 251ms/epoch - 4ms/step\n",
            "Epoch 159/300\n",
            "65/65 - 0s - loss: 0.0346 - val_loss: 0.1384 - 299ms/epoch - 5ms/step\n",
            "Epoch 160/300\n",
            "65/65 - 0s - loss: 0.0368 - val_loss: 0.1074 - 242ms/epoch - 4ms/step\n",
            "Epoch 161/300\n",
            "65/65 - 0s - loss: 0.0336 - val_loss: 0.1129 - 243ms/epoch - 4ms/step\n",
            "Epoch 162/300\n",
            "65/65 - 0s - loss: 0.0380 - val_loss: 0.1329 - 255ms/epoch - 4ms/step\n",
            "Epoch 163/300\n",
            "65/65 - 0s - loss: 0.0414 - val_loss: 0.1329 - 296ms/epoch - 5ms/step\n",
            "Epoch 164/300\n",
            "65/65 - 0s - loss: 0.0422 - val_loss: 0.1213 - 249ms/epoch - 4ms/step\n",
            "Epoch 165/300\n",
            "65/65 - 0s - loss: 0.0325 - val_loss: 0.1196 - 243ms/epoch - 4ms/step\n",
            "Epoch 166/300\n",
            "65/65 - 0s - loss: 0.0316 - val_loss: 0.1151 - 247ms/epoch - 4ms/step\n",
            "Epoch 167/300\n",
            "65/65 - 0s - loss: 0.0347 - val_loss: 0.1156 - 261ms/epoch - 4ms/step\n",
            "Epoch 168/300\n",
            "65/65 - 0s - loss: 0.0332 - val_loss: 0.1176 - 277ms/epoch - 4ms/step\n",
            "Epoch 169/300\n",
            "65/65 - 0s - loss: 0.0319 - val_loss: 0.1159 - 252ms/epoch - 4ms/step\n",
            "Epoch 170/300\n",
            "65/65 - 0s - loss: 0.0312 - val_loss: 0.1344 - 300ms/epoch - 5ms/step\n",
            "Epoch 171/300\n",
            "65/65 - 0s - loss: 0.0413 - val_loss: 0.1142 - 284ms/epoch - 4ms/step\n",
            "Epoch 172/300\n",
            "65/65 - 0s - loss: 0.0355 - val_loss: 0.1174 - 250ms/epoch - 4ms/step\n",
            "Epoch 173/300\n",
            "65/65 - 0s - loss: 0.0302 - val_loss: 0.1153 - 282ms/epoch - 4ms/step\n",
            "Epoch 174/300\n",
            "65/65 - 0s - loss: 0.0301 - val_loss: 0.1108 - 264ms/epoch - 4ms/step\n",
            "Epoch 175/300\n",
            "65/65 - 0s - loss: 0.0326 - val_loss: 0.1126 - 246ms/epoch - 4ms/step\n",
            "Epoch 176/300\n",
            "65/65 - 0s - loss: 0.0341 - val_loss: 0.1180 - 241ms/epoch - 4ms/step\n",
            "Epoch 177/300\n",
            "65/65 - 0s - loss: 0.0363 - val_loss: 0.1332 - 281ms/epoch - 4ms/step\n",
            "Epoch 178/300\n",
            "65/65 - 0s - loss: 0.0327 - val_loss: 0.1357 - 271ms/epoch - 4ms/step\n",
            "Epoch 179/300\n",
            "65/65 - 0s - loss: 0.0332 - val_loss: 0.1174 - 247ms/epoch - 4ms/step\n",
            "Epoch 180/300\n",
            "65/65 - 0s - loss: 0.0317 - val_loss: 0.1240 - 252ms/epoch - 4ms/step\n",
            "Epoch 181/300\n",
            "65/65 - 0s - loss: 0.0303 - val_loss: 0.1151 - 296ms/epoch - 5ms/step\n",
            "Epoch 182/300\n",
            "65/65 - 0s - loss: 0.0339 - val_loss: 0.1118 - 265ms/epoch - 4ms/step\n",
            "Epoch 183/300\n",
            "65/65 - 0s - loss: 0.0330 - val_loss: 0.1160 - 291ms/epoch - 4ms/step\n",
            "Epoch 184/300\n",
            "65/65 - 0s - loss: 0.0310 - val_loss: 0.1137 - 257ms/epoch - 4ms/step\n",
            "Epoch 185/300\n",
            "65/65 - 0s - loss: 0.0301 - val_loss: 0.1062 - 261ms/epoch - 4ms/step\n",
            "Epoch 186/300\n",
            "65/65 - 0s - loss: 0.0312 - val_loss: 0.1071 - 245ms/epoch - 4ms/step\n",
            "Epoch 187/300\n",
            "65/65 - 0s - loss: 0.0304 - val_loss: 0.1136 - 245ms/epoch - 4ms/step\n",
            "Epoch 188/300\n",
            "65/65 - 0s - loss: 0.0294 - val_loss: 0.1189 - 255ms/epoch - 4ms/step\n",
            "Epoch 189/300\n",
            "65/65 - 0s - loss: 0.0307 - val_loss: 0.1058 - 260ms/epoch - 4ms/step\n",
            "Epoch 190/300\n",
            "65/65 - 0s - loss: 0.0324 - val_loss: 0.1165 - 251ms/epoch - 4ms/step\n",
            "Epoch 191/300\n",
            "65/65 - 0s - loss: 0.0289 - val_loss: 0.1143 - 245ms/epoch - 4ms/step\n",
            "Epoch 192/300\n",
            "65/65 - 0s - loss: 0.0291 - val_loss: 0.1158 - 274ms/epoch - 4ms/step\n",
            "Epoch 193/300\n",
            "65/65 - 0s - loss: 0.0307 - val_loss: 0.1124 - 264ms/epoch - 4ms/step\n",
            "Epoch 194/300\n",
            "65/65 - 0s - loss: 0.0305 - val_loss: 0.1083 - 254ms/epoch - 4ms/step\n",
            "Epoch 195/300\n",
            "65/65 - 0s - loss: 0.0286 - val_loss: 0.1089 - 396ms/epoch - 6ms/step\n",
            "Epoch 196/300\n",
            "65/65 - 0s - loss: 0.0272 - val_loss: 0.1083 - 411ms/epoch - 6ms/step\n",
            "Epoch 197/300\n",
            "65/65 - 0s - loss: 0.0274 - val_loss: 0.1112 - 364ms/epoch - 6ms/step\n",
            "Epoch 198/300\n",
            "65/65 - 0s - loss: 0.0291 - val_loss: 0.1234 - 362ms/epoch - 6ms/step\n",
            "Epoch 199/300\n",
            "65/65 - 0s - loss: 0.0312 - val_loss: 0.1045 - 380ms/epoch - 6ms/step\n",
            "Epoch 200/300\n",
            "65/65 - 0s - loss: 0.0360 - val_loss: 0.1136 - 448ms/epoch - 7ms/step\n",
            "Epoch 201/300\n",
            "65/65 - 0s - loss: 0.0286 - val_loss: 0.1015 - 440ms/epoch - 7ms/step\n",
            "Epoch 202/300\n",
            "65/65 - 0s - loss: 0.0274 - val_loss: 0.1219 - 375ms/epoch - 6ms/step\n",
            "Epoch 203/300\n",
            "65/65 - 0s - loss: 0.0293 - val_loss: 0.1076 - 430ms/epoch - 7ms/step\n",
            "Epoch 204/300\n",
            "65/65 - 0s - loss: 0.0270 - val_loss: 0.1103 - 349ms/epoch - 5ms/step\n",
            "Epoch 205/300\n",
            "65/65 - 0s - loss: 0.0291 - val_loss: 0.1134 - 288ms/epoch - 4ms/step\n",
            "Epoch 206/300\n",
            "65/65 - 0s - loss: 0.0367 - val_loss: 0.1022 - 268ms/epoch - 4ms/step\n",
            "Epoch 207/300\n",
            "65/65 - 0s - loss: 0.0281 - val_loss: 0.1051 - 252ms/epoch - 4ms/step\n",
            "Epoch 208/300\n",
            "65/65 - 0s - loss: 0.0279 - val_loss: 0.1084 - 252ms/epoch - 4ms/step\n",
            "Epoch 209/300\n",
            "65/65 - 0s - loss: 0.0325 - val_loss: 0.1083 - 245ms/epoch - 4ms/step\n",
            "Epoch 210/300\n",
            "65/65 - 0s - loss: 0.0299 - val_loss: 0.1043 - 252ms/epoch - 4ms/step\n",
            "Epoch 211/300\n",
            "65/65 - 0s - loss: 0.0265 - val_loss: 0.1121 - 248ms/epoch - 4ms/step\n",
            "Epoch 212/300\n",
            "65/65 - 0s - loss: 0.0286 - val_loss: 0.1151 - 293ms/epoch - 5ms/step\n",
            "Epoch 213/300\n",
            "65/65 - 0s - loss: 0.0268 - val_loss: 0.1021 - 291ms/epoch - 4ms/step\n",
            "Epoch 214/300\n",
            "65/65 - 0s - loss: 0.0253 - val_loss: 0.1166 - 245ms/epoch - 4ms/step\n",
            "Epoch 215/300\n",
            "65/65 - 0s - loss: 0.0246 - val_loss: 0.1173 - 249ms/epoch - 4ms/step\n",
            "Epoch 216/300\n",
            "65/65 - 0s - loss: 0.0252 - val_loss: 0.1107 - 255ms/epoch - 4ms/step\n",
            "Epoch 217/300\n",
            "65/65 - 0s - loss: 0.0273 - val_loss: 0.1191 - 258ms/epoch - 4ms/step\n",
            "Epoch 218/300\n",
            "65/65 - 0s - loss: 0.0259 - val_loss: 0.1174 - 251ms/epoch - 4ms/step\n",
            "Epoch 219/300\n",
            "65/65 - 0s - loss: 0.0250 - val_loss: 0.1068 - 253ms/epoch - 4ms/step\n",
            "Epoch 220/300\n",
            "65/65 - 0s - loss: 0.0251 - val_loss: 0.1077 - 249ms/epoch - 4ms/step\n",
            "Epoch 221/300\n",
            "65/65 - 0s - loss: 0.0265 - val_loss: 0.1091 - 260ms/epoch - 4ms/step\n",
            "Epoch 222/300\n",
            "65/65 - 0s - loss: 0.0257 - val_loss: 0.1113 - 290ms/epoch - 4ms/step\n",
            "Epoch 223/300\n",
            "65/65 - 0s - loss: 0.0266 - val_loss: 0.1157 - 260ms/epoch - 4ms/step\n",
            "Epoch 224/300\n",
            "65/65 - 0s - loss: 0.0265 - val_loss: 0.1163 - 294ms/epoch - 5ms/step\n",
            "Epoch 225/300\n",
            "65/65 - 0s - loss: 0.0257 - val_loss: 0.1152 - 290ms/epoch - 4ms/step\n",
            "Epoch 226/300\n",
            "65/65 - 0s - loss: 0.0243 - val_loss: 0.1104 - 247ms/epoch - 4ms/step\n",
            "Epoch 227/300\n",
            "65/65 - 0s - loss: 0.0255 - val_loss: 0.1140 - 304ms/epoch - 5ms/step\n",
            "Epoch 228/300\n",
            "65/65 - 0s - loss: 0.0249 - val_loss: 0.1329 - 250ms/epoch - 4ms/step\n",
            "Epoch 229/300\n",
            "65/65 - 0s - loss: 0.0278 - val_loss: 0.1035 - 255ms/epoch - 4ms/step\n",
            "Epoch 230/300\n",
            "65/65 - 0s - loss: 0.0240 - val_loss: 0.1139 - 245ms/epoch - 4ms/step\n",
            "Epoch 231/300\n",
            "65/65 - 0s - loss: 0.0254 - val_loss: 0.1129 - 247ms/epoch - 4ms/step\n",
            "Epoch 232/300\n",
            "65/65 - 0s - loss: 0.0237 - val_loss: 0.1174 - 286ms/epoch - 4ms/step\n",
            "Epoch 233/300\n",
            "65/65 - 0s - loss: 0.0214 - val_loss: 0.1085 - 261ms/epoch - 4ms/step\n",
            "Epoch 234/300\n",
            "65/65 - 0s - loss: 0.0228 - val_loss: 0.1177 - 294ms/epoch - 5ms/step\n",
            "Epoch 235/300\n",
            "65/65 - 0s - loss: 0.0233 - val_loss: 0.1180 - 254ms/epoch - 4ms/step\n",
            "Epoch 236/300\n",
            "65/65 - 0s - loss: 0.0223 - val_loss: 0.1086 - 251ms/epoch - 4ms/step\n",
            "Epoch 237/300\n",
            "65/65 - 0s - loss: 0.0244 - val_loss: 0.1203 - 252ms/epoch - 4ms/step\n",
            "Epoch 238/300\n",
            "65/65 - 0s - loss: 0.0239 - val_loss: 0.1046 - 303ms/epoch - 5ms/step\n",
            "Epoch 239/300\n",
            "65/65 - 0s - loss: 0.0253 - val_loss: 0.1121 - 260ms/epoch - 4ms/step\n",
            "Epoch 240/300\n",
            "65/65 - 0s - loss: 0.0244 - val_loss: 0.1067 - 292ms/epoch - 4ms/step\n",
            "Epoch 241/300\n",
            "65/65 - 0s - loss: 0.0241 - val_loss: 0.1156 - 333ms/epoch - 5ms/step\n",
            "Epoch 242/300\n",
            "65/65 - 0s - loss: 0.0257 - val_loss: 0.1148 - 401ms/epoch - 6ms/step\n",
            "Epoch 243/300\n",
            "65/65 - 0s - loss: 0.0258 - val_loss: 0.1082 - 421ms/epoch - 6ms/step\n",
            "Epoch 244/300\n",
            "65/65 - 0s - loss: 0.0274 - val_loss: 0.1110 - 407ms/epoch - 6ms/step\n",
            "Epoch 245/300\n",
            "65/65 - 0s - loss: 0.0244 - val_loss: 0.1262 - 396ms/epoch - 6ms/step\n",
            "Epoch 246/300\n",
            "65/65 - 0s - loss: 0.0250 - val_loss: 0.1173 - 398ms/epoch - 6ms/step\n",
            "Epoch 247/300\n",
            "65/65 - 0s - loss: 0.0273 - val_loss: 0.1075 - 406ms/epoch - 6ms/step\n",
            "Epoch 248/300\n",
            "65/65 - 0s - loss: 0.0241 - val_loss: 0.1306 - 347ms/epoch - 5ms/step\n",
            "Epoch 249/300\n",
            "65/65 - 0s - loss: 0.0249 - val_loss: 0.1181 - 370ms/epoch - 6ms/step\n",
            "Epoch 250/300\n",
            "65/65 - 0s - loss: 0.0218 - val_loss: 0.1089 - 422ms/epoch - 6ms/step\n",
            "Epoch 251/300\n",
            "65/65 - 0s - loss: 0.0214 - val_loss: 0.1112 - 245ms/epoch - 4ms/step\n",
            "Epoch 252/300\n",
            "65/65 - 0s - loss: 0.0202 - val_loss: 0.1101 - 280ms/epoch - 4ms/step\n",
            "Epoch 253/300\n",
            "65/65 - 0s - loss: 0.0204 - val_loss: 0.1123 - 257ms/epoch - 4ms/step\n",
            "Epoch 254/300\n",
            "65/65 - 0s - loss: 0.0230 - val_loss: 0.1200 - 256ms/epoch - 4ms/step\n",
            "Epoch 255/300\n",
            "65/65 - 0s - loss: 0.0259 - val_loss: 0.1307 - 242ms/epoch - 4ms/step\n",
            "Epoch 256/300\n",
            "65/65 - 0s - loss: 0.0254 - val_loss: 0.1092 - 284ms/epoch - 4ms/step\n",
            "Epoch 257/300\n",
            "65/65 - 0s - loss: 0.0222 - val_loss: 0.1278 - 251ms/epoch - 4ms/step\n",
            "Epoch 258/300\n",
            "65/65 - 0s - loss: 0.0227 - val_loss: 0.1105 - 247ms/epoch - 4ms/step\n",
            "Epoch 259/300\n",
            "65/65 - 0s - loss: 0.0197 - val_loss: 0.1146 - 282ms/epoch - 4ms/step\n",
            "Epoch 260/300\n",
            "65/65 - 0s - loss: 0.0240 - val_loss: 0.1142 - 248ms/epoch - 4ms/step\n",
            "Epoch 261/300\n",
            "65/65 - 0s - loss: 0.0198 - val_loss: 0.1134 - 250ms/epoch - 4ms/step\n",
            "Epoch 262/300\n",
            "65/65 - 0s - loss: 0.0205 - val_loss: 0.1198 - 280ms/epoch - 4ms/step\n",
            "Epoch 263/300\n",
            "65/65 - 0s - loss: 0.0204 - val_loss: 0.1120 - 285ms/epoch - 4ms/step\n",
            "Epoch 264/300\n",
            "65/65 - 0s - loss: 0.0202 - val_loss: 0.1050 - 251ms/epoch - 4ms/step\n",
            "Epoch 265/300\n",
            "65/65 - 0s - loss: 0.0231 - val_loss: 0.1121 - 292ms/epoch - 4ms/step\n",
            "Epoch 266/300\n",
            "65/65 - 0s - loss: 0.0228 - val_loss: 0.1082 - 243ms/epoch - 4ms/step\n",
            "Epoch 267/300\n",
            "65/65 - 0s - loss: 0.0212 - val_loss: 0.1067 - 253ms/epoch - 4ms/step\n",
            "Epoch 268/300\n",
            "65/65 - 0s - loss: 0.0232 - val_loss: 0.1150 - 259ms/epoch - 4ms/step\n",
            "Epoch 269/300\n",
            "65/65 - 0s - loss: 0.0239 - val_loss: 0.1125 - 283ms/epoch - 4ms/step\n",
            "Epoch 270/300\n",
            "65/65 - 0s - loss: 0.0229 - val_loss: 0.1090 - 246ms/epoch - 4ms/step\n",
            "Epoch 271/300\n",
            "65/65 - 0s - loss: 0.0189 - val_loss: 0.1119 - 247ms/epoch - 4ms/step\n",
            "Epoch 272/300\n",
            "65/65 - 0s - loss: 0.0245 - val_loss: 0.1179 - 264ms/epoch - 4ms/step\n",
            "Epoch 273/300\n",
            "65/65 - 0s - loss: 0.0222 - val_loss: 0.1129 - 287ms/epoch - 4ms/step\n",
            "Epoch 274/300\n",
            "65/65 - 0s - loss: 0.0209 - val_loss: 0.1067 - 246ms/epoch - 4ms/step\n",
            "Epoch 275/300\n",
            "65/65 - 0s - loss: 0.0205 - val_loss: 0.1083 - 253ms/epoch - 4ms/step\n",
            "Epoch 276/300\n",
            "65/65 - 0s - loss: 0.0200 - val_loss: 0.1324 - 262ms/epoch - 4ms/step\n",
            "Epoch 277/300\n",
            "65/65 - 0s - loss: 0.0206 - val_loss: 0.1083 - 246ms/epoch - 4ms/step\n",
            "Epoch 278/300\n",
            "65/65 - 0s - loss: 0.0201 - val_loss: 0.1112 - 248ms/epoch - 4ms/step\n",
            "Epoch 279/300\n",
            "65/65 - 0s - loss: 0.0209 - val_loss: 0.1185 - 285ms/epoch - 4ms/step\n",
            "Epoch 280/300\n",
            "65/65 - 0s - loss: 0.0221 - val_loss: 0.1065 - 288ms/epoch - 4ms/step\n",
            "Epoch 281/300\n",
            "65/65 - 0s - loss: 0.0234 - val_loss: 0.1107 - 285ms/epoch - 4ms/step\n",
            "Epoch 282/300\n",
            "65/65 - 0s - loss: 0.0192 - val_loss: 0.1082 - 254ms/epoch - 4ms/step\n",
            "Epoch 283/300\n",
            "65/65 - 0s - loss: 0.0211 - val_loss: 0.1048 - 272ms/epoch - 4ms/step\n",
            "Epoch 284/300\n",
            "65/65 - 0s - loss: 0.0197 - val_loss: 0.1252 - 265ms/epoch - 4ms/step\n",
            "Epoch 285/300\n",
            "65/65 - 0s - loss: 0.0193 - val_loss: 0.1061 - 253ms/epoch - 4ms/step\n",
            "Epoch 286/300\n",
            "65/65 - 0s - loss: 0.0166 - val_loss: 0.1124 - 247ms/epoch - 4ms/step\n",
            "Epoch 287/300\n",
            "65/65 - 0s - loss: 0.0180 - val_loss: 0.1118 - 267ms/epoch - 4ms/step\n",
            "Epoch 288/300\n",
            "65/65 - 0s - loss: 0.0183 - val_loss: 0.1198 - 402ms/epoch - 6ms/step\n",
            "Epoch 289/300\n",
            "65/65 - 0s - loss: 0.0208 - val_loss: 0.1220 - 383ms/epoch - 6ms/step\n",
            "Epoch 290/300\n",
            "65/65 - 0s - loss: 0.0187 - val_loss: 0.1084 - 378ms/epoch - 6ms/step\n",
            "Epoch 291/300\n",
            "65/65 - 0s - loss: 0.0193 - val_loss: 0.1158 - 393ms/epoch - 6ms/step\n",
            "Epoch 292/300\n",
            "65/65 - 0s - loss: 0.0203 - val_loss: 0.1083 - 398ms/epoch - 6ms/step\n",
            "Epoch 293/300\n",
            "65/65 - 0s - loss: 0.0173 - val_loss: 0.1179 - 377ms/epoch - 6ms/step\n",
            "Epoch 294/300\n",
            "65/65 - 0s - loss: 0.0181 - val_loss: 0.1086 - 392ms/epoch - 6ms/step\n",
            "Epoch 295/300\n",
            "65/65 - 0s - loss: 0.0181 - val_loss: 0.1143 - 414ms/epoch - 6ms/step\n",
            "Epoch 296/300\n",
            "65/65 - 0s - loss: 0.0181 - val_loss: 0.1073 - 407ms/epoch - 6ms/step\n",
            "Epoch 297/300\n",
            "65/65 - 0s - loss: 0.0175 - val_loss: 0.1196 - 307ms/epoch - 5ms/step\n",
            "Epoch 298/300\n",
            "65/65 - 0s - loss: 0.0201 - val_loss: 0.1235 - 262ms/epoch - 4ms/step\n",
            "Epoch 299/300\n",
            "65/65 - 0s - loss: 0.0198 - val_loss: 0.1057 - 252ms/epoch - 4ms/step\n",
            "Epoch 300/300\n",
            "65/65 - 0s - loss: 0.0213 - val_loss: 0.1101 - 260ms/epoch - 4ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fd251e62230>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build the model\n",
        "hidden_layer_neurals = 64\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(hidden_layer_neurals, activation='relu', input_shape=(10,)),\n",
        "    tf.keras.layers.Dense(hidden_layer_neurals, activation='relu'),\n",
        "    tf.keras.layers.Dense(hidden_layer_neurals, activation='relu'),\n",
        "    tf.keras.layers.Dense(hidden_layer_neurals, activation='relu'),\n",
        "    tf.keras.layers.Dense(hidden_layer_neurals, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "# Define your desired learning rate\n",
        "learning_rate = 2e-4\n",
        "adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=adam_optimizer, loss='mean_squared_error')\n",
        "\n",
        "# # Train the model\n",
        "model.fit(X_train_minmax, y_train, validation_split=0.15, epochs=300, batch_size=32, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hizV8PYg0Zod",
        "outputId": "e8dd3549-5706-4087-812a-414e9a492cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0998\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "\n",
        "test_loss = model.evaluate(X_test_minmax, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ahR0Q4b_b_4",
        "outputId": "040285a8-1f99-4c5f-e32a-74976258cfc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 3ms/step\n",
            "True: 3.0178682662762513, Predicted: 2.9539005756378174\n",
            "True: 0.34011344442588587, Predicted: 0.462912380695343\n",
            "True: 0.4888605092503627, Predicted: 0.46087661385536194\n",
            "True: 0.5187183288106738, Predicted: 0.5197278261184692\n",
            "True: 3.839619957911904, Predicted: 4.492387294769287\n",
            "True: 0.5437148188748948, Predicted: 0.5917494297027588\n",
            "True: 1.8904210069442406, Predicted: 1.8316186666488647\n",
            "True: 0.16692362756604606, Predicted: 0.2620367109775543\n",
            "True: 0.6165579585404503, Predicted: 0.6703601479530334\n",
            "True: 0.4256696180779985, Predicted: 1.259719967842102\n",
            "True: 0.2265400860152856, Predicted: -0.07402719557285309\n",
            "True: 0.3635165964266504, Predicted: 0.457239031791687\n",
            "True: 3.1286093587060138, Predicted: 3.123720645904541\n",
            "True: 0.37906718659229477, Predicted: 0.37145134806632996\n",
            "True: 0.5592932747010888, Predicted: 0.5612027049064636\n",
            "True: 0.9191880242335625, Predicted: 1.0597026348114014\n",
            "True: 0.5398662690392555, Predicted: 0.5737130045890808\n",
            "True: 0.947616845543993, Predicted: 0.8408961892127991\n",
            "True: 0.5976291318793855, Predicted: 0.62075275182724\n",
            "True: 0.5444679227980618, Predicted: 0.5658093690872192\n",
            "True: 0.36442501587431986, Predicted: 0.2361379861831665\n",
            "True: 0.3213966364663681, Predicted: 0.4025286138057709\n",
            "True: 0.39719217855370564, Predicted: 0.42751574516296387\n",
            "True: 0.46339406881878753, Predicted: 0.5141991972923279\n",
            "True: 0.4998711346774508, Predicted: 0.4973873496055603\n",
            "True: 0.6621818370389729, Predicted: 0.5760633945465088\n",
            "True: 0.3466140390859927, Predicted: 0.24018928408622742\n",
            "True: 0.5304353586542719, Predicted: 0.6755796074867249\n",
            "True: 0.6349281278131933, Predicted: 0.6055775284767151\n",
            "True: 4.009078370790966, Predicted: 0.6365982294082642\n",
            "True: 0.15693528156527262, Predicted: 0.13684457540512085\n",
            "True: 0.005760578790451412, Predicted: 0.1725917011499405\n",
            "True: 0.6012484725763904, Predicted: 0.5712727308273315\n",
            "True: 2.550113897264019, Predicted: 2.837585926055908\n",
            "True: 0.5979547634140958, Predicted: 0.4567400813102722\n",
            "True: 0.5147429939518088, Predicted: 0.49170899391174316\n",
            "True: 0.5489264960751795, Predicted: 0.7236393094062805\n",
            "True: 0.4418033158814417, Predicted: 0.5043516755104065\n",
            "True: 0.4124673847122135, Predicted: 0.6174694299697876\n",
            "True: 0.40102232178488234, Predicted: 0.3617843985557556\n",
            "True: 0.42481285414657927, Predicted: 0.24945449829101562\n",
            "True: 0.32066235380614466, Predicted: 0.22441759705543518\n",
            "True: 0.5114085626179508, Predicted: 0.5618292093276978\n",
            "True: 2.8078526311468717, Predicted: 3.1554415225982666\n",
            "True: 0.1745484529195676, Predicted: 0.3025878667831421\n",
            "True: 3.285942394938939, Predicted: 2.981917381286621\n",
            "True: 0.43155547391679716, Predicted: 0.4759776294231415\n",
            "True: 0.5457043260666736, Predicted: 0.5801572799682617\n",
            "True: 3.7029384353296853, Predicted: 2.9861161708831787\n",
            "True: 0.47613036038078593, Predicted: 0.4169211685657501\n",
            "True: 3.902199776495614, Predicted: 4.558155536651611\n",
            "True: 1.8334584544155872, Predicted: 2.377272844314575\n",
            "True: 0.26580122325567723, Predicted: -0.02053128555417061\n",
            "True: 0.5963953520268879, Predicted: 0.67310631275177\n",
            "True: 0.5608153560764636, Predicted: 0.6619210839271545\n",
            "True: 0.8222657677885976, Predicted: 1.0848169326782227\n",
            "True: 0.2652822699803816, Predicted: 0.3244360685348511\n",
            "True: 0.5055572379073607, Predicted: 0.4382801055908203\n",
            "True: 0.5663086327461045, Predicted: 0.507904589176178\n",
            "True: 0.3499933377620261, Predicted: 0.4118845462799072\n",
            "True: 3.114378859658725, Predicted: 3.7408061027526855\n",
            "True: 0.6456398873024529, Predicted: 0.6451042890548706\n",
            "True: 0.3997232724780272, Predicted: 0.28333190083503723\n",
            "True: 0.5703849287756964, Predicted: 0.7441393733024597\n",
            "True: 0.6103283617523672, Predicted: 0.7054727673530579\n",
            "True: 0.9966142010332308, Predicted: 1.2253410816192627\n",
            "True: 0.9691263352627072, Predicted: 1.1038275957107544\n",
            "True: 0.42264960442993743, Predicted: 0.47204020619392395\n",
            "True: 0.5447169992602588, Predicted: 0.26469987630844116\n",
            "True: 0.5752680159344936, Predicted: 0.6169838905334473\n",
            "True: 0.003632533849790467, Predicted: 0.3600457012653351\n",
            "True: 0.006014552492107068, Predicted: 0.050957705825567245\n",
            "True: 0.40956650398751326, Predicted: 0.4964238405227661\n",
            "True: 0.5047437795579498, Predicted: 0.6285306811332703\n",
            "True: 0.5158447086637097, Predicted: 1.3403353691101074\n",
            "True: 0.6887522842245746, Predicted: 0.9127582907676697\n",
            "True: 0.5860988329210595, Predicted: 0.4507445991039276\n",
            "True: 0.5739638359127148, Predicted: 0.6706158518791199\n",
            "True: 0.31614828853927457, Predicted: 0.34707942605018616\n",
            "True: 0.43838793637638185, Predicted: 0.42959946393966675\n",
            "True: 0.5827640311558833, Predicted: 0.535490095615387\n",
            "True: 0.4629608001607466, Predicted: 0.5495949387550354\n",
            "True: 0.5062471112686066, Predicted: 0.5212545990943909\n",
            "True: 0.5760668643206351, Predicted: 0.5818135738372803\n",
            "True: 0.5146541515916518, Predicted: 0.4466070830821991\n",
            "True: 0.630198244235264, Predicted: 0.37563660740852356\n",
            "True: 3.097019043293701, Predicted: 2.9627459049224854\n",
            "True: 1.1693592383058196, Predicted: 1.0876502990722656\n",
            "True: 0.5004326371553228, Predicted: 0.9546458721160889\n",
            "True: 0.5396738572860376, Predicted: 1.3187336921691895\n",
            "True: 0.493212953583548, Predicted: 0.391147255897522\n",
            "True: 0.5291180080024881, Predicted: 0.6199533343315125\n",
            "True: 0.4811047148332485, Predicted: 0.6255080103874207\n",
            "True: 0.3820149566945108, Predicted: 0.3698756694793701\n",
            "True: 0.5560640077799889, Predicted: 0.45821520686149597\n",
            "True: 0.49995782287342827, Predicted: 0.6277008652687073\n",
            "True: 0.6043538411393561, Predicted: 0.5707365274429321\n",
            "True: 0.265581178327119, Predicted: 0.34313732385635376\n",
            "True: 0.4766963441986063, Predicted: 0.3465057909488678\n",
            "True: 0.5674555867814141, Predicted: 0.6158217191696167\n",
            "True: 0.6528894864365454, Predicted: 0.7391430735588074\n",
            "True: 0.06706591656360081, Predicted: 0.3187830448150635\n",
            "True: 0.5905983821662687, Predicted: 0.6013023257255554\n",
            "True: 0.44724779891869043, Predicted: 0.34679239988327026\n",
            "True: 0.004935881579399667, Predicted: 0.18681921064853668\n",
            "True: 0.32330762392429957, Predicted: 0.3987836539745331\n",
            "True: 0.5271019720593643, Predicted: 1.0329885482788086\n",
            "True: 0.6348981782513815, Predicted: 0.420523464679718\n",
            "True: 0.48595428075306696, Predicted: 0.5374298095703125\n",
            "True: 0.5424922242989205, Predicted: 0.7890400290489197\n",
            "True: 0.592971588922771, Predicted: 0.683635950088501\n",
            "True: 0.5586420825204634, Predicted: 0.5279372334480286\n",
            "True: 1.1142485820771038, Predicted: 0.8150177597999573\n",
            "True: 0.3352893391326924, Predicted: 0.33351796865463257\n",
            "True: 3.045423356890952, Predicted: 3.0899369716644287\n",
            "True: 0.5127106140345801, Predicted: 0.3356059491634369\n",
            "True: 0.5584410769679805, Predicted: 0.7528403401374817\n",
            "True: 0.572191263552938, Predicted: 0.59011310338974\n",
            "True: 0.5063630744781207, Predicted: 0.1659659743309021\n",
            "True: 0.5011340068668914, Predicted: 0.8975936770439148\n",
            "True: 0.5525271771455922, Predicted: 0.50509113073349\n",
            "True: 0.25116046661893104, Predicted: 0.012560289353132248\n",
            "True: 0.35531697135750884, Predicted: 0.4086328148841858\n",
            "True: 0.5698185087828924, Predicted: 0.7220752835273743\n",
            "True: 0.4539330672596794, Predicted: 0.7379298806190491\n",
            "True: 0.41705718636424377, Predicted: 0.3625463545322418\n",
            "True: 0.454809004385321, Predicted: 0.6356999278068542\n",
            "True: 0.5090534486983491, Predicted: 0.5823807120323181\n",
            "True: 0.5413102434580368, Predicted: 0.6418117880821228\n",
            "True: 0.007451671921194336, Predicted: 0.38195133209228516\n",
            "True: 0.5439178084168016, Predicted: 0.5966451168060303\n",
            "True: 2.1704656577845727, Predicted: 2.427945613861084\n",
            "True: 0.5671899479207911, Predicted: 0.48613500595092773\n",
            "True: 0.455413790206956, Predicted: 0.42707186937332153\n",
            "True: 0.44365758690689494, Predicted: 0.42808517813682556\n",
            "True: 0.4119664524547543, Predicted: 0.4399811327457428\n",
            "True: 0.5350664435014026, Predicted: 0.5806378126144409\n",
            "True: 0.6187307326434571, Predicted: 0.6631409525871277\n",
            "True: 1.7382992658786716, Predicted: 0.7405110597610474\n",
            "True: 0.5285594844504782, Predicted: 0.5960707664489746\n",
            "True: 0.5633012271351573, Predicted: 0.5418705344200134\n",
            "True: 0.5142505474316261, Predicted: 0.554799497127533\n",
            "True: 0.06415932260159048, Predicted: 0.15703056752681732\n",
            "True: 0.5658981640144848, Predicted: 0.5110117197036743\n",
            "True: 0.5559150979793952, Predicted: 0.4799751043319702\n",
            "True: 1.7385343409415026, Predicted: 2.252531051635742\n",
            "True: 0.4235421969573525, Predicted: 0.33725109696388245\n",
            "True: 0.4764426598290648, Predicted: 0.6656543016433716\n",
            "True: 0.5734915972219224, Predicted: 0.7136861681938171\n",
            "True: 0.4318881193501102, Predicted: 0.44664841890335083\n",
            "True: 0.516779037386176, Predicted: 0.49445417523384094\n",
            "True: 0.46713493394744154, Predicted: 0.48183223605155945\n",
            "True: 0.5305347008950302, Predicted: 0.5470377206802368\n",
            "True: 0.35101555722338845, Predicted: 0.46402308344841003\n",
            "True: 0.5008671264664958, Predicted: 0.47887471318244934\n",
            "True: 0.7176217325329808, Predicted: 0.797036349773407\n",
            "True: 0.9444968281103342, Predicted: 1.8895798921585083\n",
            "True: 1.4905785195246772, Predicted: 1.3977735042572021\n",
            "True: 1.4952519904060333, Predicted: 2.4627814292907715\n",
            "True: 0.5254460199436873, Predicted: 0.6431744694709778\n",
            "True: 1.4217714929342395, Predicted: 1.453420877456665\n",
            "True: 0.5777936451179756, Predicted: 0.3108094334602356\n",
            "True: 0.4096657733642221, Predicted: 0.4442669153213501\n",
            "True: 3.4343159750066334, Predicted: 2.9885611534118652\n",
            "True: 0.33512677843290917, Predicted: 0.34576845169067383\n",
            "True: 0.46721815805939393, Predicted: 0.54450923204422\n",
            "True: 0.5770828951900283, Predicted: 0.06335997581481934\n",
            "True: 0.5960003815985626, Predicted: 0.6212850213050842\n",
            "True: 0.9753516128291212, Predicted: 1.2155399322509766\n",
            "True: 0.1278841712708297, Predicted: 0.2703092694282532\n",
            "True: 0.5413124374571668, Predicted: 0.6421092748641968\n",
            "True: 1.0012355580724621, Predicted: 1.1505988836288452\n",
            "True: 0.4728111656453197, Predicted: 0.47492700815200806\n",
            "True: 3.6424377950700384, Predicted: 3.231081247329712\n",
            "True: 0.26012978798270003, Predicted: 0.37859460711479187\n",
            "True: 0.4776504231547176, Predicted: 0.34254586696624756\n",
            "True: 1.2387867084696458, Predicted: 1.2799458503723145\n",
            "True: 0.3875632720594947, Predicted: 0.2995542883872986\n",
            "True: 0.4450743595453788, Predicted: 0.4462015628814697\n",
            "True: 0.3175030586512923, Predicted: 0.3062497079372406\n",
            "True: 0.08607564735048949, Predicted: 0.049877237528562546\n",
            "True: 0.47224947560154296, Predicted: 0.49522116780281067\n",
            "True: 0.3227890665664677, Predicted: 0.372336745262146\n",
            "True: 0.5076096522723875, Predicted: 0.6994267106056213\n",
            "True: 0.4874685363293496, Predicted: 0.3297099173069\n",
            "True: 0.16031446188002527, Predicted: 0.2771020233631134\n",
            "True: 0.4073320324309529, Predicted: 0.3266630470752716\n",
            "True: 0.05218723056727326, Predicted: 0.10866868495941162\n",
            "True: 0.5123546830578027, Predicted: 0.5209525227546692\n",
            "True: 0.5689551350333061, Predicted: 0.4493134319782257\n",
            "True: 0.31557608142525917, Predicted: 0.45667821168899536\n",
            "True: 0.5143174836404412, Predicted: 0.59116131067276\n",
            "True: 0.5512890776211052, Predicted: 0.49255669116973877\n",
            "True: 4.421803738678234, Predicted: 4.064488887786865\n",
            "True: 0.4164943808263621, Predicted: 0.4104132354259491\n",
            "True: 0.38950308069068074, Predicted: 0.23031337559223175\n",
            "True: 1.1776533542655794, Predicted: 2.0650713443756104\n",
            "True: 0.5619731189756225, Predicted: 0.58343505859375\n",
            "True: 0.5345842097282487, Predicted: 0.5963069796562195\n",
            "True: 3.0680036191982856, Predicted: 3.4633524417877197\n",
            "True: 1.2451634475197089, Predicted: 1.0217498540878296\n",
            "True: 0.5234595505983579, Predicted: 0.5143002271652222\n",
            "True: 0.8636330397856207, Predicted: 0.9322780966758728\n",
            "True: 0.6039996559713253, Predicted: 0.6676198840141296\n",
            "True: 0.5528056262635658, Predicted: 0.63300621509552\n",
            "True: 0.8822395418720328, Predicted: 0.9010770320892334\n",
            "True: 0.42073205896346955, Predicted: 0.5857909321784973\n",
            "True: 0.12608009626470387, Predicted: 0.0936090499162674\n",
            "True: 0.6496401050369173, Predicted: 0.5792980790138245\n",
            "True: 0.46980904567703546, Predicted: 0.5105956196784973\n",
            "True: 0.1517574065910375, Predicted: 0.10840663313865662\n",
            "True: 1.4010140667762543, Predicted: 1.2983124256134033\n",
            "True: 0.5677807306479226, Predicted: 0.7547587752342224\n",
            "True: 0.6251798771489965, Predicted: 0.6257231831550598\n",
            "True: 0.755938902511106, Predicted: 0.8404566645622253\n",
            "True: 0.6238999729143934, Predicted: 0.7027813196182251\n",
            "True: 0.43536542326035116, Predicted: 0.8267373442649841\n",
            "True: 0.41965237075550277, Predicted: 0.6343104839324951\n",
            "True: 0.3574600268477557, Predicted: 0.5213713645935059\n",
            "True: 2.829365370309198, Predicted: 1.7588860988616943\n",
            "True: 0.3881112828730292, Predicted: 0.33272895216941833\n",
            "True: 0.41673140467336933, Predicted: 0.5498165488243103\n",
            "True: 0.580261962568283, Predicted: 0.4775503873825073\n",
            "True: 0.4111934403599161, Predicted: 0.42959272861480713\n",
            "True: 0.7451181751056992, Predicted: 0.6180260181427002\n",
            "True: 0.46271758957111137, Predicted: 0.39372384548187256\n",
            "True: 0.5634257858230397, Predicted: 0.5816939473152161\n",
            "True: 0.8048141194348469, Predicted: 0.7501196265220642\n",
            "True: 0.5016212235471288, Predicted: 0.604103147983551\n",
            "True: 0.558375263402458, Predicted: 0.5326734781265259\n",
            "True: 0.3968243105282249, Predicted: 0.37454068660736084\n",
            "True: 0.495910371677825, Predicted: 0.553673267364502\n",
            "True: 1.6720428240775649, Predicted: 1.9031113386154175\n",
            "True: 0.3498680544181406, Predicted: 0.3556368052959442\n",
            "True: 0.0293155585160025, Predicted: 0.06608043611049652\n",
            "True: 0.005520389526246448, Predicted: 0.09794433414936066\n",
            "True: 0.5754547199987408, Predicted: 0.5452761054039001\n",
            "True: 0.5447100157507454, Predicted: 0.47571292519569397\n",
            "True: 0.3295297231155877, Predicted: 0.5407922267913818\n",
            "True: 0.4011206593634006, Predicted: 0.6660667657852173\n",
            "True: 0.12101355907246902, Predicted: 0.08617204427719116\n",
            "True: 0.41795147858528114, Predicted: 0.47655707597732544\n",
            "True: 1.1878806851389438, Predicted: 0.9182986617088318\n",
            "True: 1.2553674010002056, Predicted: 0.8372998237609863\n",
            "True: 0.0053716631470254, Predicted: 0.30239078402519226\n",
            "True: 0.16526243331380952, Predicted: 0.18518032133579254\n",
            "True: 0.38781247989496304, Predicted: 0.24155890941619873\n",
            "True: 1.7266619786850408, Predicted: 1.707505702972412\n",
            "True: 0.5574733933515582, Predicted: 0.5980014801025391\n",
            "True: 0.8250648732111642, Predicted: 0.7625746130943298\n",
            "True: 0.56966199787398, Predicted: 0.6347293257713318\n",
            "True: 0.5074450376062797, Predicted: 0.5525640845298767\n",
            "True: 0.49399247311342614, Predicted: 0.5635839104652405\n",
            "True: 0.6734506811993722, Predicted: 0.6877236366271973\n",
            "True: 0.36329870198927333, Predicted: 0.47406408190727234\n",
            "True: 0.3965031355849322, Predicted: 0.47640830278396606\n",
            "True: 0.6171975513739832, Predicted: 0.4141731262207031\n",
            "True: 0.586769788741315, Predicted: 0.5888215899467468\n",
            "True: 0.32870773395874064, Predicted: 0.6312790513038635\n",
            "True: 0.3301120582868426, Predicted: 0.20553943514823914\n",
            "True: 0.9212499555013718, Predicted: 0.9225639700889587\n",
            "True: 3.029963087332907, Predicted: 3.5760066509246826\n",
            "True: 0.6524319251569635, Predicted: 0.6549216508865356\n",
            "True: 0.27473797821356094, Predicted: 0.24306538701057434\n",
            "True: 0.5355594641258705, Predicted: 0.8089414238929749\n",
            "True: 0.32405875892246555, Predicted: 0.41860857605934143\n",
            "True: 0.6530161247548498, Predicted: 0.9331390857696533\n",
            "True: 0.4304205555075136, Predicted: 0.4366718828678131\n",
            "True: 0.3445888679950133, Predicted: 0.29275497794151306\n",
            "True: 0.8796005121390759, Predicted: 0.7782304286956787\n",
            "True: 0.9083751608952247, Predicted: 0.858556866645813\n",
            "True: 0.418327051991724, Predicted: 0.28758418560028076\n",
            "True: 0.19418604559285954, Predicted: 0.34131842851638794\n",
            "True: 0.505852034512233, Predicted: 0.5344070792198181\n",
            "True: 0.584108078490298, Predicted: 0.420865923166275\n",
            "True: 0.5722976627703975, Predicted: 0.5071088671684265\n",
            "True: 0.474457677905189, Predicted: 0.7380852699279785\n",
            "True: 0.40973611707906954, Predicted: 0.3452851176261902\n",
            "True: 0.5207149161149576, Predicted: 0.5359952449798584\n",
            "True: 0.5730028915591172, Predicted: 0.4432469308376312\n",
            "True: 0.004136710048815613, Predicted: 0.07042458653450012\n",
            "True: 2.2097515146182864, Predicted: 1.3689316511154175\n",
            "True: 0.32213555471655836, Predicted: 0.33392754197120667\n",
            "True: 0.8093768152981499, Predicted: 0.9432935118675232\n",
            "True: 2.22471054008744, Predicted: 2.481154680252075\n",
            "True: 0.705298910100876, Predicted: 1.1310395002365112\n",
            "True: 0.41342320292718787, Predicted: 0.2511448264122009\n",
            "True: 0.36438957123129845, Predicted: 0.3814355134963989\n",
            "True: 0.9199297464446872, Predicted: 0.5172074437141418\n",
            "True: 0.7846069305127013, Predicted: 0.8308830857276917\n",
            "True: 0.5807892519050166, Predicted: 0.6211600303649902\n",
            "True: 0.7813258864427746, Predicted: 2.337684392929077\n",
            "True: 2.9139098100623824, Predicted: 3.8942174911499023\n",
            "True: 0.27130634068841103, Predicted: 0.20105330646038055\n",
            "True: 2.8799042801008383, Predicted: 3.0207910537719727\n",
            "True: 0.6660771192030668, Predicted: 0.2619078755378723\n",
            "True: 0.5102619710246241, Predicted: 0.5878974199295044\n",
            "True: 0.0027958591789994337, Predicted: 0.6205277442932129\n",
            "True: 0.31302821000370795, Predicted: 0.3007577359676361\n",
            "True: 0.5626152229305537, Predicted: 0.710077702999115\n",
            "True: 0.6806247882133637, Predicted: 0.6372914910316467\n",
            "True: 0.19188758461207694, Predicted: -0.06347277760505676\n",
            "True: 0.6158579378830831, Predicted: 0.6467631459236145\n",
            "True: 0.6141722316858543, Predicted: 0.5234315991401672\n",
            "True: 0.5439247334644753, Predicted: 0.4557035267353058\n",
            "True: 1.5334786536375882, Predicted: 1.2309726476669312\n",
            "True: 1.153617433868687, Predicted: 0.9380078911781311\n",
            "True: 0.37312404859154724, Predicted: 0.42885541915893555\n",
            "True: 0.38717273365063765, Predicted: 0.8852762579917908\n",
            "True: 0.09505126522922763, Predicted: 0.2791026532649994\n",
            "True: 0.5303134591494891, Predicted: 0.6109424233436584\n",
            "True: 0.22389825633537375, Predicted: 0.23741382360458374\n",
            "True: 0.27090045512905503, Predicted: -0.057499561458826065\n",
            "True: 0.35807548903780806, Predicted: 0.4452512860298157\n",
            "True: 0.5458907931246092, Predicted: 0.5969387292861938\n",
            "True: 1.2106073688232672, Predicted: 2.0219767093658447\n",
            "True: 0.48286386629271866, Predicted: 0.38410767912864685\n",
            "True: 0.5177213748955252, Predicted: 0.5024383664131165\n",
            "True: 0.5821739186729791, Predicted: 0.7387872338294983\n",
            "True: 0.5121860107286177, Predicted: 0.47190535068511963\n",
            "True: 0.2998186066581788, Predicted: 0.5403624773025513\n",
            "True: 0.5489467101644766, Predicted: 0.7095787525177002\n",
            "True: 0.6071773030618068, Predicted: 0.9421486258506775\n",
            "True: 0.5978601267729612, Predicted: 0.6015687584877014\n",
            "True: 0.5841359603211388, Predicted: 0.5635645985603333\n",
            "True: 1.1415976883070755, Predicted: 1.2481006383895874\n",
            "True: 0.5582587594133436, Predicted: 0.5501449108123779\n",
            "True: 0.5747693500490207, Predicted: 0.6162101030349731\n",
            "True: 0.543369745920991, Predicted: 0.9105328917503357\n",
            "True: 3.992126885487972, Predicted: 3.880585193634033\n",
            "True: 0.39073461492401773, Predicted: 0.4012530446052551\n",
            "True: 0.6245771921809543, Predicted: 0.5454003810882568\n",
            "True: 1.318379824613935, Predicted: 1.1985719203948975\n",
            "True: 0.7276519770713993, Predicted: 0.6934264898300171\n",
            "True: 0.4255000186520082, Predicted: 0.45944106578826904\n",
            "True: 0.5141292637781116, Predicted: 0.45902779698371887\n",
            "True: 0.3988537303427012, Predicted: 0.4170469045639038\n",
            "True: 2.5961618216314393, Predicted: 2.1416726112365723\n",
            "True: 0.2833853495804853, Predicted: 0.3406858742237091\n",
            "True: 0.5539440687461469, Predicted: 0.5966160893440247\n",
            "True: 3.2672756981650375, Predicted: 3.0760951042175293\n",
            "True: 0.3667323113591937, Predicted: 0.5893036723136902\n",
            "True: 2.37562012452399, Predicted: 2.9311413764953613\n",
            "True: 0.34292130610077287, Predicted: 0.5292340517044067\n",
            "True: 1.063811137041237, Predicted: 1.6892685890197754\n",
            "True: 0.5528027975962169, Predicted: 0.49784231185913086\n",
            "True: 0.7286015586174522, Predicted: 0.7552935481071472\n",
            "True: 0.41785491969415484, Predicted: 0.6041886806488037\n",
            "True: 0.41551423149780414, Predicted: 0.47072672843933105\n",
            "True: 0.5424987741791034, Predicted: 0.6369004845619202\n",
            "True: 0.41012447014271836, Predicted: 0.5440858006477356\n",
            "True: 0.15405166191861103, Predicted: -0.12496200203895569\n",
            "True: 0.42123298223484995, Predicted: 0.37776878476142883\n",
            "True: 0.5116119762542414, Predicted: 0.4751417338848114\n",
            "True: 0.737193512085931, Predicted: 0.7946605086326599\n",
            "True: 0.49935446434116965, Predicted: 0.7587886452674866\n",
            "True: 0.6073158890189307, Predicted: 0.7517766356468201\n",
            "True: 0.616853731822046, Predicted: 0.6327407956123352\n",
            "True: 0.3874500432683276, Predicted: 0.35516148805618286\n",
            "True: 0.35396049106203215, Predicted: 0.46753811836242676\n",
            "True: 2.0791462623551684, Predicted: 2.34997296333313\n",
            "True: 0.4671331473013026, Predicted: 0.540302574634552\n",
            "True: 0.5845496615533631, Predicted: 0.8672379851341248\n",
            "True: 0.5718996945779558, Predicted: 0.6268906593322754\n",
            "True: 0.5421494257576649, Predicted: 0.5987641215324402\n",
            "True: 0.5681457474250358, Predicted: 0.5183797478675842\n",
            "True: 0.3270999286606835, Predicted: 0.2238362431526184\n",
            "True: 0.9094261124303096, Predicted: 1.4664016962051392\n",
            "True: 0.8669224757348308, Predicted: 0.7761871218681335\n",
            "True: 0.5534780082759685, Predicted: 0.5779929161071777\n",
            "True: 0.43780019537514914, Predicted: 0.49072587490081787\n",
            "True: 3.805697053846136, Predicted: 3.6285505294799805\n",
            "True: 0.5682172076372134, Predicted: 0.8366155028343201\n",
            "True: 0.5395508913492147, Predicted: 0.6225999593734741\n",
            "True: 0.5845249304955428, Predicted: 0.5590217709541321\n",
            "True: 0.5787084662869124, Predicted: 0.5068362951278687\n",
            "True: 0.690218181672059, Predicted: 0.38886621594429016\n",
            "True: 0.35308433880249457, Predicted: 0.2718559503555298\n",
            "True: 2.3102164917633994, Predicted: 2.733551263809204\n",
            "True: 1.524294227837417, Predicted: 1.0621681213378906\n",
            "True: 0.48892162925920674, Predicted: 0.4879830479621887\n",
            "True: 0.6487109913435524, Predicted: 0.5592418313026428\n",
            "True: 0.8082491348419513, Predicted: 0.8832906484603882\n",
            "True: 0.33882159582695104, Predicted: 0.1510809361934662\n",
            "True: 0.3358181186142875, Predicted: 0.4723649322986603\n",
            "True: 1.1920327965505453, Predicted: 0.9248912930488586\n",
            "True: 1.1908896007428988, Predicted: 1.5451549291610718\n",
            "True: 0.7469600152016266, Predicted: 0.7402750849723816\n",
            "True: 0.3718849988925145, Predicted: 0.6358886361122131\n",
            "True: 0.3462869249929549, Predicted: 0.2877035439014435\n",
            "True: 0.5586190371548804, Predicted: 0.6174136400222778\n",
            "True: 0.5390845634626795, Predicted: 0.49888113141059875\n",
            "True: 0.5169840374356431, Predicted: 0.6650394201278687\n",
            "True: 0.6190379165105564, Predicted: 0.8759711384773254\n",
            "True: 0.2254158611847807, Predicted: 0.22467532753944397\n",
            "True: 0.7084809839306503, Predicted: 0.9777874946594238\n",
            "True: 1.6147726322010545, Predicted: 1.9340351819992065\n",
            "True: 0.44701035879979956, Predicted: 0.5296630263328552\n",
            "True: 0.6025654476554595, Predicted: 0.5931281447410583\n",
            "True: 0.5309343759772696, Predicted: 0.620378851890564\n",
            "True: 0.6304568534858884, Predicted: 0.5264347791671753\n",
            "True: 0.5584492144049215, Predicted: 0.6263359189033508\n",
            "True: 0.6027132852528538, Predicted: 1.0225918292999268\n",
            "True: 0.40799685183466006, Predicted: 0.6443737149238586\n",
            "True: 0.6351587930393794, Predicted: 0.5686188340187073\n",
            "True: 0.39255237638781343, Predicted: 0.47820690274238586\n",
            "True: 1.1636328534317562, Predicted: 0.9630045294761658\n",
            "True: 0.406580000759409, Predicted: 0.3504100441932678\n",
            "True: 0.3399859260526826, Predicted: 0.3216416835784912\n",
            "True: 3.5792331183445762, Predicted: 3.284034490585327\n",
            "True: 0.5443153090458585, Predicted: 0.5378430485725403\n",
            "True: 0.5648422786754692, Predicted: 0.4955856204032898\n",
            "True: 0.5956192347434321, Predicted: 0.6204070448875427\n",
            "True: 3.98111803780072, Predicted: 4.840734004974365\n",
            "True: 0.5317901108312656, Predicted: 0.636486291885376\n",
            "True: 0.5530233442136157, Predicted: 0.4085354506969452\n",
            "True: 0.005018649712650877, Predicted: 0.05566274747252464\n",
            "True: 0.47334024774266154, Predicted: 0.5401774644851685\n",
            "True: 0.3261808137539814, Predicted: 0.3551784157752991\n",
            "True: 0.5497814895600651, Predicted: 0.5376847982406616\n",
            "True: 0.6869632451901988, Predicted: 0.7522699236869812\n",
            "True: 0.5349457269910716, Predicted: 0.5903544425964355\n",
            "True: 1.2111472607182456, Predicted: 1.3888784646987915\n",
            "True: 1.071220806251477, Predicted: 0.9026190638542175\n",
            "True: 0.16115016480062785, Predicted: 0.17376452684402466\n",
            "True: 0.4704861038996926, Predicted: 0.5815140008926392\n",
            "True: 0.5131818656232503, Predicted: 0.6260650753974915\n",
            "True: 0.6354547690070012, Predicted: 1.0074002742767334\n",
            "True: 1.5802320275005688, Predicted: 2.589759588241577\n",
            "True: 2.1410888612587535, Predicted: 2.117036819458008\n",
            "True: 0.5988361605215892, Predicted: 1.1857160329818726\n",
            "True: 0.4682948039291134, Predicted: 0.6158921122550964\n",
            "True: 0.5182735825034865, Predicted: 0.4252147674560547\n",
            "True: 0.5955890368484735, Predicted: 0.41141414642333984\n",
            "True: 1.0753221066736482, Predicted: 1.0499790906906128\n",
            "True: 0.531027603207394, Predicted: 0.5896134972572327\n",
            "True: 0.7128542354729969, Predicted: 0.8613784909248352\n",
            "True: 4.157204290792338, Predicted: 1.851047158241272\n",
            "True: 0.46984376016996443, Predicted: 0.5282981991767883\n",
            "True: 0.3520168090698665, Predicted: 0.34624332189559937\n",
            "True: 0.0030066338970676275, Predicted: 0.02153293415904045\n",
            "True: 0.5078993740149549, Predicted: 0.5428306460380554\n",
            "True: 0.48547483417278137, Predicted: 0.4013080596923828\n",
            "True: 0.5865718303194678, Predicted: 0.7186529636383057\n",
            "True: 1.3994067089982836, Predicted: 1.0612716674804688\n",
            "True: 2.5529600930906717, Predicted: 2.742025852203369\n",
            "True: 0.5848661340969626, Predicted: 0.42015835642814636\n",
            "True: 1.0738589176505626, Predicted: 0.8763670921325684\n",
            "True: 0.3752594783865661, Predicted: 0.39183923602104187\n",
            "True: 0.40710056826780344, Predicted: 0.26804330945014954\n",
            "True: 0.7111795162434519, Predicted: 0.5708277821540833\n",
            "True: 0.38295129303467557, Predicted: 0.5277159214019775\n",
            "True: 0.5011637471293104, Predicted: 0.5349324941635132\n",
            "True: 0.9853194004049903, Predicted: 1.858600378036499\n",
            "True: 0.34919655527658683, Predicted: 0.2770818769931793\n",
            "True: 0.5043972320592826, Predicted: 0.5138124823570251\n",
            "True: 0.4003664150703572, Predicted: 0.4222702383995056\n",
            "True: 0.5163612245137101, Predicted: 0.5524488091468811\n",
            "True: 0.5203827303302575, Predicted: 0.5649228096008301\n",
            "True: 0.6226265793908854, Predicted: 0.6612246632575989\n",
            "True: 0.6168529250283754, Predicted: 0.7052244544029236\n",
            "True: 0.525541717506945, Predicted: 0.5995456576347351\n",
            "True: 0.6229339376633912, Predicted: 0.6703732013702393\n",
            "True: 0.39693025734745446, Predicted: 0.054670240730047226\n",
            "True: 0.5197546131830914, Predicted: 0.48469632863998413\n",
            "True: 0.46334621518009383, Predicted: 0.43707484006881714\n",
            "True: 0.46849498073678375, Predicted: 0.46259167790412903\n",
            "True: 0.3948369906229112, Predicted: 0.36126092076301575\n",
            "True: 1.1223231051795364, Predicted: 0.9170196056365967\n",
            "True: 0.8923359629371589, Predicted: 0.4288950562477112\n",
            "True: 0.18784592863750443, Predicted: 0.17189282178878784\n",
            "True: 0.34390050945951944, Predicted: 0.3218896985054016\n",
            "True: 0.7354558899037368, Predicted: 0.6725897789001465\n",
            "True: 0.5068303247447268, Predicted: 0.48616549372673035\n",
            "True: 0.6015867051946128, Predicted: 0.5962327122688293\n",
            "True: 3.2138220506180835, Predicted: 1.0478066205978394\n",
            "True: 0.7444095893113067, Predicted: 0.6317458152770996\n",
            "True: 2.8804359914610367, Predicted: 2.231461524963379\n",
            "True: 0.3125670043081603, Predicted: 0.2819049656391144\n",
            "True: 0.1316926070633454, Predicted: 0.28924107551574707\n",
            "True: 0.4760445174475848, Predicted: 0.558339536190033\n",
            "True: 0.521397810691949, Predicted: 0.30433231592178345\n",
            "True: 0.5967962075877945, Predicted: 0.6791606545448303\n",
            "True: 0.7058135724288216, Predicted: 0.8226692080497742\n",
            "True: 0.18735624469349138, Predicted: 0.23808170855045319\n",
            "True: 0.8167587235765217, Predicted: 0.6310052275657654\n",
            "True: 0.7552900914169896, Predicted: 1.3773040771484375\n",
            "True: 0.35460476300199095, Predicted: 0.3500504493713379\n",
            "True: 0.9438723750393884, Predicted: 0.7528076767921448\n",
            "True: 0.475800411007348, Predicted: 0.45532163977622986\n",
            "True: 2.672595340003873, Predicted: 2.895861864089966\n",
            "True: 0.5491008514559714, Predicted: 0.6117991209030151\n",
            "True: 0.3752581014325554, Predicted: 0.3812999129295349\n",
            "True: 0.4596535176894643, Predicted: 0.3778977394104004\n",
            "True: 0.843653446082625, Predicted: 1.0608161687850952\n",
            "True: 3.8914179511566185, Predicted: 3.5030710697174072\n",
            "True: 0.7074752878937729, Predicted: 0.6103914380073547\n",
            "True: 0.19326960269017096, Predicted: 0.14508333802223206\n",
            "True: 0.6654615932144765, Predicted: 0.8209862112998962\n",
            "True: 0.33143294539862306, Predicted: 0.306379497051239\n",
            "True: 0.4608314968530211, Predicted: 0.5609848499298096\n",
            "True: 0.3615708731591389, Predicted: 0.43039005994796753\n",
            "True: 1.1789670649879471, Predicted: 1.015645146369934\n",
            "True: 0.4972549695882965, Predicted: 0.45027485489845276\n",
            "True: 0.47593142811024536, Predicted: 0.44191083312034607\n",
            "True: 0.0054497603380347865, Predicted: 0.08934615552425385\n",
            "True: 0.9102542258816745, Predicted: 0.7050458192825317\n",
            "True: 0.37695138728546324, Predicted: 0.4087868630886078\n",
            "True: 0.6068899561208037, Predicted: 0.783619225025177\n",
            "True: 1.5372976675715955, Predicted: 1.1848833560943604\n",
            "True: 0.6688507021557214, Predicted: 1.708997130393982\n",
            "True: 0.16327224273239482, Predicted: 0.17985281348228455\n",
            "True: 0.448769124197937, Predicted: 0.4602465033531189\n",
            "True: 0.5206520659922663, Predicted: 0.6223415732383728\n",
            "True: 0.5385356120464756, Predicted: 0.6368868947029114\n",
            "True: 0.5962179644015803, Predicted: 0.9119473099708557\n",
            "True: 1.5776933065467718, Predicted: 1.267526626586914\n",
            "True: 0.6554701980476372, Predicted: 0.6014910340309143\n",
            "True: 0.4127350695879768, Predicted: 0.3202959895133972\n",
            "True: 2.7191990263418235, Predicted: 2.969010353088379\n",
            "True: 0.006966256910859557, Predicted: -0.10454273223876953\n",
            "True: 1.9430816754909255, Predicted: 2.7873694896698\n",
            "True: 0.005179657608992576, Predicted: 0.14060544967651367\n",
            "True: 0.4927602398535579, Predicted: 0.5156094431877136\n",
            "True: 0.4077012082073199, Predicted: 0.405938982963562\n",
            "True: 0.5113666826418796, Predicted: 0.4578450322151184\n",
            "True: 0.5234989042682543, Predicted: 0.48957526683807373\n",
            "True: 0.6238556083952549, Predicted: 0.7883885502815247\n",
            "True: 2.8598155652471675, Predicted: 2.8244714736938477\n",
            "True: 0.5726988184307397, Predicted: 0.580230176448822\n",
            "True: 0.891251886208861, Predicted: 0.413531094789505\n",
            "True: 2.197668344040642, Predicted: 2.416792869567871\n",
            "True: 3.5016059982620193, Predicted: 2.978449583053589\n",
            "True: 0.5813322900207085, Predicted: 0.6337288618087769\n",
            "True: 0.448063289759941, Predicted: 0.46863141655921936\n",
            "True: 0.7291589367497857, Predicted: 0.6531623005867004\n",
            "True: 1.476135422053748, Predicted: 1.4145982265472412\n",
            "True: 0.8488120340440543, Predicted: 0.6807827949523926\n",
            "True: 0.9744279467459542, Predicted: 1.0672245025634766\n",
            "True: 0.5962173804977966, Predicted: 0.8792573809623718\n",
            "True: 0.5007403699717118, Predicted: 0.3374480605125427\n",
            "True: 0.5643646963510478, Predicted: 0.6434445977210999\n",
            "True: 0.5673890654957199, Predicted: 0.6279406547546387\n",
            "True: 0.6107577361125615, Predicted: 0.31475213170051575\n",
            "True: 0.3965871881339581, Predicted: 0.3866209387779236\n",
            "True: 0.5989043582801681, Predicted: 0.19622203707695007\n",
            "True: 0.008037997243595892, Predicted: -0.37271928787231445\n",
            "True: 0.006102619577323208, Predicted: 0.3618537187576294\n",
            "True: 0.5784453912958065, Predicted: 0.648620069026947\n",
            "True: 0.4090499589927471, Predicted: 0.4377552270889282\n",
            "True: 3.960113290091421, Predicted: 3.375054121017456\n",
            "True: 0.46026496554561175, Predicted: 0.34689250588417053\n",
            "True: 0.470733526610215, Predicted: 0.4612998366355896\n",
            "True: 0.7264296742449678, Predicted: 0.7413303256034851\n",
            "True: 0.28491284014886736, Predicted: 0.35892802476882935\n",
            "True: 0.0071511361637617565, Predicted: -0.0034322328865528107\n",
            "True: 0.8963499435522967, Predicted: 0.8703394532203674\n",
            "True: 3.538136518325004, Predicted: 3.1326823234558105\n",
            "True: 0.5119412439278836, Predicted: 0.6294732689857483\n",
            "True: 0.5602086375594613, Predicted: 0.6189365386962891\n",
            "True: 0.7267605206197338, Predicted: 0.6161009669303894\n",
            "True: 0.5336038309409923, Predicted: 0.4581730365753174\n",
            "True: 3.682172754719707, Predicted: 4.121590614318848\n",
            "True: 3.301950087110185, Predicted: 3.874753952026367\n",
            "True: 0.3619583903209908, Predicted: 0.23381678760051727\n",
            "True: 0.8797346592753317, Predicted: 0.9947763085365295\n",
            "True: 0.3866075619674395, Predicted: 0.3234596252441406\n",
            "True: 0.44800107858626753, Predicted: 0.5245905518531799\n",
            "True: 0.10821256136601773, Predicted: 0.17160336673259735\n",
            "True: 0.5482439257226331, Predicted: 0.5923544764518738\n",
            "True: 0.5210917933938366, Predicted: 0.5064516067504883\n",
            "True: 0.4800378660747556, Predicted: 0.6113993525505066\n",
            "True: 1.422306654469969, Predicted: 1.3712738752365112\n",
            "True: 1.8127033542235635, Predicted: 1.779198408126831\n",
            "True: 0.5112533074744269, Predicted: 0.6927081346511841\n",
            "True: 0.6271080578807635, Predicted: 0.47767892479896545\n",
            "True: 0.3379623690950358, Predicted: 0.8427460789680481\n",
            "True: 0.4745513989891442, Predicted: 0.6566323041915894\n",
            "True: 0.502074662613169, Predicted: 0.5892260670661926\n",
            "True: 0.5599513322089322, Predicted: 0.589426577091217\n",
            "True: 1.7994781067480479, Predicted: 0.3230852782726288\n",
            "True: 1.489668581198676, Predicted: 1.2858039140701294\n",
            "True: 0.8204007805829351, Predicted: 0.7204580903053284\n",
            "True: 0.72351139792817, Predicted: 0.8472781777381897\n",
            "True: 1.5590491039929246, Predicted: 2.1505978107452393\n",
            "True: 0.3374721493373578, Predicted: 0.18868839740753174\n",
            "True: 0.3658708611084559, Predicted: 0.48406216502189636\n",
            "True: 0.540075001274014, Predicted: 0.5445098876953125\n",
            "True: 2.3925870109568144, Predicted: 2.672912120819092\n",
            "True: 0.2752193289940888, Predicted: 0.10882295668125153\n",
            "True: 0.003450789291310434, Predicted: 0.18602582812309265\n",
            "True: 0.12036224429586317, Predicted: 0.2010709047317505\n",
            "True: 0.6464920172407943, Predicted: 0.5622996091842651\n",
            "True: 0.6908210462593407, Predicted: 0.5442578792572021\n",
            "True: 2.273148037789624, Predicted: 2.3323605060577393\n",
            "True: 0.4945764065327153, Predicted: 0.5890650153160095\n",
            "True: 0.2225576682405711, Predicted: 0.22652938961982727\n",
            "True: 0.5697367273730228, Predicted: 0.16415385901927948\n",
            "True: 0.5454741446870325, Predicted: 0.37571126222610474\n",
            "True: 0.5558939145519897, Predicted: 0.40597835183143616\n",
            "True: 0.4378575896515877, Predicted: 0.35164421796798706\n",
            "True: 0.5151545498184201, Predicted: 0.6070356965065002\n",
            "True: 0.5542778166071753, Predicted: 0.639948844909668\n",
            "True: 0.6599962079721712, Predicted: 0.6297489404678345\n",
            "True: 0.2914887652060093, Predicted: 0.39959877729415894\n",
            "True: 0.5589837038905836, Predicted: 1.0550142526626587\n",
            "True: 0.52843666314775, Predicted: 0.4553813338279724\n",
            "True: 0.8113528750979347, Predicted: 0.8318104147911072\n",
            "True: 1.3869325057956703, Predicted: 1.4160078763961792\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Generate predictions\n",
        "y_pred = model.predict(X_test_minmax)\n",
        "\n",
        "# Flatten y_pred to ensure it's in the same shape as y_test\n",
        "y_pred = y_pred.flatten()\n",
        "\n",
        "# Print true and predicted values\n",
        "for true, pred in zip(y_test, y_pred):\n",
        "    print(f\"True: {true}, Predicted: {pred}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jrlkc1pZs9Z",
        "outputId": "b9eb3caa-8baa-4e89-b69a-30c5b539f4dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# model.save_weights('cage_metric_model.ckpt')\n",
        "model.save('model_varyingGoal_cutoffLabels.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEer6ssAafeO",
        "outputId": "f48aaf4e-cb7e-4812-fea4-be9d5e316e23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.6385281345710567, -0.5092962134283774, 0.08382842145923423, -0.13254497591122066, -1.5364387572726412, -0.4886458616509667, 0.003567941207741127, 1.4215608118319583, 0.023628152616274812, -0.3700396101036746]]\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "[[1.4909074]]\n"
          ]
        }
      ],
      "source": [
        "# Load the entire model\n",
        "new_model = load_model('path_to_my_model.h5')\n",
        "\n",
        "# Use the model for inference\n",
        "i = (X_test[0:1]).tolist()\n",
        "print(i)\n",
        "prediction = new_model.predict(i)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz2YtNA-rmA7"
      },
      "source": [
        "# TORCH 1D Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsPLUJLtruO8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWTf4Ml2shTD"
      },
      "outputs": [],
      "source": [
        "layer_size = 64\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    total_loss = 0\n",
        "    num_batch = len(dataloader)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y.unsqueeze(1))\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / batch\n",
        "\n",
        "def val_loop(dataloader, model, loss_fn):\n",
        "    num_batch = len(dataloader)\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y.unsqueeze(1))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / num_batch\n",
        "\n",
        "# Define the model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(12, layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_size, layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_size, layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_size, layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_size, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_relu_stack(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlv06qozsHQd",
        "outputId": "75a27868-4ec1-4a7c-cf68-5cfd5c76660d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['scaler_minmax.pkl']"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Assuming 'inputs' and 'labels' are your data\n",
        "# labels = [[s,m] for s,m in zip(success_labels, maneuver_labels)]\n",
        "labels = [-dis+stick+engage for dis,stick,engage in quality]\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.15, random_state=42)\n",
        "\n",
        "# # Min-Max Scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_train = min_max_scaler.fit_transform(X_train)\n",
        "X_test = min_max_scaler.transform(X_test)\n",
        "joblib.dump(min_max_scaler, 'scaler_minmax.pkl')\n",
        "\n",
        "# Standardization\n",
        "# standard_scaler = StandardScaler()\n",
        "# X_train = standard_scaler.fit_transform(X_train)\n",
        "# X_test = standard_scaler.transform(X_test)\n",
        "# joblib.dump(min_max_scaler, 'scaler_standard.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT_W1AD0rpVI"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Convert arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = NeuralNetwork()\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "learning_rate = 3e-5\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.MSELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BuABwP_b_xrH",
        "outputId": "78e80898-3915-4c0d-bc9c-5670284bf605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Training Loss: 1466.4011\n",
            "Validation Loss: 800.5823\n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Training Loss: 1466.2094\n",
            "Validation Loss: 800.3750\n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Training Loss: 1465.9334\n",
            "Validation Loss: 800.2381\n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Training Loss: 1465.5490\n",
            "Validation Loss: 799.6942\n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Training Loss: 1465.0784\n",
            "Validation Loss: 801.8420\n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Training Loss: 1464.6338\n",
            "Validation Loss: 798.8369\n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Training Loss: 1464.0664\n",
            "Validation Loss: 798.4285\n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Training Loss: 1464.7429\n",
            "Validation Loss: 798.0860\n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Training Loss: 1463.1920\n",
            "Validation Loss: 797.7915\n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Training Loss: 1462.8232\n",
            "Validation Loss: 797.5296\n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Training Loss: 1463.2217\n",
            "Validation Loss: 797.3160\n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Training Loss: 1462.2067\n",
            "Validation Loss: 797.1245\n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Training Loss: 1463.0209\n",
            "Validation Loss: 796.9854\n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Training Loss: 1461.6311\n",
            "Validation Loss: 796.6972\n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Training Loss: 1461.3060\n",
            "Validation Loss: 796.4444\n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Training Loss: 1460.9664\n",
            "Validation Loss: 796.2034\n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Training Loss: 1460.6632\n",
            "Validation Loss: 795.9986\n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Training Loss: 1460.3246\n",
            "Validation Loss: 795.8992\n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Training Loss: 1459.9913\n",
            "Validation Loss: 795.5767\n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Training Loss: 1459.6453\n",
            "Validation Loss: 795.3483\n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Training Loss: 1459.3361\n",
            "Validation Loss: 795.1790\n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Training Loss: 1459.0428\n",
            "Validation Loss: 795.0185\n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Training Loss: 1458.8471\n",
            "Validation Loss: 794.8436\n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Training Loss: 1458.5900\n",
            "Validation Loss: 794.7254\n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Training Loss: 1458.3647\n",
            "Validation Loss: 794.5697\n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Training Loss: 1458.1978\n",
            "Validation Loss: 794.5556\n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Training Loss: 1457.9266\n",
            "Validation Loss: 809.4839\n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Training Loss: 1457.7589\n",
            "Validation Loss: 794.2031\n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Training Loss: 1457.5907\n",
            "Validation Loss: 794.3050\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-2dcfd8434286>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-fdc5675c3e01>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                             )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 state_steps)\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;31m# bake-in time before making it the default, even if it is typically faster.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mforeach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforeach\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_to_fused_or_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;31m# Do not flip on foreach for the unsupported case where lr is a Tensor and capturable=False.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforeach\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcapturable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_loop(train_loader, model, loss_fn, optimizer)\n",
        "    val_loss = val_loop(val_loader, model, loss_fn)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
        "    print(f\"Training Loss: {train_loss:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "4GmZLaGWd4mv",
        "outputId": "83608497-a048-4fb7-e9ff-0424736fd2e2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a plot of training and validation losses\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "ax = fig.add_subplot()\n",
        "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\")\n",
        "plt.plot(range(1, epochs + 1), val_losses, label=\"Validation Loss\")\n",
        "ax.set_yscale('log')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOQLkQuuygek",
        "outputId": "f0c09c38-9b3d-4feb-9932-91984a05e953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.2334563136100769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1707])) that is different to the input size (torch.Size([1707, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_tensor)\n",
        "    test_loss = loss_fn(y_pred, y_test_tensor).item()\n",
        "    print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model_11k.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jsimULgsfGF",
        "outputId": "86cdc87c-4e01-4e4e-d042-c3263b5901d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True: 0.09501648334557618, Predicted: [0.12087370455265045]\n",
            "True: 1.1702300156168265e-11, Predicted: [-0.010196041315793991]\n",
            "True: 0.0, Predicted: [-0.0067215003073215485]\n",
            "True: 4.720007476675832e-05, Predicted: [-0.003118019551038742]\n",
            "True: 0.023287717772783965, Predicted: [0.03565071150660515]\n",
            "True: 0.0, Predicted: [-0.051439907401800156]\n",
            "True: 0.0, Predicted: [-0.018868248909711838]\n",
            "True: 0.0, Predicted: [-0.00734793022274971]\n",
            "True: 4.03199003735671e-11, Predicted: [-0.008567478507757187]\n",
            "True: 3.821138289710384e-08, Predicted: [-0.007883157581090927]\n",
            "True: 0.763437781905207, Predicted: [0.5751135349273682]\n",
            "True: 0.0, Predicted: [-0.005150366574525833]\n",
            "True: 0.5044446776319355, Predicted: [0.4770084619522095]\n",
            "True: 7.440086685681769e-09, Predicted: [-0.033794548362493515]\n",
            "True: 0.04272308665047889, Predicted: [0.11257430911064148]\n",
            "True: 0.3059998462526766, Predicted: [0.10276058316230774]\n",
            "True: 0.0, Predicted: [0.04548525810241699]\n",
            "True: 0.08782566794397852, Predicted: [0.02412785217165947]\n",
            "True: 0.4459828155837875, Predicted: [0.20400550961494446]\n",
            "True: 0.9927122802735966, Predicted: [0.8732120990753174]\n",
            "True: 6.273156657473323e-13, Predicted: [-0.009450387209653854]\n",
            "True: 3.0752935501895727e-10, Predicted: [-0.007818277925252914]\n",
            "True: 5.5030820031391356e-05, Predicted: [0.006713036447763443]\n",
            "True: 0.0, Predicted: [-0.009676557034254074]\n",
            "True: 0.19726192659762015, Predicted: [0.09189246594905853]\n",
            "True: 0.0, Predicted: [-0.005211357027292252]\n",
            "True: 1.5895842833726834e-09, Predicted: [-0.006789427250623703]\n",
            "True: 0.0, Predicted: [-0.0016156546771526337]\n",
            "True: 0.1881199662331589, Predicted: [0.1530844122171402]\n",
            "True: 0.0007474235343835579, Predicted: [-0.0013736598193645477]\n",
            "True: 0.0, Predicted: [0.0031419433653354645]\n",
            "True: 6.855759259440951e-10, Predicted: [-0.011166464537382126]\n",
            "True: 0.041672338992536744, Predicted: [0.0778454840183258]\n",
            "True: 8.918497978324385e-05, Predicted: [-0.05018879100680351]\n",
            "True: 0.0, Predicted: [0.003337562084197998]\n",
            "True: 0.8434170240517614, Predicted: [0.8542272448539734]\n",
            "True: 0.5576049275738598, Predicted: [0.4667954444885254]\n",
            "True: 0.4116017093057395, Predicted: [0.4093371033668518]\n",
            "True: 0.0, Predicted: [-0.00651409849524498]\n",
            "True: 0.0, Predicted: [-0.028776686638593674]\n",
            "True: 0.0, Predicted: [-0.02527136728167534]\n",
            "True: 0.0, Predicted: [0.004429135471582413]\n",
            "True: 0.0, Predicted: [-0.005004283040761948]\n",
            "True: 0.832968684479052, Predicted: [0.8489643335342407]\n",
            "True: 2.1114038047805258e-05, Predicted: [-0.02947458252310753]\n",
            "True: 1.5568706371708436e-11, Predicted: [-0.007620837539434433]\n",
            "True: 0.0, Predicted: [-0.005763348191976547]\n",
            "True: 0.0, Predicted: [-0.00539768859744072]\n",
            "True: 0.1970437724296573, Predicted: [0.305654913187027]\n",
            "True: 0.0, Predicted: [-0.007087152451276779]\n",
            "True: 0.9230158843440479, Predicted: [0.8249533176422119]\n",
            "True: 8.014042275936572e-10, Predicted: [-0.007097315043210983]\n",
            "True: 0.8943215940877989, Predicted: [0.6253154277801514]\n",
            "True: 8.843342539588638e-07, Predicted: [-0.0017648674547672272]\n",
            "True: 0.9470057718750919, Predicted: [0.5845175385475159]\n",
            "True: 0.9088446856686554, Predicted: [0.8183942437171936]\n",
            "True: 0.9196342609272897, Predicted: [0.8627683520317078]\n",
            "True: 2.557894704260794e-10, Predicted: [-0.009190570563077927]\n",
            "True: 0.8470476601021638, Predicted: [0.8102831840515137]\n",
            "True: 2.6577499650083632e-09, Predicted: [-0.007663648575544357]\n",
            "True: 0.0, Predicted: [-0.007320243865251541]\n",
            "True: 1.0, Predicted: [0.8936652541160583]\n",
            "True: 0.6322808202792254, Predicted: [0.40743646025657654]\n",
            "True: 6.839102340385514e-11, Predicted: [-0.0062949322164058685]\n",
            "True: 0.7808161489720525, Predicted: [0.7083143591880798]\n",
            "True: 1.5738556080976766e-15, Predicted: [-0.00468951091170311]\n",
            "True: 7.285546974731237e-07, Predicted: [-0.0033331625163555145]\n",
            "True: 4.677544983455982e-10, Predicted: [-0.013089250773191452]\n",
            "True: 0.0, Predicted: [-0.008752752095460892]\n",
            "True: 7.183954367872837e-10, Predicted: [-0.004699084907770157]\n",
            "True: 4.347512207938431e-05, Predicted: [0.002508174628019333]\n",
            "True: 0.0, Predicted: [-0.006377425044775009]\n",
            "True: 0.002444301193501627, Predicted: [0.1638817936182022]\n",
            "True: 0.9110259881442452, Predicted: [0.7538881897926331]\n",
            "True: 0.0016181084829003732, Predicted: [0.024963077157735825]\n",
            "True: 2.6425309522472287e-06, Predicted: [-0.002365242689847946]\n",
            "True: 4.065128279816067e-11, Predicted: [-0.009746532887220383]\n",
            "True: 0.2345435383661267, Predicted: [0.1599721908569336]\n",
            "True: 0.9651956217903385, Predicted: [0.8118435740470886]\n",
            "True: 1.1403786755861632e-10, Predicted: [-0.009178902953863144]\n",
            "True: 0.12277797467698265, Predicted: [0.107784703373909]\n",
            "True: 0.0, Predicted: [-0.01012241467833519]\n",
            "True: 0.0, Predicted: [0.0363704152405262]\n",
            "True: 4.1346826258813295e-05, Predicted: [-0.0024491436779499054]\n",
            "True: 1.0738949416860704e-10, Predicted: [-0.013401631265878677]\n",
            "True: 0.0, Predicted: [-0.005374085158109665]\n",
            "True: 2.190486094524266e-09, Predicted: [-0.008518021553754807]\n",
            "True: 0.8371657105042054, Predicted: [0.861146092414856]\n",
            "True: 9.55440523378409e-09, Predicted: [-0.0066741593182086945]\n",
            "True: 0.0, Predicted: [-0.0071114785969257355]\n",
            "True: 0.5665149777640033, Predicted: [0.7829747796058655]\n",
            "True: 0.8020793829821066, Predicted: [0.4209415912628174]\n",
            "True: 0.3260935758970891, Predicted: [0.3097994327545166]\n",
            "True: 0.009242887696115552, Predicted: [0.018854402005672455]\n",
            "True: 0.8474421421948678, Predicted: [0.9503524899482727]\n",
            "True: 0.0, Predicted: [-0.006410133093595505]\n",
            "True: 1.1110081837803273e-05, Predicted: [-0.01013566181063652]\n",
            "True: 1.1862449292267323e-05, Predicted: [-0.012510668486356735]\n",
            "True: 0.0, Predicted: [-0.0036566145718097687]\n",
            "True: 0.09378353921943548, Predicted: [0.1541980654001236]\n"
          ]
        }
      ],
      "source": [
        "# Print true and predicted values\n",
        "for true, pred in zip(y_test[:100], y_pred.tolist()[:100]):\n",
        "    print(f\"True: {true}, Predicted: {pred}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsSn7wnjgVOo"
      },
      "source": [
        "# TORCH 2D Output (Our Metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-Mpc_EogXsX",
        "outputId": "885a5e6a-fe76-420c-f6de-d616ca73beab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Training Loss: 0.1310\n",
            "Validation Loss: 0.0940\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Training Loss: 0.0849\n",
            "Validation Loss: 0.0815\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Training Loss: 0.0777\n",
            "Validation Loss: 0.0761\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Training Loss: 0.0733\n",
            "Validation Loss: 0.0714\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Training Loss: 0.0695\n",
            "Validation Loss: 0.0682\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Training Loss: 0.0663\n",
            "Validation Loss: 0.0656\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Training Loss: 0.0627\n",
            "Validation Loss: 0.0633\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Training Loss: 0.0594\n",
            "Validation Loss: 0.0589\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Training Loss: 0.0559\n",
            "Validation Loss: 0.0575\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Training Loss: 0.0531\n",
            "Validation Loss: 0.0568\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Training Loss: 0.0509\n",
            "Validation Loss: 0.0505\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Training Loss: 0.0492\n",
            "Validation Loss: 0.0500\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Training Loss: 0.0479\n",
            "Validation Loss: 0.0483\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Training Loss: 0.0466\n",
            "Validation Loss: 0.0471\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Training Loss: 0.0459\n",
            "Validation Loss: 0.0467\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Training Loss: 0.0451\n",
            "Validation Loss: 0.0456\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Training Loss: 0.0443\n",
            "Validation Loss: 0.0449\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Training Loss: 0.0435\n",
            "Validation Loss: 0.0448\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Training Loss: 0.0427\n",
            "Validation Loss: 0.0431\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Training Loss: 0.0420\n",
            "Validation Loss: 0.0425\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Training Loss: 0.0415\n",
            "Validation Loss: 0.0421\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Training Loss: 0.0408\n",
            "Validation Loss: 0.0409\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Training Loss: 0.0403\n",
            "Validation Loss: 0.0410\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Training Loss: 0.0398\n",
            "Validation Loss: 0.0413\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Training Loss: 0.0390\n",
            "Validation Loss: 0.0395\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Training Loss: 0.0384\n",
            "Validation Loss: 0.0383\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Training Loss: 0.0376\n",
            "Validation Loss: 0.0381\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Training Loss: 0.0372\n",
            "Validation Loss: 0.0393\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Training Loss: 0.0366\n",
            "Validation Loss: 0.0369\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "Training Loss: 0.0358\n",
            "Validation Loss: 0.0365\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "Training Loss: 0.0354\n",
            "Validation Loss: 0.0356\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "Training Loss: 0.0346\n",
            "Validation Loss: 0.0350\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "Training Loss: 0.0341\n",
            "Validation Loss: 0.0344\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "Training Loss: 0.0337\n",
            "Validation Loss: 0.0347\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "Training Loss: 0.0328\n",
            "Validation Loss: 0.0330\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "Training Loss: 0.0327\n",
            "Validation Loss: 0.0331\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "Training Loss: 0.0319\n",
            "Validation Loss: 0.0329\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "Training Loss: 0.0313\n",
            "Validation Loss: 0.0328\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "Training Loss: 0.0310\n",
            "Validation Loss: 0.0329\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "Training Loss: 0.0309\n",
            "Validation Loss: 0.0318\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "Training Loss: 0.0301\n",
            "Validation Loss: 0.0316\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "Training Loss: 0.0296\n",
            "Validation Loss: 0.0314\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "Training Loss: 0.0296\n",
            "Validation Loss: 0.0297\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "Training Loss: 0.0289\n",
            "Validation Loss: 0.0298\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "Training Loss: 0.0287\n",
            "Validation Loss: 0.0295\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "Training Loss: 0.0283\n",
            "Validation Loss: 0.0294\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "Training Loss: 0.0281\n",
            "Validation Loss: 0.0287\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "Training Loss: 0.0276\n",
            "Validation Loss: 0.0288\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "Training Loss: 0.0274\n",
            "Validation Loss: 0.0290\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "Training Loss: 0.0273\n",
            "Validation Loss: 0.0286\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "Training Loss: 0.0268\n",
            "Validation Loss: 0.0317\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "Training Loss: 0.0266\n",
            "Validation Loss: 0.0333\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "Training Loss: 0.0265\n",
            "Validation Loss: 0.0271\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "Training Loss: 0.0260\n",
            "Validation Loss: 0.0269\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "Training Loss: 0.0258\n",
            "Validation Loss: 0.0268\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "Training Loss: 0.0256\n",
            "Validation Loss: 0.0280\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "Training Loss: 0.0257\n",
            "Validation Loss: 0.0267\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "Training Loss: 0.0252\n",
            "Validation Loss: 0.0272\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "Training Loss: 0.0252\n",
            "Validation Loss: 0.0294\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "Training Loss: 0.0249\n",
            "Validation Loss: 0.0282\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "Training Loss: 0.0250\n",
            "Validation Loss: 0.0260\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "Training Loss: 0.0244\n",
            "Validation Loss: 0.0257\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "Training Loss: 0.0244\n",
            "Validation Loss: 0.0250\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "Training Loss: 0.0242\n",
            "Validation Loss: 0.0250\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "Training Loss: 0.0239\n",
            "Validation Loss: 0.0254\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "Training Loss: 0.0239\n",
            "Validation Loss: 0.0259\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "Training Loss: 0.0236\n",
            "Validation Loss: 0.0249\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "Training Loss: 0.0234\n",
            "Validation Loss: 0.0274\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "Training Loss: 0.0234\n",
            "Validation Loss: 0.0240\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "Training Loss: 0.0230\n",
            "Validation Loss: 0.0245\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "Training Loss: 0.0228\n",
            "Validation Loss: 0.0243\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "Training Loss: 0.0228\n",
            "Validation Loss: 0.0235\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "Training Loss: 0.0225\n",
            "Validation Loss: 0.0248\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "Training Loss: 0.0223\n",
            "Validation Loss: 0.0232\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "Training Loss: 0.0223\n",
            "Validation Loss: 0.0259\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "Training Loss: 0.0222\n",
            "Validation Loss: 0.0231\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "Training Loss: 0.0220\n",
            "Validation Loss: 0.0231\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "Training Loss: 0.0220\n",
            "Validation Loss: 0.0234\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "Training Loss: 0.0218\n",
            "Validation Loss: 0.0234\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "Training Loss: 0.0219\n",
            "Validation Loss: 0.0223\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "Training Loss: 0.0215\n",
            "Validation Loss: 0.0229\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "Training Loss: 0.0214\n",
            "Validation Loss: 0.0223\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "Training Loss: 0.0215\n",
            "Validation Loss: 0.0222\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "Training Loss: 0.0211\n",
            "Validation Loss: 0.0234\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "Training Loss: 0.0211\n",
            "Validation Loss: 0.0215\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "Training Loss: 0.0208\n",
            "Validation Loss: 0.0228\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "Training Loss: 0.0208\n",
            "Validation Loss: 0.0224\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "Training Loss: 0.0207\n",
            "Validation Loss: 0.0227\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "Training Loss: 0.0205\n",
            "Validation Loss: 0.0217\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "Training Loss: 0.0206\n",
            "Validation Loss: 0.0240\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "Training Loss: 0.0204\n",
            "Validation Loss: 0.0211\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "Training Loss: 0.0205\n",
            "Validation Loss: 0.0212\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "Training Loss: 0.0203\n",
            "Validation Loss: 0.0214\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "Training Loss: 0.0201\n",
            "Validation Loss: 0.0220\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "Training Loss: 0.0200\n",
            "Validation Loss: 0.0208\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "Training Loss: 0.0198\n",
            "Validation Loss: 0.0220\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "Training Loss: 0.0200\n",
            "Validation Loss: 0.0209\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "Training Loss: 0.0201\n",
            "Validation Loss: 0.0209\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "Training Loss: 0.0198\n",
            "Validation Loss: 0.0205\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "Training Loss: 0.0196\n",
            "Validation Loss: 0.0211\n",
            "Epoch 101\n",
            "-------------------------------\n",
            "Training Loss: 0.0197\n",
            "Validation Loss: 0.0208\n",
            "Epoch 102\n",
            "-------------------------------\n",
            "Training Loss: 0.0195\n",
            "Validation Loss: 0.0206\n",
            "Epoch 103\n",
            "-------------------------------\n",
            "Training Loss: 0.0194\n",
            "Validation Loss: 0.0213\n",
            "Epoch 104\n",
            "-------------------------------\n",
            "Training Loss: 0.0194\n",
            "Validation Loss: 0.0204\n",
            "Epoch 105\n",
            "-------------------------------\n",
            "Training Loss: 0.0192\n",
            "Validation Loss: 0.0205\n",
            "Epoch 106\n",
            "-------------------------------\n",
            "Training Loss: 0.0195\n",
            "Validation Loss: 0.0214\n",
            "Epoch 107\n",
            "-------------------------------\n",
            "Training Loss: 0.0191\n",
            "Validation Loss: 0.0212\n",
            "Epoch 108\n",
            "-------------------------------\n",
            "Training Loss: 0.0195\n",
            "Validation Loss: 0.0203\n",
            "Epoch 109\n",
            "-------------------------------\n",
            "Training Loss: 0.0191\n",
            "Validation Loss: 0.0197\n",
            "Epoch 110\n",
            "-------------------------------\n",
            "Training Loss: 0.0189\n",
            "Validation Loss: 0.0218\n",
            "Epoch 111\n",
            "-------------------------------\n",
            "Training Loss: 0.0190\n",
            "Validation Loss: 0.0201\n",
            "Epoch 112\n",
            "-------------------------------\n",
            "Training Loss: 0.0188\n",
            "Validation Loss: 0.0198\n",
            "Epoch 113\n",
            "-------------------------------\n",
            "Training Loss: 0.0188\n",
            "Validation Loss: 0.0195\n",
            "Epoch 114\n",
            "-------------------------------\n",
            "Training Loss: 0.0187\n",
            "Validation Loss: 0.0198\n",
            "Epoch 115\n",
            "-------------------------------\n",
            "Training Loss: 0.0186\n",
            "Validation Loss: 0.0204\n",
            "Epoch 116\n",
            "-------------------------------\n",
            "Training Loss: 0.0186\n",
            "Validation Loss: 0.0212\n",
            "Epoch 117\n",
            "-------------------------------\n",
            "Training Loss: 0.0187\n",
            "Validation Loss: 0.0193\n",
            "Epoch 118\n",
            "-------------------------------\n",
            "Training Loss: 0.0184\n",
            "Validation Loss: 0.0215\n",
            "Epoch 119\n",
            "-------------------------------\n",
            "Training Loss: 0.0186\n",
            "Validation Loss: 0.0199\n",
            "Epoch 120\n",
            "-------------------------------\n",
            "Training Loss: 0.0184\n",
            "Validation Loss: 0.0197\n",
            "Epoch 121\n",
            "-------------------------------\n",
            "Training Loss: 0.0183\n",
            "Validation Loss: 0.0191\n",
            "Epoch 122\n",
            "-------------------------------\n",
            "Training Loss: 0.0183\n",
            "Validation Loss: 0.0194\n",
            "Epoch 123\n",
            "-------------------------------\n",
            "Training Loss: 0.0181\n",
            "Validation Loss: 0.0191\n",
            "Epoch 124\n",
            "-------------------------------\n",
            "Training Loss: 0.0181\n",
            "Validation Loss: 0.0194\n",
            "Epoch 125\n",
            "-------------------------------\n",
            "Training Loss: 0.0184\n",
            "Validation Loss: 0.0194\n",
            "Epoch 126\n",
            "-------------------------------\n",
            "Training Loss: 0.0181\n",
            "Validation Loss: 0.0203\n",
            "Epoch 127\n",
            "-------------------------------\n",
            "Training Loss: 0.0179\n",
            "Validation Loss: 0.0190\n",
            "Epoch 128\n",
            "-------------------------------\n",
            "Training Loss: 0.0179\n",
            "Validation Loss: 0.0188\n",
            "Epoch 129\n",
            "-------------------------------\n",
            "Training Loss: 0.0178\n",
            "Validation Loss: 0.0191\n",
            "Epoch 130\n",
            "-------------------------------\n",
            "Training Loss: 0.0178\n",
            "Validation Loss: 0.0188\n",
            "Epoch 131\n",
            "-------------------------------\n",
            "Training Loss: 0.0179\n",
            "Validation Loss: 0.0191\n",
            "Epoch 132\n",
            "-------------------------------\n",
            "Training Loss: 0.0175\n",
            "Validation Loss: 0.0194\n",
            "Epoch 133\n",
            "-------------------------------\n",
            "Training Loss: 0.0181\n",
            "Validation Loss: 0.0209\n",
            "Epoch 134\n",
            "-------------------------------\n",
            "Training Loss: 0.0175\n",
            "Validation Loss: 0.0187\n",
            "Epoch 135\n",
            "-------------------------------\n",
            "Training Loss: 0.0177\n",
            "Validation Loss: 0.0182\n",
            "Epoch 136\n",
            "-------------------------------\n",
            "Training Loss: 0.0174\n",
            "Validation Loss: 0.0186\n",
            "Epoch 137\n",
            "-------------------------------\n",
            "Training Loss: 0.0177\n",
            "Validation Loss: 0.0190\n",
            "Epoch 138\n",
            "-------------------------------\n",
            "Training Loss: 0.0172\n",
            "Validation Loss: 0.0187\n",
            "Epoch 139\n",
            "-------------------------------\n",
            "Training Loss: 0.0175\n",
            "Validation Loss: 0.0186\n",
            "Epoch 140\n",
            "-------------------------------\n",
            "Training Loss: 0.0172\n",
            "Validation Loss: 0.0187\n",
            "Epoch 141\n",
            "-------------------------------\n",
            "Training Loss: 0.0171\n",
            "Validation Loss: 0.0182\n",
            "Epoch 142\n",
            "-------------------------------\n",
            "Training Loss: 0.0172\n",
            "Validation Loss: 0.0183\n",
            "Epoch 143\n",
            "-------------------------------\n",
            "Training Loss: 0.0170\n",
            "Validation Loss: 0.0187\n",
            "Epoch 144\n",
            "-------------------------------\n",
            "Training Loss: 0.0173\n",
            "Validation Loss: 0.0193\n",
            "Epoch 145\n",
            "-------------------------------\n",
            "Training Loss: 0.0171\n",
            "Validation Loss: 0.0200\n",
            "Epoch 146\n",
            "-------------------------------\n",
            "Training Loss: 0.0168\n",
            "Validation Loss: 0.0185\n",
            "Epoch 147\n",
            "-------------------------------\n",
            "Training Loss: 0.0172\n",
            "Validation Loss: 0.0184\n",
            "Epoch 148\n",
            "-------------------------------\n",
            "Training Loss: 0.0168\n",
            "Validation Loss: 0.0189\n",
            "Epoch 149\n",
            "-------------------------------\n",
            "Training Loss: 0.0171\n",
            "Validation Loss: 0.0188\n",
            "Epoch 150\n",
            "-------------------------------\n",
            "Training Loss: 0.0168\n",
            "Validation Loss: 0.0184\n",
            "Epoch 151\n",
            "-------------------------------\n",
            "Training Loss: 0.0169\n",
            "Validation Loss: 0.0175\n",
            "Epoch 152\n",
            "-------------------------------\n",
            "Training Loss: 0.0167\n",
            "Validation Loss: 0.0191\n",
            "Epoch 153\n",
            "-------------------------------\n",
            "Training Loss: 0.0169\n",
            "Validation Loss: 0.0176\n",
            "Epoch 154\n",
            "-------------------------------\n",
            "Training Loss: 0.0167\n",
            "Validation Loss: 0.0174\n",
            "Epoch 155\n",
            "-------------------------------\n",
            "Training Loss: 0.0165\n",
            "Validation Loss: 0.0186\n",
            "Epoch 156\n",
            "-------------------------------\n",
            "Training Loss: 0.0166\n",
            "Validation Loss: 0.0180\n",
            "Epoch 157\n",
            "-------------------------------\n",
            "Training Loss: 0.0164\n",
            "Validation Loss: 0.0180\n",
            "Epoch 158\n",
            "-------------------------------\n",
            "Training Loss: 0.0164\n",
            "Validation Loss: 0.0174\n",
            "Epoch 159\n",
            "-------------------------------\n",
            "Training Loss: 0.0163\n",
            "Validation Loss: 0.0174\n",
            "Epoch 160\n",
            "-------------------------------\n",
            "Training Loss: 0.0163\n",
            "Validation Loss: 0.0184\n",
            "Epoch 161\n",
            "-------------------------------\n",
            "Training Loss: 0.0164\n",
            "Validation Loss: 0.0177\n",
            "Epoch 162\n",
            "-------------------------------\n",
            "Training Loss: 0.0163\n",
            "Validation Loss: 0.0174\n",
            "Epoch 163\n",
            "-------------------------------\n",
            "Training Loss: 0.0164\n",
            "Validation Loss: 0.0184\n",
            "Epoch 164\n",
            "-------------------------------\n",
            "Training Loss: 0.0161\n",
            "Validation Loss: 0.0178\n",
            "Epoch 165\n",
            "-------------------------------\n",
            "Training Loss: 0.0164\n",
            "Validation Loss: 0.0183\n",
            "Epoch 166\n",
            "-------------------------------\n",
            "Training Loss: 0.0161\n",
            "Validation Loss: 0.0175\n",
            "Epoch 167\n",
            "-------------------------------\n",
            "Training Loss: 0.0162\n",
            "Validation Loss: 0.0178\n",
            "Epoch 168\n",
            "-------------------------------\n",
            "Training Loss: 0.0162\n",
            "Validation Loss: 0.0176\n",
            "Epoch 169\n",
            "-------------------------------\n",
            "Training Loss: 0.0161\n",
            "Validation Loss: 0.0173\n",
            "Epoch 170\n",
            "-------------------------------\n",
            "Training Loss: 0.0162\n",
            "Validation Loss: 0.0175\n",
            "Epoch 171\n",
            "-------------------------------\n",
            "Training Loss: 0.0161\n",
            "Validation Loss: 0.0184\n",
            "Epoch 172\n",
            "-------------------------------\n",
            "Training Loss: 0.0158\n",
            "Validation Loss: 0.0173\n",
            "Epoch 173\n",
            "-------------------------------\n",
            "Training Loss: 0.0159\n",
            "Validation Loss: 0.0169\n",
            "Epoch 174\n",
            "-------------------------------\n",
            "Training Loss: 0.0160\n",
            "Validation Loss: 0.0196\n",
            "Epoch 175\n",
            "-------------------------------\n",
            "Training Loss: 0.0159\n",
            "Validation Loss: 0.0181\n",
            "Epoch 176\n",
            "-------------------------------\n",
            "Training Loss: 0.0160\n",
            "Validation Loss: 0.0173\n",
            "Epoch 177\n",
            "-------------------------------\n",
            "Training Loss: 0.0160\n",
            "Validation Loss: 0.0185\n",
            "Epoch 178\n",
            "-------------------------------\n",
            "Training Loss: 0.0159\n",
            "Validation Loss: 0.0178\n",
            "Epoch 179\n",
            "-------------------------------\n",
            "Training Loss: 0.0157\n",
            "Validation Loss: 0.0188\n",
            "Epoch 180\n",
            "-------------------------------\n",
            "Training Loss: 0.0158\n",
            "Validation Loss: 0.0167\n",
            "Epoch 181\n",
            "-------------------------------\n",
            "Training Loss: 0.0158\n",
            "Validation Loss: 0.0167\n",
            "Epoch 182\n",
            "-------------------------------\n",
            "Training Loss: 0.0157\n",
            "Validation Loss: 0.0170\n",
            "Epoch 183\n",
            "-------------------------------\n",
            "Training Loss: 0.0157\n",
            "Validation Loss: 0.0167\n",
            "Epoch 184\n",
            "-------------------------------\n",
            "Training Loss: 0.0158\n",
            "Validation Loss: 0.0165\n",
            "Epoch 185\n",
            "-------------------------------\n",
            "Training Loss: 0.0156\n",
            "Validation Loss: 0.0167\n",
            "Epoch 186\n",
            "-------------------------------\n",
            "Training Loss: 0.0155\n",
            "Validation Loss: 0.0172\n",
            "Epoch 187\n",
            "-------------------------------\n",
            "Training Loss: 0.0155\n",
            "Validation Loss: 0.0166\n",
            "Epoch 188\n",
            "-------------------------------\n",
            "Training Loss: 0.0154\n",
            "Validation Loss: 0.0166\n",
            "Epoch 189\n",
            "-------------------------------\n",
            "Training Loss: 0.0156\n",
            "Validation Loss: 0.0179\n",
            "Epoch 190\n",
            "-------------------------------\n",
            "Training Loss: 0.0155\n",
            "Validation Loss: 0.0163\n",
            "Epoch 191\n",
            "-------------------------------\n",
            "Training Loss: 0.0156\n",
            "Validation Loss: 0.0170\n",
            "Epoch 192\n",
            "-------------------------------\n",
            "Training Loss: 0.0155\n",
            "Validation Loss: 0.0168\n",
            "Epoch 193\n",
            "-------------------------------\n",
            "Training Loss: 0.0153\n",
            "Validation Loss: 0.0164\n",
            "Epoch 194\n",
            "-------------------------------\n",
            "Training Loss: 0.0154\n",
            "Validation Loss: 0.0168\n",
            "Epoch 195\n",
            "-------------------------------\n",
            "Training Loss: 0.0153\n",
            "Validation Loss: 0.0170\n",
            "Epoch 196\n",
            "-------------------------------\n",
            "Training Loss: 0.0153\n",
            "Validation Loss: 0.0170\n",
            "Epoch 197\n",
            "-------------------------------\n",
            "Training Loss: 0.0151\n",
            "Validation Loss: 0.0164\n",
            "Epoch 198\n",
            "-------------------------------\n",
            "Training Loss: 0.0154\n",
            "Validation Loss: 0.0161\n",
            "Epoch 199\n",
            "-------------------------------\n",
            "Training Loss: 0.0151\n",
            "Validation Loss: 0.0163\n",
            "Epoch 200\n",
            "-------------------------------\n",
            "Training Loss: 0.0152\n",
            "Validation Loss: 0.0162\n",
            "Epoch 201\n",
            "-------------------------------\n",
            "Training Loss: 0.0152\n",
            "Validation Loss: 0.0199\n",
            "Epoch 202\n",
            "-------------------------------\n",
            "Training Loss: 0.0154\n",
            "Validation Loss: 0.0168\n",
            "Epoch 203\n",
            "-------------------------------\n",
            "Training Loss: 0.0152\n",
            "Validation Loss: 0.0167\n",
            "Epoch 204\n",
            "-------------------------------\n",
            "Training Loss: 0.0150\n",
            "Validation Loss: 0.0177\n",
            "Epoch 205\n",
            "-------------------------------\n",
            "Training Loss: 0.0152\n",
            "Validation Loss: 0.0166\n",
            "Epoch 206\n",
            "-------------------------------\n",
            "Training Loss: 0.0150\n",
            "Validation Loss: 0.0167\n",
            "Epoch 207\n",
            "-------------------------------\n",
            "Training Loss: 0.0150\n",
            "Validation Loss: 0.0166\n",
            "Epoch 208\n",
            "-------------------------------\n",
            "Training Loss: 0.0151\n",
            "Validation Loss: 0.0160\n",
            "Epoch 209\n",
            "-------------------------------\n",
            "Training Loss: 0.0151\n",
            "Validation Loss: 0.0175\n",
            "Epoch 210\n",
            "-------------------------------\n",
            "Training Loss: 0.0151\n",
            "Validation Loss: 0.0173\n",
            "Epoch 211\n",
            "-------------------------------\n",
            "Training Loss: 0.0149\n",
            "Validation Loss: 0.0166\n",
            "Epoch 212\n",
            "-------------------------------\n",
            "Training Loss: 0.0148\n",
            "Validation Loss: 0.0172\n",
            "Epoch 213\n",
            "-------------------------------\n",
            "Training Loss: 0.0148\n",
            "Validation Loss: 0.0170\n",
            "Epoch 214\n",
            "-------------------------------\n",
            "Training Loss: 0.0147\n",
            "Validation Loss: 0.0165\n",
            "Epoch 215\n",
            "-------------------------------\n",
            "Training Loss: 0.0148\n",
            "Validation Loss: 0.0176\n",
            "Epoch 216\n",
            "-------------------------------\n",
            "Training Loss: 0.0149\n",
            "Validation Loss: 0.0166\n",
            "Epoch 217\n",
            "-------------------------------\n",
            "Training Loss: 0.0147\n",
            "Validation Loss: 0.0158\n",
            "Epoch 218\n",
            "-------------------------------\n",
            "Training Loss: 0.0149\n",
            "Validation Loss: 0.0159\n",
            "Epoch 219\n",
            "-------------------------------\n",
            "Training Loss: 0.0147\n",
            "Validation Loss: 0.0161\n",
            "Epoch 220\n",
            "-------------------------------\n",
            "Training Loss: 0.0147\n",
            "Validation Loss: 0.0161\n",
            "Epoch 221\n",
            "-------------------------------\n",
            "Training Loss: 0.0148\n",
            "Validation Loss: 0.0171\n",
            "Epoch 222\n",
            "-------------------------------\n",
            "Training Loss: 0.0146\n",
            "Validation Loss: 0.0165\n",
            "Epoch 223\n",
            "-------------------------------\n",
            "Training Loss: 0.0146\n",
            "Validation Loss: 0.0158\n",
            "Epoch 224\n",
            "-------------------------------\n",
            "Training Loss: 0.0146\n",
            "Validation Loss: 0.0159\n",
            "Epoch 225\n",
            "-------------------------------\n",
            "Training Loss: 0.0148\n",
            "Validation Loss: 0.0158\n",
            "Epoch 226\n",
            "-------------------------------\n",
            "Training Loss: 0.0146\n",
            "Validation Loss: 0.0171\n",
            "Epoch 227\n",
            "-------------------------------\n",
            "Training Loss: 0.0146\n",
            "Validation Loss: 0.0163\n",
            "Epoch 228\n",
            "-------------------------------\n",
            "Training Loss: 0.0145\n",
            "Validation Loss: 0.0168\n",
            "Epoch 229\n",
            "-------------------------------\n",
            "Training Loss: 0.0146\n",
            "Validation Loss: 0.0161\n",
            "Epoch 230\n",
            "-------------------------------\n",
            "Training Loss: 0.0147\n",
            "Validation Loss: 0.0164\n",
            "Epoch 231\n",
            "-------------------------------\n",
            "Training Loss: 0.0145\n",
            "Validation Loss: 0.0155\n",
            "Epoch 232\n",
            "-------------------------------\n",
            "Training Loss: 0.0143\n",
            "Validation Loss: 0.0160\n",
            "Epoch 233\n",
            "-------------------------------\n",
            "Training Loss: 0.0147\n",
            "Validation Loss: 0.0154\n",
            "Epoch 234\n",
            "-------------------------------\n",
            "Training Loss: 0.0145\n",
            "Validation Loss: 0.0163\n",
            "Epoch 235\n",
            "-------------------------------\n",
            "Training Loss: 0.0146\n",
            "Validation Loss: 0.0163\n",
            "Epoch 236\n",
            "-------------------------------\n",
            "Training Loss: 0.0143\n",
            "Validation Loss: 0.0172\n",
            "Epoch 237\n",
            "-------------------------------\n",
            "Training Loss: 0.0144\n",
            "Validation Loss: 0.0167\n",
            "Epoch 238\n",
            "-------------------------------\n",
            "Training Loss: 0.0145\n",
            "Validation Loss: 0.0159\n",
            "Epoch 239\n",
            "-------------------------------\n",
            "Training Loss: 0.0143\n",
            "Validation Loss: 0.0158\n",
            "Epoch 240\n",
            "-------------------------------\n",
            "Training Loss: 0.0141\n",
            "Validation Loss: 0.0159\n",
            "Epoch 241\n",
            "-------------------------------\n",
            "Training Loss: 0.0142\n",
            "Validation Loss: 0.0157\n",
            "Epoch 242\n",
            "-------------------------------\n",
            "Training Loss: 0.0144\n",
            "Validation Loss: 0.0158\n",
            "Epoch 243\n",
            "-------------------------------\n",
            "Training Loss: 0.0142\n",
            "Validation Loss: 0.0156\n",
            "Epoch 244\n",
            "-------------------------------\n",
            "Training Loss: 0.0143\n",
            "Validation Loss: 0.0159\n",
            "Epoch 245\n",
            "-------------------------------\n",
            "Training Loss: 0.0142\n",
            "Validation Loss: 0.0154\n",
            "Epoch 246\n",
            "-------------------------------\n",
            "Training Loss: 0.0143\n",
            "Validation Loss: 0.0158\n",
            "Epoch 247\n",
            "-------------------------------\n",
            "Training Loss: 0.0143\n",
            "Validation Loss: 0.0160\n",
            "Epoch 248\n",
            "-------------------------------\n",
            "Training Loss: 0.0144\n",
            "Validation Loss: 0.0156\n",
            "Epoch 249\n",
            "-------------------------------\n",
            "Training Loss: 0.0142\n",
            "Validation Loss: 0.0159\n",
            "Epoch 250\n",
            "-------------------------------\n",
            "Training Loss: 0.0142\n",
            "Validation Loss: 0.0154\n",
            "Epoch 251\n",
            "-------------------------------\n",
            "Training Loss: 0.0142\n",
            "Validation Loss: 0.0156\n",
            "Epoch 252\n",
            "-------------------------------\n",
            "Training Loss: 0.0141\n",
            "Validation Loss: 0.0151\n",
            "Epoch 253\n",
            "-------------------------------\n",
            "Training Loss: 0.0140\n",
            "Validation Loss: 0.0153\n",
            "Epoch 254\n",
            "-------------------------------\n",
            "Training Loss: 0.0142\n",
            "Validation Loss: 0.0164\n",
            "Epoch 255\n",
            "-------------------------------\n",
            "Training Loss: 0.0141\n",
            "Validation Loss: 0.0151\n",
            "Epoch 256\n",
            "-------------------------------\n",
            "Training Loss: 0.0141\n",
            "Validation Loss: 0.0159\n",
            "Epoch 257\n",
            "-------------------------------\n",
            "Training Loss: 0.0140\n",
            "Validation Loss: 0.0162\n",
            "Epoch 258\n",
            "-------------------------------\n",
            "Training Loss: 0.0140\n",
            "Validation Loss: 0.0156\n",
            "Epoch 259\n",
            "-------------------------------\n",
            "Training Loss: 0.0141\n",
            "Validation Loss: 0.0159\n",
            "Epoch 260\n",
            "-------------------------------\n",
            "Training Loss: 0.0140\n",
            "Validation Loss: 0.0154\n",
            "Epoch 261\n",
            "-------------------------------\n",
            "Training Loss: 0.0142\n",
            "Validation Loss: 0.0157\n",
            "Epoch 262\n",
            "-------------------------------\n",
            "Training Loss: 0.0142\n",
            "Validation Loss: 0.0152\n",
            "Epoch 263\n",
            "-------------------------------\n",
            "Training Loss: 0.0139\n",
            "Validation Loss: 0.0156\n",
            "Epoch 264\n",
            "-------------------------------\n",
            "Training Loss: 0.0139\n",
            "Validation Loss: 0.0154\n",
            "Epoch 265\n",
            "-------------------------------\n",
            "Training Loss: 0.0140\n",
            "Validation Loss: 0.0174\n",
            "Epoch 266\n",
            "-------------------------------\n",
            "Training Loss: 0.0141\n",
            "Validation Loss: 0.0150\n",
            "Epoch 267\n",
            "-------------------------------\n",
            "Training Loss: 0.0140\n",
            "Validation Loss: 0.0150\n",
            "Epoch 268\n",
            "-------------------------------\n",
            "Training Loss: 0.0138\n",
            "Validation Loss: 0.0156\n",
            "Epoch 269\n",
            "-------------------------------\n",
            "Training Loss: 0.0139\n",
            "Validation Loss: 0.0153\n",
            "Epoch 270\n",
            "-------------------------------\n",
            "Training Loss: 0.0141\n",
            "Validation Loss: 0.0163\n",
            "Epoch 271\n",
            "-------------------------------\n",
            "Training Loss: 0.0137\n",
            "Validation Loss: 0.0154\n",
            "Epoch 272\n",
            "-------------------------------\n",
            "Training Loss: 0.0137\n",
            "Validation Loss: 0.0162\n",
            "Epoch 273\n",
            "-------------------------------\n",
            "Training Loss: 0.0139\n",
            "Validation Loss: 0.0154\n",
            "Epoch 274\n",
            "-------------------------------\n",
            "Training Loss: 0.0139\n",
            "Validation Loss: 0.0169\n",
            "Epoch 275\n",
            "-------------------------------\n",
            "Training Loss: 0.0138\n",
            "Validation Loss: 0.0159\n",
            "Epoch 276\n",
            "-------------------------------\n",
            "Training Loss: 0.0139\n",
            "Validation Loss: 0.0149\n",
            "Epoch 277\n",
            "-------------------------------\n",
            "Training Loss: 0.0139\n",
            "Validation Loss: 0.0171\n",
            "Epoch 278\n",
            "-------------------------------\n",
            "Training Loss: 0.0139\n",
            "Validation Loss: 0.0149\n",
            "Epoch 279\n",
            "-------------------------------\n",
            "Training Loss: 0.0138\n",
            "Validation Loss: 0.0155\n",
            "Epoch 280\n",
            "-------------------------------\n",
            "Training Loss: 0.0137\n",
            "Validation Loss: 0.0169\n",
            "Epoch 281\n",
            "-------------------------------\n",
            "Training Loss: 0.0138\n",
            "Validation Loss: 0.0159\n",
            "Epoch 282\n",
            "-------------------------------\n",
            "Training Loss: 0.0139\n",
            "Validation Loss: 0.0156\n",
            "Epoch 283\n",
            "-------------------------------\n",
            "Training Loss: 0.0136\n",
            "Validation Loss: 0.0156\n",
            "Epoch 284\n",
            "-------------------------------\n",
            "Training Loss: 0.0138\n",
            "Validation Loss: 0.0160\n",
            "Epoch 285\n",
            "-------------------------------\n",
            "Training Loss: 0.0138\n",
            "Validation Loss: 0.0153\n",
            "Epoch 286\n",
            "-------------------------------\n",
            "Training Loss: 0.0137\n",
            "Validation Loss: 0.0153\n",
            "Epoch 287\n",
            "-------------------------------\n",
            "Training Loss: 0.0137\n",
            "Validation Loss: 0.0159\n",
            "Epoch 288\n",
            "-------------------------------\n",
            "Training Loss: 0.0138\n",
            "Validation Loss: 0.0151\n",
            "Epoch 289\n",
            "-------------------------------\n",
            "Training Loss: 0.0138\n",
            "Validation Loss: 0.0172\n",
            "Epoch 290\n",
            "-------------------------------\n",
            "Training Loss: 0.0137\n",
            "Validation Loss: 0.0156\n",
            "Epoch 291\n",
            "-------------------------------\n",
            "Training Loss: 0.0137\n",
            "Validation Loss: 0.0152\n",
            "Epoch 292\n",
            "-------------------------------\n",
            "Training Loss: 0.0138\n",
            "Validation Loss: 0.0154\n",
            "Epoch 293\n",
            "-------------------------------\n",
            "Training Loss: 0.0136\n",
            "Validation Loss: 0.0149\n",
            "Epoch 294\n",
            "-------------------------------\n",
            "Training Loss: 0.0136\n",
            "Validation Loss: 0.0150\n",
            "Epoch 295\n",
            "-------------------------------\n",
            "Training Loss: 0.0137\n",
            "Validation Loss: 0.0152\n",
            "Epoch 296\n",
            "-------------------------------\n",
            "Training Loss: 0.0135\n",
            "Validation Loss: 0.0158\n",
            "Epoch 297\n",
            "-------------------------------\n",
            "Training Loss: 0.0135\n",
            "Validation Loss: 0.0154\n",
            "Epoch 298\n",
            "-------------------------------\n",
            "Training Loss: 0.0137\n",
            "Validation Loss: 0.0151\n",
            "Epoch 299\n",
            "-------------------------------\n",
            "Training Loss: 0.0134\n",
            "Validation Loss: 0.0162\n",
            "Epoch 300\n",
            "-------------------------------\n",
            "Training Loss: 0.0134\n",
            "Validation Loss: 0.0149\n",
            "Epoch 301\n",
            "-------------------------------\n",
            "Training Loss: 0.0136\n",
            "Validation Loss: 0.0177\n",
            "Epoch 302\n",
            "-------------------------------\n",
            "Training Loss: 0.0135\n",
            "Validation Loss: 0.0162\n",
            "Epoch 303\n",
            "-------------------------------\n",
            "Training Loss: 0.0134\n",
            "Validation Loss: 0.0153\n",
            "Epoch 304\n",
            "-------------------------------\n",
            "Training Loss: 0.0134\n",
            "Validation Loss: 0.0186\n",
            "Epoch 305\n",
            "-------------------------------\n",
            "Training Loss: 0.0136\n",
            "Validation Loss: 0.0156\n",
            "Epoch 306\n",
            "-------------------------------\n",
            "Training Loss: 0.0136\n",
            "Validation Loss: 0.0157\n",
            "Epoch 307\n",
            "-------------------------------\n",
            "Training Loss: 0.0134\n",
            "Validation Loss: 0.0154\n",
            "Epoch 308\n",
            "-------------------------------\n",
            "Training Loss: 0.0135\n",
            "Validation Loss: 0.0149\n",
            "Epoch 309\n",
            "-------------------------------\n",
            "Training Loss: 0.0134\n",
            "Validation Loss: 0.0160\n",
            "Epoch 310\n",
            "-------------------------------\n",
            "Training Loss: 0.0135\n",
            "Validation Loss: 0.0150\n",
            "Epoch 311\n",
            "-------------------------------\n",
            "Training Loss: 0.0133\n",
            "Validation Loss: 0.0149\n",
            "Epoch 312\n",
            "-------------------------------\n",
            "Training Loss: 0.0134\n",
            "Validation Loss: 0.0157\n",
            "Epoch 313\n",
            "-------------------------------\n",
            "Training Loss: 0.0132\n",
            "Validation Loss: 0.0153\n",
            "Epoch 314\n",
            "-------------------------------\n",
            "Training Loss: 0.0133\n",
            "Validation Loss: 0.0169\n",
            "Epoch 315\n",
            "-------------------------------\n",
            "Training Loss: 0.0134\n",
            "Validation Loss: 0.0152\n",
            "Epoch 316\n",
            "-------------------------------\n",
            "Training Loss: 0.0135\n",
            "Validation Loss: 0.0147\n",
            "Epoch 317\n",
            "-------------------------------\n",
            "Training Loss: 0.0134\n",
            "Validation Loss: 0.0158\n",
            "Epoch 318\n",
            "-------------------------------\n",
            "Training Loss: 0.0134\n",
            "Validation Loss: 0.0154\n",
            "Epoch 319\n",
            "-------------------------------\n",
            "Training Loss: 0.0132\n",
            "Validation Loss: 0.0153\n",
            "Epoch 320\n",
            "-------------------------------\n",
            "Training Loss: 0.0135\n",
            "Validation Loss: 0.0148\n",
            "Epoch 321\n",
            "-------------------------------\n",
            "Training Loss: 0.0133\n",
            "Validation Loss: 0.0152\n",
            "Epoch 322\n",
            "-------------------------------\n",
            "Training Loss: 0.0133\n",
            "Validation Loss: 0.0151\n",
            "Epoch 323\n",
            "-------------------------------\n",
            "Training Loss: 0.0134\n",
            "Validation Loss: 0.0156\n",
            "Epoch 324\n",
            "-------------------------------\n",
            "Training Loss: 0.0132\n",
            "Validation Loss: 0.0159\n",
            "Epoch 325\n",
            "-------------------------------\n",
            "Training Loss: 0.0133\n",
            "Validation Loss: 0.0157\n",
            "Epoch 326\n",
            "-------------------------------\n",
            "Training Loss: 0.0131\n",
            "Validation Loss: 0.0158\n",
            "Epoch 327\n",
            "-------------------------------\n",
            "Training Loss: 0.0132\n",
            "Validation Loss: 0.0148\n",
            "Epoch 328\n",
            "-------------------------------\n",
            "Training Loss: 0.0132\n",
            "Validation Loss: 0.0162\n",
            "Epoch 329\n",
            "-------------------------------\n",
            "Training Loss: 0.0131\n",
            "Validation Loss: 0.0151\n",
            "Epoch 330\n",
            "-------------------------------\n",
            "Training Loss: 0.0132\n",
            "Validation Loss: 0.0151\n",
            "Epoch 331\n",
            "-------------------------------\n",
            "Training Loss: 0.0132\n",
            "Validation Loss: 0.0165\n",
            "Epoch 332\n",
            "-------------------------------\n",
            "Training Loss: 0.0133\n",
            "Validation Loss: 0.0147\n",
            "Epoch 333\n",
            "-------------------------------\n",
            "Training Loss: 0.0130\n",
            "Validation Loss: 0.0158\n",
            "Epoch 334\n",
            "-------------------------------\n",
            "Training Loss: 0.0134\n",
            "Validation Loss: 0.0147\n",
            "Epoch 335\n",
            "-------------------------------\n",
            "Training Loss: 0.0130\n",
            "Validation Loss: 0.0160\n",
            "Epoch 336\n",
            "-------------------------------\n",
            "Training Loss: 0.0131\n",
            "Validation Loss: 0.0146\n",
            "Epoch 337\n",
            "-------------------------------\n",
            "Training Loss: 0.0131\n",
            "Validation Loss: 0.0150\n",
            "Epoch 338\n",
            "-------------------------------\n",
            "Training Loss: 0.0130\n",
            "Validation Loss: 0.0151\n",
            "Epoch 339\n",
            "-------------------------------\n",
            "Training Loss: 0.0130\n",
            "Validation Loss: 0.0159\n",
            "Epoch 340\n",
            "-------------------------------\n",
            "Training Loss: 0.0130\n",
            "Validation Loss: 0.0147\n",
            "Epoch 341\n",
            "-------------------------------\n",
            "Training Loss: 0.0129\n",
            "Validation Loss: 0.0152\n",
            "Epoch 342\n",
            "-------------------------------\n",
            "Training Loss: 0.0130\n",
            "Validation Loss: 0.0147\n",
            "Epoch 343\n",
            "-------------------------------\n",
            "Training Loss: 0.0134\n",
            "Validation Loss: 0.0152\n",
            "Epoch 344\n",
            "-------------------------------\n",
            "Training Loss: 0.0132\n",
            "Validation Loss: 0.0155\n",
            "Epoch 345\n",
            "-------------------------------\n",
            "Training Loss: 0.0128\n",
            "Validation Loss: 0.0152\n",
            "Epoch 346\n",
            "-------------------------------\n",
            "Training Loss: 0.0132\n",
            "Validation Loss: 0.0151\n",
            "Epoch 347\n",
            "-------------------------------\n",
            "Training Loss: 0.0130\n",
            "Validation Loss: 0.0144\n",
            "Epoch 348\n",
            "-------------------------------\n",
            "Training Loss: 0.0130\n",
            "Validation Loss: 0.0162\n",
            "Epoch 349\n",
            "-------------------------------\n",
            "Training Loss: 0.0132\n",
            "Validation Loss: 0.0152\n",
            "Epoch 350\n",
            "-------------------------------\n",
            "Training Loss: 0.0130\n",
            "Validation Loss: 0.0155\n",
            "Epoch 351\n",
            "-------------------------------\n",
            "Training Loss: 0.0130\n",
            "Validation Loss: 0.0144\n",
            "Epoch 352\n",
            "-------------------------------\n",
            "Training Loss: 0.0128\n",
            "Validation Loss: 0.0146\n",
            "Epoch 353\n",
            "-------------------------------\n",
            "Training Loss: 0.0129\n",
            "Validation Loss: 0.0148\n",
            "Epoch 354\n",
            "-------------------------------\n",
            "Training Loss: 0.0129\n",
            "Validation Loss: 0.0147\n",
            "Epoch 355\n",
            "-------------------------------\n",
            "Training Loss: 0.0131\n",
            "Validation Loss: 0.0145\n",
            "Epoch 356\n",
            "-------------------------------\n",
            "Training Loss: 0.0130\n",
            "Validation Loss: 0.0151\n",
            "Epoch 357\n",
            "-------------------------------\n",
            "Training Loss: 0.0129\n",
            "Validation Loss: 0.0146\n",
            "Epoch 358\n",
            "-------------------------------\n",
            "Training Loss: 0.0128\n",
            "Validation Loss: 0.0146\n",
            "Epoch 359\n",
            "-------------------------------\n",
            "Training Loss: 0.0129\n",
            "Validation Loss: 0.0159\n",
            "Epoch 360\n",
            "-------------------------------\n",
            "Training Loss: 0.0129\n",
            "Validation Loss: 0.0145\n",
            "Epoch 361\n",
            "-------------------------------\n",
            "Training Loss: 0.0128\n",
            "Validation Loss: 0.0157\n",
            "Epoch 362\n",
            "-------------------------------\n",
            "Training Loss: 0.0128\n",
            "Validation Loss: 0.0149\n",
            "Epoch 363\n",
            "-------------------------------\n",
            "Training Loss: 0.0129\n",
            "Validation Loss: 0.0155\n",
            "Epoch 364\n",
            "-------------------------------\n",
            "Training Loss: 0.0130\n",
            "Validation Loss: 0.0146\n",
            "Epoch 365\n",
            "-------------------------------\n",
            "Training Loss: 0.0127\n",
            "Validation Loss: 0.0143\n",
            "Epoch 366\n",
            "-------------------------------\n",
            "Training Loss: 0.0127\n",
            "Validation Loss: 0.0146\n",
            "Epoch 367\n",
            "-------------------------------\n",
            "Training Loss: 0.0127\n",
            "Validation Loss: 0.0149\n",
            "Epoch 368\n",
            "-------------------------------\n",
            "Training Loss: 0.0127\n",
            "Validation Loss: 0.0154\n",
            "Epoch 369\n",
            "-------------------------------\n",
            "Training Loss: 0.0127\n",
            "Validation Loss: 0.0149\n",
            "Epoch 370\n",
            "-------------------------------\n",
            "Training Loss: 0.0128\n",
            "Validation Loss: 0.0147\n",
            "Epoch 371\n",
            "-------------------------------\n",
            "Training Loss: 0.0126\n",
            "Validation Loss: 0.0151\n",
            "Epoch 372\n",
            "-------------------------------\n",
            "Training Loss: 0.0127\n",
            "Validation Loss: 0.0149\n",
            "Epoch 373\n",
            "-------------------------------\n",
            "Training Loss: 0.0126\n",
            "Validation Loss: 0.0147\n",
            "Epoch 374\n",
            "-------------------------------\n",
            "Training Loss: 0.0126\n",
            "Validation Loss: 0.0156\n",
            "Epoch 375\n",
            "-------------------------------\n",
            "Training Loss: 0.0126\n",
            "Validation Loss: 0.0148\n",
            "Epoch 376\n",
            "-------------------------------\n",
            "Training Loss: 0.0127\n",
            "Validation Loss: 0.0144\n",
            "Epoch 377\n",
            "-------------------------------\n",
            "Training Loss: 0.0129\n",
            "Validation Loss: 0.0142\n",
            "Epoch 378\n",
            "-------------------------------\n",
            "Training Loss: 0.0126\n",
            "Validation Loss: 0.0150\n",
            "Epoch 379\n",
            "-------------------------------\n",
            "Training Loss: 0.0127\n",
            "Validation Loss: 0.0147\n",
            "Epoch 380\n",
            "-------------------------------\n",
            "Training Loss: 0.0126\n",
            "Validation Loss: 0.0147\n",
            "Epoch 381\n",
            "-------------------------------\n",
            "Training Loss: 0.0125\n",
            "Validation Loss: 0.0154\n",
            "Epoch 382\n",
            "-------------------------------\n",
            "Training Loss: 0.0126\n",
            "Validation Loss: 0.0159\n",
            "Epoch 383\n",
            "-------------------------------\n",
            "Training Loss: 0.0127\n",
            "Validation Loss: 0.0152\n",
            "Epoch 384\n",
            "-------------------------------\n",
            "Training Loss: 0.0128\n",
            "Validation Loss: 0.0142\n",
            "Epoch 385\n",
            "-------------------------------\n",
            "Training Loss: 0.0125\n",
            "Validation Loss: 0.0146\n",
            "Epoch 386\n",
            "-------------------------------\n",
            "Training Loss: 0.0126\n",
            "Validation Loss: 0.0148\n",
            "Epoch 387\n",
            "-------------------------------\n",
            "Training Loss: 0.0127\n",
            "Validation Loss: 0.0157\n",
            "Epoch 388\n",
            "-------------------------------\n",
            "Training Loss: 0.0125\n",
            "Validation Loss: 0.0160\n",
            "Epoch 389\n",
            "-------------------------------\n",
            "Training Loss: 0.0125\n",
            "Validation Loss: 0.0146\n",
            "Epoch 390\n",
            "-------------------------------\n",
            "Training Loss: 0.0125\n",
            "Validation Loss: 0.0151\n",
            "Epoch 391\n",
            "-------------------------------\n",
            "Training Loss: 0.0127\n",
            "Validation Loss: 0.0147\n",
            "Epoch 392\n",
            "-------------------------------\n",
            "Training Loss: 0.0127\n",
            "Validation Loss: 0.0157\n",
            "Epoch 393\n",
            "-------------------------------\n",
            "Training Loss: 0.0125\n",
            "Validation Loss: 0.0148\n",
            "Epoch 394\n",
            "-------------------------------\n",
            "Training Loss: 0.0127\n",
            "Validation Loss: 0.0144\n",
            "Epoch 395\n",
            "-------------------------------\n",
            "Training Loss: 0.0124\n",
            "Validation Loss: 0.0143\n",
            "Epoch 396\n",
            "-------------------------------\n",
            "Training Loss: 0.0124\n",
            "Validation Loss: 0.0143\n",
            "Epoch 397\n",
            "-------------------------------\n",
            "Training Loss: 0.0124\n",
            "Validation Loss: 0.0161\n",
            "Epoch 398\n",
            "-------------------------------\n",
            "Training Loss: 0.0125\n",
            "Validation Loss: 0.0144\n",
            "Epoch 399\n",
            "-------------------------------\n",
            "Training Loss: 0.0125\n",
            "Validation Loss: 0.0152\n",
            "Epoch 400\n",
            "-------------------------------\n",
            "Training Loss: 0.0126\n",
            "Validation Loss: 0.0145\n",
            "Epoch 401\n",
            "-------------------------------\n",
            "Training Loss: 0.0125\n",
            "Validation Loss: 0.0154\n",
            "Epoch 402\n",
            "-------------------------------\n",
            "Training Loss: 0.0126\n",
            "Validation Loss: 0.0148\n",
            "Epoch 403\n",
            "-------------------------------\n",
            "Training Loss: 0.0126\n",
            "Validation Loss: 0.0146\n",
            "Epoch 404\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0154\n",
            "Epoch 405\n",
            "-------------------------------\n",
            "Training Loss: 0.0124\n",
            "Validation Loss: 0.0149\n",
            "Epoch 406\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0154\n",
            "Epoch 407\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0148\n",
            "Epoch 408\n",
            "-------------------------------\n",
            "Training Loss: 0.0124\n",
            "Validation Loss: 0.0144\n",
            "Epoch 409\n",
            "-------------------------------\n",
            "Training Loss: 0.0124\n",
            "Validation Loss: 0.0151\n",
            "Epoch 410\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0143\n",
            "Epoch 411\n",
            "-------------------------------\n",
            "Training Loss: 0.0125\n",
            "Validation Loss: 0.0149\n",
            "Epoch 412\n",
            "-------------------------------\n",
            "Training Loss: 0.0124\n",
            "Validation Loss: 0.0145\n",
            "Epoch 413\n",
            "-------------------------------\n",
            "Training Loss: 0.0124\n",
            "Validation Loss: 0.0153\n",
            "Epoch 414\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0147\n",
            "Epoch 415\n",
            "-------------------------------\n",
            "Training Loss: 0.0125\n",
            "Validation Loss: 0.0151\n",
            "Epoch 416\n",
            "-------------------------------\n",
            "Training Loss: 0.0122\n",
            "Validation Loss: 0.0149\n",
            "Epoch 417\n",
            "-------------------------------\n",
            "Training Loss: 0.0124\n",
            "Validation Loss: 0.0147\n",
            "Epoch 418\n",
            "-------------------------------\n",
            "Training Loss: 0.0121\n",
            "Validation Loss: 0.0149\n",
            "Epoch 419\n",
            "-------------------------------\n",
            "Training Loss: 0.0124\n",
            "Validation Loss: 0.0152\n",
            "Epoch 420\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0149\n",
            "Epoch 421\n",
            "-------------------------------\n",
            "Training Loss: 0.0122\n",
            "Validation Loss: 0.0159\n",
            "Epoch 422\n",
            "-------------------------------\n",
            "Training Loss: 0.0122\n",
            "Validation Loss: 0.0149\n",
            "Epoch 423\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0144\n",
            "Epoch 424\n",
            "-------------------------------\n",
            "Training Loss: 0.0122\n",
            "Validation Loss: 0.0144\n",
            "Epoch 425\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0148\n",
            "Epoch 426\n",
            "-------------------------------\n",
            "Training Loss: 0.0122\n",
            "Validation Loss: 0.0145\n",
            "Epoch 427\n",
            "-------------------------------\n",
            "Training Loss: 0.0122\n",
            "Validation Loss: 0.0143\n",
            "Epoch 428\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0147\n",
            "Epoch 429\n",
            "-------------------------------\n",
            "Training Loss: 0.0122\n",
            "Validation Loss: 0.0143\n",
            "Epoch 430\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0144\n",
            "Epoch 431\n",
            "-------------------------------\n",
            "Training Loss: 0.0121\n",
            "Validation Loss: 0.0150\n",
            "Epoch 432\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0144\n",
            "Epoch 433\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0146\n",
            "Epoch 434\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0144\n",
            "Epoch 435\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0139\n",
            "Epoch 436\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0142\n",
            "Epoch 437\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0143\n",
            "Epoch 438\n",
            "-------------------------------\n",
            "Training Loss: 0.0122\n",
            "Validation Loss: 0.0143\n",
            "Epoch 439\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0142\n",
            "Epoch 440\n",
            "-------------------------------\n",
            "Training Loss: 0.0121\n",
            "Validation Loss: 0.0142\n",
            "Epoch 441\n",
            "-------------------------------\n",
            "Training Loss: 0.0122\n",
            "Validation Loss: 0.0144\n",
            "Epoch 442\n",
            "-------------------------------\n",
            "Training Loss: 0.0123\n",
            "Validation Loss: 0.0148\n",
            "Epoch 443\n",
            "-------------------------------\n",
            "Training Loss: 0.0118\n",
            "Validation Loss: 0.0141\n",
            "Epoch 444\n",
            "-------------------------------\n",
            "Training Loss: 0.0121\n",
            "Validation Loss: 0.0154\n",
            "Epoch 445\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0143\n",
            "Epoch 446\n",
            "-------------------------------\n",
            "Training Loss: 0.0122\n",
            "Validation Loss: 0.0147\n",
            "Epoch 447\n",
            "-------------------------------\n",
            "Training Loss: 0.0121\n",
            "Validation Loss: 0.0152\n",
            "Epoch 448\n",
            "-------------------------------\n",
            "Training Loss: 0.0121\n",
            "Validation Loss: 0.0146\n",
            "Epoch 449\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0144\n",
            "Epoch 450\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0141\n",
            "Epoch 451\n",
            "-------------------------------\n",
            "Training Loss: 0.0119\n",
            "Validation Loss: 0.0146\n",
            "Epoch 452\n",
            "-------------------------------\n",
            "Training Loss: 0.0121\n",
            "Validation Loss: 0.0145\n",
            "Epoch 453\n",
            "-------------------------------\n",
            "Training Loss: 0.0121\n",
            "Validation Loss: 0.0139\n",
            "Epoch 454\n",
            "-------------------------------\n",
            "Training Loss: 0.0122\n",
            "Validation Loss: 0.0146\n",
            "Epoch 455\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0149\n",
            "Epoch 456\n",
            "-------------------------------\n",
            "Training Loss: 0.0121\n",
            "Validation Loss: 0.0149\n",
            "Epoch 457\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0143\n",
            "Epoch 458\n",
            "-------------------------------\n",
            "Training Loss: 0.0119\n",
            "Validation Loss: 0.0138\n",
            "Epoch 459\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0141\n",
            "Epoch 460\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0141\n",
            "Epoch 461\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0142\n",
            "Epoch 462\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0145\n",
            "Epoch 463\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0142\n",
            "Epoch 464\n",
            "-------------------------------\n",
            "Training Loss: 0.0119\n",
            "Validation Loss: 0.0144\n",
            "Epoch 465\n",
            "-------------------------------\n",
            "Training Loss: 0.0118\n",
            "Validation Loss: 0.0142\n",
            "Epoch 466\n",
            "-------------------------------\n",
            "Training Loss: 0.0119\n",
            "Validation Loss: 0.0143\n",
            "Epoch 467\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0147\n",
            "Epoch 468\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0162\n",
            "Epoch 469\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0152\n",
            "Epoch 470\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0139\n",
            "Epoch 471\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0148\n",
            "Epoch 472\n",
            "-------------------------------\n",
            "Training Loss: 0.0118\n",
            "Validation Loss: 0.0147\n",
            "Epoch 473\n",
            "-------------------------------\n",
            "Training Loss: 0.0120\n",
            "Validation Loss: 0.0139\n",
            "Epoch 474\n",
            "-------------------------------\n",
            "Training Loss: 0.0119\n",
            "Validation Loss: 0.0143\n",
            "Epoch 475\n",
            "-------------------------------\n",
            "Training Loss: 0.0118\n",
            "Validation Loss: 0.0150\n",
            "Epoch 476\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0149\n",
            "Epoch 477\n",
            "-------------------------------\n",
            "Training Loss: 0.0118\n",
            "Validation Loss: 0.0141\n",
            "Epoch 478\n",
            "-------------------------------\n",
            "Training Loss: 0.0119\n",
            "Validation Loss: 0.0150\n",
            "Epoch 479\n",
            "-------------------------------\n",
            "Training Loss: 0.0119\n",
            "Validation Loss: 0.0142\n",
            "Epoch 480\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0143\n",
            "Epoch 481\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0141\n",
            "Epoch 482\n",
            "-------------------------------\n",
            "Training Loss: 0.0118\n",
            "Validation Loss: 0.0139\n",
            "Epoch 483\n",
            "-------------------------------\n",
            "Training Loss: 0.0118\n",
            "Validation Loss: 0.0142\n",
            "Epoch 484\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0140\n",
            "Epoch 485\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0151\n",
            "Epoch 486\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0141\n",
            "Epoch 487\n",
            "-------------------------------\n",
            "Training Loss: 0.0118\n",
            "Validation Loss: 0.0147\n",
            "Epoch 488\n",
            "-------------------------------\n",
            "Training Loss: 0.0118\n",
            "Validation Loss: 0.0137\n",
            "Epoch 489\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0143\n",
            "Epoch 490\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0141\n",
            "Epoch 491\n",
            "-------------------------------\n",
            "Training Loss: 0.0118\n",
            "Validation Loss: 0.0143\n",
            "Epoch 492\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0139\n",
            "Epoch 493\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0140\n",
            "Epoch 494\n",
            "-------------------------------\n",
            "Training Loss: 0.0115\n",
            "Validation Loss: 0.0143\n",
            "Epoch 495\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0141\n",
            "Epoch 496\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0163\n",
            "Epoch 497\n",
            "-------------------------------\n",
            "Training Loss: 0.0118\n",
            "Validation Loss: 0.0142\n",
            "Epoch 498\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0139\n",
            "Epoch 499\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0138\n",
            "Epoch 500\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0139\n",
            "Epoch 501\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0142\n",
            "Epoch 502\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0142\n",
            "Epoch 503\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0142\n",
            "Epoch 504\n",
            "-------------------------------\n",
            "Training Loss: 0.0118\n",
            "Validation Loss: 0.0140\n",
            "Epoch 505\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0137\n",
            "Epoch 506\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0141\n",
            "Epoch 507\n",
            "-------------------------------\n",
            "Training Loss: 0.0115\n",
            "Validation Loss: 0.0146\n",
            "Epoch 508\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0142\n",
            "Epoch 509\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0136\n",
            "Epoch 510\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0140\n",
            "Epoch 511\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0156\n",
            "Epoch 512\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0155\n",
            "Epoch 513\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0140\n",
            "Epoch 514\n",
            "-------------------------------\n",
            "Training Loss: 0.0115\n",
            "Validation Loss: 0.0140\n",
            "Epoch 515\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0145\n",
            "Epoch 516\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0141\n",
            "Epoch 517\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0144\n",
            "Epoch 518\n",
            "-------------------------------\n",
            "Training Loss: 0.0115\n",
            "Validation Loss: 0.0142\n",
            "Epoch 519\n",
            "-------------------------------\n",
            "Training Loss: 0.0115\n",
            "Validation Loss: 0.0140\n",
            "Epoch 520\n",
            "-------------------------------\n",
            "Training Loss: 0.0115\n",
            "Validation Loss: 0.0144\n",
            "Epoch 521\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0137\n",
            "Epoch 522\n",
            "-------------------------------\n",
            "Training Loss: 0.0115\n",
            "Validation Loss: 0.0146\n",
            "Epoch 523\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0136\n",
            "Epoch 524\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0142\n",
            "Epoch 525\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0136\n",
            "Epoch 526\n",
            "-------------------------------\n",
            "Training Loss: 0.0115\n",
            "Validation Loss: 0.0152\n",
            "Epoch 527\n",
            "-------------------------------\n",
            "Training Loss: 0.0115\n",
            "Validation Loss: 0.0140\n",
            "Epoch 528\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0138\n",
            "Epoch 529\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0137\n",
            "Epoch 530\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0144\n",
            "Epoch 531\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0140\n",
            "Epoch 532\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0148\n",
            "Epoch 533\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0146\n",
            "Epoch 534\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0143\n",
            "Epoch 535\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0154\n",
            "Epoch 536\n",
            "-------------------------------\n",
            "Training Loss: 0.0115\n",
            "Validation Loss: 0.0152\n",
            "Epoch 537\n",
            "-------------------------------\n",
            "Training Loss: 0.0113\n",
            "Validation Loss: 0.0148\n",
            "Epoch 538\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0140\n",
            "Epoch 539\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0139\n",
            "Epoch 540\n",
            "-------------------------------\n",
            "Training Loss: 0.0116\n",
            "Validation Loss: 0.0146\n",
            "Epoch 541\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0140\n",
            "Epoch 542\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0137\n",
            "Epoch 543\n",
            "-------------------------------\n",
            "Training Loss: 0.0113\n",
            "Validation Loss: 0.0142\n",
            "Epoch 544\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0140\n",
            "Epoch 545\n",
            "-------------------------------\n",
            "Training Loss: 0.0115\n",
            "Validation Loss: 0.0147\n",
            "Epoch 546\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0140\n",
            "Epoch 547\n",
            "-------------------------------\n",
            "Training Loss: 0.0113\n",
            "Validation Loss: 0.0139\n",
            "Epoch 548\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0139\n",
            "Epoch 549\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0142\n",
            "Epoch 550\n",
            "-------------------------------\n",
            "Training Loss: 0.0115\n",
            "Validation Loss: 0.0148\n",
            "Epoch 551\n",
            "-------------------------------\n",
            "Training Loss: 0.0113\n",
            "Validation Loss: 0.0138\n",
            "Epoch 552\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0142\n",
            "Epoch 553\n",
            "-------------------------------\n",
            "Training Loss: 0.0113\n",
            "Validation Loss: 0.0142\n",
            "Epoch 554\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0138\n",
            "Epoch 555\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0136\n",
            "Epoch 556\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0141\n",
            "Epoch 557\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0137\n",
            "Epoch 558\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0134\n",
            "Epoch 559\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0138\n",
            "Epoch 560\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0161\n",
            "Epoch 561\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0137\n",
            "Epoch 562\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0141\n",
            "Epoch 563\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0137\n",
            "Epoch 564\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0139\n",
            "Epoch 565\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0139\n",
            "Epoch 566\n",
            "-------------------------------\n",
            "Training Loss: 0.0113\n",
            "Validation Loss: 0.0139\n",
            "Epoch 567\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0140\n",
            "Epoch 568\n",
            "-------------------------------\n",
            "Training Loss: 0.0113\n",
            "Validation Loss: 0.0141\n",
            "Epoch 569\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0140\n",
            "Epoch 570\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0143\n",
            "Epoch 571\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0134\n",
            "Epoch 572\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0142\n",
            "Epoch 573\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0140\n",
            "Epoch 574\n",
            "-------------------------------\n",
            "Training Loss: 0.0113\n",
            "Validation Loss: 0.0135\n",
            "Epoch 575\n",
            "-------------------------------\n",
            "Training Loss: 0.0113\n",
            "Validation Loss: 0.0134\n",
            "Epoch 576\n",
            "-------------------------------\n",
            "Training Loss: 0.0110\n",
            "Validation Loss: 0.0141\n",
            "Epoch 577\n",
            "-------------------------------\n",
            "Training Loss: 0.0113\n",
            "Validation Loss: 0.0137\n",
            "Epoch 578\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0150\n",
            "Epoch 579\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0139\n",
            "Epoch 580\n",
            "-------------------------------\n",
            "Training Loss: 0.0114\n",
            "Validation Loss: 0.0135\n",
            "Epoch 581\n",
            "-------------------------------\n",
            "Training Loss: 0.0110\n",
            "Validation Loss: 0.0140\n",
            "Epoch 582\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0140\n",
            "Epoch 583\n",
            "-------------------------------\n",
            "Training Loss: 0.0110\n",
            "Validation Loss: 0.0136\n",
            "Epoch 584\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0140\n",
            "Epoch 585\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0139\n",
            "Epoch 586\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0134\n",
            "Epoch 587\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0135\n",
            "Epoch 588\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0139\n",
            "Epoch 589\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0137\n",
            "Epoch 590\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0137\n",
            "Epoch 591\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0137\n",
            "Epoch 592\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0134\n",
            "Epoch 593\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0135\n",
            "Epoch 594\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0137\n",
            "Epoch 595\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0149\n",
            "Epoch 596\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0152\n",
            "Epoch 597\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0138\n",
            "Epoch 598\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0138\n",
            "Epoch 599\n",
            "-------------------------------\n",
            "Training Loss: 0.0110\n",
            "Validation Loss: 0.0135\n",
            "Epoch 600\n",
            "-------------------------------\n",
            "Training Loss: 0.0110\n",
            "Validation Loss: 0.0138\n",
            "Epoch 601\n",
            "-------------------------------\n",
            "Training Loss: 0.0110\n",
            "Validation Loss: 0.0141\n",
            "Epoch 602\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0142\n",
            "Epoch 603\n",
            "-------------------------------\n",
            "Training Loss: 0.0110\n",
            "Validation Loss: 0.0134\n",
            "Epoch 604\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0137\n",
            "Epoch 605\n",
            "-------------------------------\n",
            "Training Loss: 0.0110\n",
            "Validation Loss: 0.0146\n",
            "Epoch 606\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0135\n",
            "Epoch 607\n",
            "-------------------------------\n",
            "Training Loss: 0.0110\n",
            "Validation Loss: 0.0134\n",
            "Epoch 608\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0139\n",
            "Epoch 609\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0137\n",
            "Epoch 610\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0143\n",
            "Epoch 611\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0145\n",
            "Epoch 612\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0141\n",
            "Epoch 613\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0142\n",
            "Epoch 614\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0134\n",
            "Epoch 615\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0146\n",
            "Epoch 616\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0137\n",
            "Epoch 617\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0143\n",
            "Epoch 618\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0137\n",
            "Epoch 619\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0134\n",
            "Epoch 620\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0170\n",
            "Epoch 621\n",
            "-------------------------------\n",
            "Training Loss: 0.0110\n",
            "Validation Loss: 0.0149\n",
            "Epoch 622\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0135\n",
            "Epoch 623\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0139\n",
            "Epoch 624\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0141\n",
            "Epoch 625\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0135\n",
            "Epoch 626\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0135\n",
            "Epoch 627\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0137\n",
            "Epoch 628\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0135\n",
            "Epoch 629\n",
            "-------------------------------\n",
            "Training Loss: 0.0111\n",
            "Validation Loss: 0.0133\n",
            "Epoch 630\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0135\n",
            "Epoch 631\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0133\n",
            "Epoch 632\n",
            "-------------------------------\n",
            "Training Loss: 0.0110\n",
            "Validation Loss: 0.0139\n",
            "Epoch 633\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0134\n",
            "Epoch 634\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0137\n",
            "Epoch 635\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0137\n",
            "Epoch 636\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0138\n",
            "Epoch 637\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0135\n",
            "Epoch 638\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0146\n",
            "Epoch 639\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0135\n",
            "Epoch 640\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0140\n",
            "Epoch 641\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0140\n",
            "Epoch 642\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0140\n",
            "Epoch 643\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0136\n",
            "Epoch 644\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0132\n",
            "Epoch 645\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0135\n",
            "Epoch 646\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0135\n",
            "Epoch 647\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0143\n",
            "Epoch 648\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0133\n",
            "Epoch 649\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0140\n",
            "Epoch 650\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0134\n",
            "Epoch 651\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0145\n",
            "Epoch 652\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0141\n",
            "Epoch 653\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0134\n",
            "Epoch 654\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0136\n",
            "Epoch 655\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0135\n",
            "Epoch 656\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0134\n",
            "Epoch 657\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0135\n",
            "Epoch 658\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0139\n",
            "Epoch 659\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0146\n",
            "Epoch 660\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0138\n",
            "Epoch 661\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0131\n",
            "Epoch 662\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0132\n",
            "Epoch 663\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0134\n",
            "Epoch 664\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0137\n",
            "Epoch 665\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0136\n",
            "Epoch 666\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0133\n",
            "Epoch 667\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0134\n",
            "Epoch 668\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0136\n",
            "Epoch 669\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0131\n",
            "Epoch 670\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0132\n",
            "Epoch 671\n",
            "-------------------------------\n",
            "Training Loss: 0.0109\n",
            "Validation Loss: 0.0138\n",
            "Epoch 672\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0134\n",
            "Epoch 673\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0142\n",
            "Epoch 674\n",
            "-------------------------------\n",
            "Training Loss: 0.0107\n",
            "Validation Loss: 0.0141\n",
            "Epoch 675\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0142\n",
            "Epoch 676\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0135\n",
            "Epoch 677\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0133\n",
            "Epoch 678\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0161\n",
            "Epoch 679\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0136\n",
            "Epoch 680\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0131\n",
            "Epoch 681\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0150\n",
            "Epoch 682\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0134\n",
            "Epoch 683\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0137\n",
            "Epoch 684\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0130\n",
            "Epoch 685\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0132\n",
            "Epoch 686\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0135\n",
            "Epoch 687\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0135\n",
            "Epoch 688\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0136\n",
            "Epoch 689\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0133\n",
            "Epoch 690\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0136\n",
            "Epoch 691\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0141\n",
            "Epoch 692\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0135\n",
            "Epoch 693\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0131\n",
            "Epoch 694\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0133\n",
            "Epoch 695\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0130\n",
            "Epoch 696\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0136\n",
            "Epoch 697\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0136\n",
            "Epoch 698\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0132\n",
            "Epoch 699\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0133\n",
            "Epoch 700\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0139\n",
            "Epoch 701\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0132\n",
            "Epoch 702\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0139\n",
            "Epoch 703\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0138\n",
            "Epoch 704\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0132\n",
            "Epoch 705\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0145\n",
            "Epoch 706\n",
            "-------------------------------\n",
            "Training Loss: 0.0106\n",
            "Validation Loss: 0.0132\n",
            "Epoch 707\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0138\n",
            "Epoch 708\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0135\n",
            "Epoch 709\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0142\n",
            "Epoch 710\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0136\n",
            "Epoch 711\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0135\n",
            "Epoch 712\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0139\n",
            "Epoch 713\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0137\n",
            "Epoch 714\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0131\n",
            "Epoch 715\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0136\n",
            "Epoch 716\n",
            "-------------------------------\n",
            "Training Loss: 0.0105\n",
            "Validation Loss: 0.0132\n",
            "Epoch 717\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0133\n",
            "Epoch 718\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0133\n",
            "Epoch 719\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0134\n",
            "Epoch 720\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0135\n",
            "Epoch 721\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0133\n",
            "Epoch 722\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0136\n",
            "Epoch 723\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0138\n",
            "Epoch 724\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0146\n",
            "Epoch 725\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0141\n",
            "Epoch 726\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0138\n",
            "Epoch 727\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0130\n",
            "Epoch 728\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0144\n",
            "Epoch 729\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0135\n",
            "Epoch 730\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0131\n",
            "Epoch 731\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0146\n",
            "Epoch 732\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0132\n",
            "Epoch 733\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0131\n",
            "Epoch 734\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0132\n",
            "Epoch 735\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0131\n",
            "Epoch 736\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0139\n",
            "Epoch 737\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0133\n",
            "Epoch 738\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0143\n",
            "Epoch 739\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0132\n",
            "Epoch 740\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0144\n",
            "Epoch 741\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0135\n",
            "Epoch 742\n",
            "-------------------------------\n",
            "Training Loss: 0.0103\n",
            "Validation Loss: 0.0134\n",
            "Epoch 743\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0130\n",
            "Epoch 744\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0135\n",
            "Epoch 745\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0134\n",
            "Epoch 746\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0137\n",
            "Epoch 747\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0131\n",
            "Epoch 748\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0131\n",
            "Epoch 749\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0137\n",
            "Epoch 750\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0138\n",
            "Epoch 751\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0131\n",
            "Epoch 752\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0131\n",
            "Epoch 753\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0134\n",
            "Epoch 754\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0136\n",
            "Epoch 755\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0129\n",
            "Epoch 756\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0135\n",
            "Epoch 757\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0133\n",
            "Epoch 758\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0136\n",
            "Epoch 759\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0131\n",
            "Epoch 760\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0131\n",
            "Epoch 761\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0133\n",
            "Epoch 762\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0137\n",
            "Epoch 763\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0130\n",
            "Epoch 764\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0136\n",
            "Epoch 765\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0131\n",
            "Epoch 766\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0136\n",
            "Epoch 767\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0138\n",
            "Epoch 768\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0128\n",
            "Epoch 769\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0133\n",
            "Epoch 770\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0159\n",
            "Epoch 771\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0129\n",
            "Epoch 772\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0133\n",
            "Epoch 773\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0134\n",
            "Epoch 774\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0130\n",
            "Epoch 775\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0137\n",
            "Epoch 776\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0131\n",
            "Epoch 777\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0132\n",
            "Epoch 778\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0134\n",
            "Epoch 779\n",
            "-------------------------------\n",
            "Training Loss: 0.0102\n",
            "Validation Loss: 0.0140\n",
            "Epoch 780\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0129\n",
            "Epoch 781\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0138\n",
            "Epoch 782\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0131\n",
            "Epoch 783\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0134\n",
            "Epoch 784\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0130\n",
            "Epoch 785\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0132\n",
            "Epoch 786\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0129\n",
            "Epoch 787\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0136\n",
            "Epoch 788\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0128\n",
            "Epoch 789\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0133\n",
            "Epoch 790\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0132\n",
            "Epoch 791\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0132\n",
            "Epoch 792\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0133\n",
            "Epoch 793\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0133\n",
            "Epoch 794\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0130\n",
            "Epoch 795\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0130\n",
            "Epoch 796\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0135\n",
            "Epoch 797\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0134\n",
            "Epoch 798\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0133\n",
            "Epoch 799\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0133\n",
            "Epoch 800\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0132\n",
            "Epoch 801\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0130\n",
            "Epoch 802\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0137\n",
            "Epoch 803\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0135\n",
            "Epoch 804\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0130\n",
            "Epoch 805\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0131\n",
            "Epoch 806\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0139\n",
            "Epoch 807\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0136\n",
            "Epoch 808\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0144\n",
            "Epoch 809\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0139\n",
            "Epoch 810\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0140\n",
            "Epoch 811\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0139\n",
            "Epoch 812\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0133\n",
            "Epoch 813\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0131\n",
            "Epoch 814\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0136\n",
            "Epoch 815\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0137\n",
            "Epoch 816\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0128\n",
            "Epoch 817\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0130\n",
            "Epoch 818\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0130\n",
            "Epoch 819\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0138\n",
            "Epoch 820\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0135\n",
            "Epoch 821\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0138\n",
            "Epoch 822\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0130\n",
            "Epoch 823\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0132\n",
            "Epoch 824\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0132\n",
            "Epoch 825\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0140\n",
            "Epoch 826\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0139\n",
            "Epoch 827\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0133\n",
            "Epoch 828\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0132\n",
            "Epoch 829\n",
            "-------------------------------\n",
            "Training Loss: 0.0100\n",
            "Validation Loss: 0.0130\n",
            "Epoch 830\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0133\n",
            "Epoch 831\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0134\n",
            "Epoch 832\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0137\n",
            "Epoch 833\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0133\n",
            "Epoch 834\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0156\n",
            "Epoch 835\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0131\n",
            "Epoch 836\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0131\n",
            "Epoch 837\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0140\n",
            "Epoch 838\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0147\n",
            "Epoch 839\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0133\n",
            "Epoch 840\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0129\n",
            "Epoch 841\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0140\n",
            "Epoch 842\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0132\n",
            "Epoch 843\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0134\n",
            "Epoch 844\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0132\n",
            "Epoch 845\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0148\n",
            "Epoch 846\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0138\n",
            "Epoch 847\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0128\n",
            "Epoch 848\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0136\n",
            "Epoch 849\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0130\n",
            "Epoch 850\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0136\n",
            "Epoch 851\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0130\n",
            "Epoch 852\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0137\n",
            "Epoch 853\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0140\n",
            "Epoch 854\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0134\n",
            "Epoch 855\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0130\n",
            "Epoch 856\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0138\n",
            "Epoch 857\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0133\n",
            "Epoch 858\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0130\n",
            "Epoch 859\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0133\n",
            "Epoch 860\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0132\n",
            "Epoch 861\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0130\n",
            "Epoch 862\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0135\n",
            "Epoch 863\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0135\n",
            "Epoch 864\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0139\n",
            "Epoch 865\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0130\n",
            "Epoch 866\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0130\n",
            "Epoch 867\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0139\n",
            "Epoch 868\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0126\n",
            "Epoch 869\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0134\n",
            "Epoch 870\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0138\n",
            "Epoch 871\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0131\n",
            "Epoch 872\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0134\n",
            "Epoch 873\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0131\n",
            "Epoch 874\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0133\n",
            "Epoch 875\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0131\n",
            "Epoch 876\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0135\n",
            "Epoch 877\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0141\n",
            "Epoch 878\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0133\n",
            "Epoch 879\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0133\n",
            "Epoch 880\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0130\n",
            "Epoch 881\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0129\n",
            "Epoch 882\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0128\n",
            "Epoch 883\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0137\n",
            "Epoch 884\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0129\n",
            "Epoch 885\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0139\n",
            "Epoch 886\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0128\n",
            "Epoch 887\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0142\n",
            "Epoch 888\n",
            "-------------------------------\n",
            "Training Loss: 0.0098\n",
            "Validation Loss: 0.0128\n",
            "Epoch 889\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0134\n",
            "Epoch 890\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0129\n",
            "Epoch 891\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0130\n",
            "Epoch 892\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0130\n",
            "Epoch 893\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0144\n",
            "Epoch 894\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0131\n",
            "Epoch 895\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0134\n",
            "Epoch 896\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0133\n",
            "Epoch 897\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0141\n",
            "Epoch 898\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0131\n",
            "Epoch 899\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0148\n",
            "Epoch 900\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0134\n",
            "Epoch 901\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0129\n",
            "Epoch 902\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0131\n",
            "Epoch 903\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0134\n",
            "Epoch 904\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0134\n",
            "Epoch 905\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0133\n",
            "Epoch 906\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0129\n",
            "Epoch 907\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0133\n",
            "Epoch 908\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0133\n",
            "Epoch 909\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0130\n",
            "Epoch 910\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0134\n",
            "Epoch 911\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0138\n",
            "Epoch 912\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0130\n",
            "Epoch 913\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0129\n",
            "Epoch 914\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0132\n",
            "Epoch 915\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0129\n",
            "Epoch 916\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0141\n",
            "Epoch 917\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0132\n",
            "Epoch 918\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0134\n",
            "Epoch 919\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0130\n",
            "Epoch 920\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0126\n",
            "Epoch 921\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0129\n",
            "Epoch 922\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0131\n",
            "Epoch 923\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0136\n",
            "Epoch 924\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0129\n",
            "Epoch 925\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0144\n",
            "Epoch 926\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0129\n",
            "Epoch 927\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0134\n",
            "Epoch 928\n",
            "-------------------------------\n",
            "Training Loss: 0.0097\n",
            "Validation Loss: 0.0135\n",
            "Epoch 929\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0128\n",
            "Epoch 930\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0142\n",
            "Epoch 931\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0137\n",
            "Epoch 932\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0126\n",
            "Epoch 933\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0135\n",
            "Epoch 934\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0127\n",
            "Epoch 935\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0134\n",
            "Epoch 936\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0132\n",
            "Epoch 937\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0132\n",
            "Epoch 938\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0141\n",
            "Epoch 939\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0133\n",
            "Epoch 940\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0130\n",
            "Epoch 941\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0134\n",
            "Epoch 942\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0132\n",
            "Epoch 943\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0129\n",
            "Epoch 944\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0134\n",
            "Epoch 945\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0131\n",
            "Epoch 946\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0136\n",
            "Epoch 947\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0128\n",
            "Epoch 948\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0135\n",
            "Epoch 949\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0129\n",
            "Epoch 950\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0130\n",
            "Epoch 951\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0134\n",
            "Epoch 952\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0130\n",
            "Epoch 953\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0132\n",
            "Epoch 954\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0129\n",
            "Epoch 955\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0130\n",
            "Epoch 956\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0141\n",
            "Epoch 957\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0127\n",
            "Epoch 958\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0134\n",
            "Epoch 959\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0128\n",
            "Epoch 960\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0135\n",
            "Epoch 961\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0128\n",
            "Epoch 962\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0132\n",
            "Epoch 963\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0132\n",
            "Epoch 964\n",
            "-------------------------------\n",
            "Training Loss: 0.0091\n",
            "Validation Loss: 0.0131\n",
            "Epoch 965\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0126\n",
            "Epoch 966\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0133\n",
            "Epoch 967\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0127\n",
            "Epoch 968\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0127\n",
            "Epoch 969\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0138\n",
            "Epoch 970\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0135\n",
            "Epoch 971\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0135\n",
            "Epoch 972\n",
            "-------------------------------\n",
            "Training Loss: 0.0091\n",
            "Validation Loss: 0.0129\n",
            "Epoch 973\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0132\n",
            "Epoch 974\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0128\n",
            "Epoch 975\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0130\n",
            "Epoch 976\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0131\n",
            "Epoch 977\n",
            "-------------------------------\n",
            "Training Loss: 0.0091\n",
            "Validation Loss: 0.0131\n",
            "Epoch 978\n",
            "-------------------------------\n",
            "Training Loss: 0.0091\n",
            "Validation Loss: 0.0130\n",
            "Epoch 979\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0129\n",
            "Epoch 980\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0130\n",
            "Epoch 981\n",
            "-------------------------------\n",
            "Training Loss: 0.0091\n",
            "Validation Loss: 0.0128\n",
            "Epoch 982\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0128\n",
            "Epoch 983\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0134\n",
            "Epoch 984\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0126\n",
            "Epoch 985\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0137\n",
            "Epoch 986\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0138\n",
            "Epoch 987\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0129\n",
            "Epoch 988\n",
            "-------------------------------\n",
            "Training Loss: 0.0094\n",
            "Validation Loss: 0.0131\n",
            "Epoch 989\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0134\n",
            "Epoch 990\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0129\n",
            "Epoch 991\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0131\n",
            "Epoch 992\n",
            "-------------------------------\n",
            "Training Loss: 0.0091\n",
            "Validation Loss: 0.0136\n",
            "Epoch 993\n",
            "-------------------------------\n",
            "Training Loss: 0.0091\n",
            "Validation Loss: 0.0129\n",
            "Epoch 994\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0136\n",
            "Epoch 995\n",
            "-------------------------------\n",
            "Training Loss: 0.0091\n",
            "Validation Loss: 0.0133\n",
            "Epoch 996\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0129\n",
            "Epoch 997\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0133\n",
            "Epoch 998\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0134\n",
            "Epoch 999\n",
            "-------------------------------\n",
            "Training Loss: 0.0093\n",
            "Validation Loss: 0.0127\n",
            "Epoch 1000\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0139\n",
            "Test Loss: 0.012883104383945465\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "\n",
        "# Define the model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(12, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2)  # Output layer for 2D output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_relu_stack(x)\n",
        "\n",
        "# Assuming 'inputs' and 'labels' are your data\n",
        "# labels should be a list of lists with 2 elements each, for example: [[output1, output2], ...]\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "labels = [[s,m] for s,m in zip(success_labels, maneuver_labels)]\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.15, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Min-Max Scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_train = min_max_scaler.fit_transform(X_train)\n",
        "X_test = min_max_scaler.transform(X_test)\n",
        "X_val = min_max_scaler.transform(X_val)\n",
        "joblib.dump(min_max_scaler, 'scaler_minmax_ours.pkl')\n",
        "\n",
        "# Convert arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = NeuralNetwork()\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "learning_rate = 2e-4  # Adjusted learning rate\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.MSELoss()  # Mean Squared Error Loss for regression\n",
        "\n",
        "# Training and validation loops\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    total_loss = 0\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def val_loop(dataloader, model, loss_fn):\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Training process\n",
        "epochs = 1000\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_loop(train_loader, model, loss_fn, optimizer)\n",
        "    val_loss = val_loop(val_loader, model, loss_fn)\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    print(f\"Training Loss: {train_loss:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_tensor)\n",
        "    test_loss = loss_fn(y_pred, y_test_tensor).item()\n",
        "    print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model_ours.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "H2j6mNXmi0Nn",
        "outputId": "d19c2e18-e0f4-4e24-923a-24d38efb1aa3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a plot of training and validation losses\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "ax = fig.add_subplot()\n",
        "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\")\n",
        "plt.plot(range(1, epochs + 1), val_losses, label=\"Validation Loss\")\n",
        "ax.set_yscale('log')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Display the plot\n",
        "# plt.show()\n",
        "# Save the plot as an image (optional)\n",
        "plt.savefig(\"loss_plot_ours.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "TFY7j8ZjvkVy",
        "outputId": "b7ac6e4f-47f4-4092-f4d4-60512377fb4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame to store epoch, training loss, and validation loss\n",
        "data = {'Epoch': range(1, epochs + 1), 'Training Loss': train_losses, 'Validation Loss': val_losses}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(\"losses_ours.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3iWCmYQhIvw",
        "outputId": "c03782d8-dab8-4568-c0c1-681e8526bf2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True: [0.0032862815802978847, 0.0029840178365195813], Predicted: [0.06847857683897018, 0.0046387240290641785]\n",
            "True: [0.0037801411749197335, 0.8626229080007829], Predicted: [0.01725202053785324, 0.6307054758071899]\n",
            "True: [0.00014736244473630098, 0.9490254904107356], Predicted: [-0.006303668022155762, 0.7775164842605591]\n",
            "True: [0.5789697879762071, 0.12382299591741197], Predicted: [0.5205562114715576, 0.3176575005054474]\n",
            "True: [0.0001178619611508935, 0.7607133574354158], Predicted: [0.07530687004327774, 0.8853983879089355]\n",
            "True: [3.5638337589401154e-06, 0.2891284826907754], Predicted: [-0.00021927803754806519, 0.28335705399513245]\n",
            "True: [2.5735504510996002e-05, 0.09192884317012084], Predicted: [0.006238944828510284, 0.3101727366447449]\n",
            "True: [0.9545577398973092, 0.42081027047964603], Predicted: [0.9250941872596741, 0.5119781494140625]\n",
            "True: [0.0, 0.6805866481887891], Predicted: [-0.0025470927357673645, 0.6355421543121338]\n",
            "True: [6.839057167939366e-07, 0.0012980712212860013], Predicted: [0.007397003471851349, -0.001652732491493225]\n"
          ]
        }
      ],
      "source": [
        "# Print true and predicted values\n",
        "for true, pred in zip(y_test[:10], y_pred.tolist()[:10]):\n",
        "    print(f\"True: {true}, Predicted: {pred}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqfdJfbGt_r5"
      },
      "source": [
        "# TORCH 3D Output (Hou Quality Metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bMrHhIdt_sC",
        "outputId": "2480b382-0642-4bbd-8947-b06652f0e03f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Training Loss: 0.8904\n",
            "Validation Loss: 0.9302\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Training Loss: 0.8357\n",
            "Validation Loss: 0.9258\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Training Loss: 0.8144\n",
            "Validation Loss: 0.8895\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Training Loss: 0.7805\n",
            "Validation Loss: 0.8627\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Training Loss: 0.7752\n",
            "Validation Loss: 0.8525\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Training Loss: 0.7558\n",
            "Validation Loss: 0.8486\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Training Loss: 0.7517\n",
            "Validation Loss: 0.8447\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Training Loss: 0.7483\n",
            "Validation Loss: 0.8389\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Training Loss: 0.7453\n",
            "Validation Loss: 0.8353\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Training Loss: 0.7418\n",
            "Validation Loss: 0.8345\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Training Loss: 0.7388\n",
            "Validation Loss: 0.8281\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Training Loss: 0.7353\n",
            "Validation Loss: 0.8244\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Training Loss: 0.7313\n",
            "Validation Loss: 0.8235\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Training Loss: 0.7278\n",
            "Validation Loss: 0.8151\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Training Loss: 0.7241\n",
            "Validation Loss: 0.8115\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Training Loss: 0.7205\n",
            "Validation Loss: 0.8096\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Training Loss: 0.7157\n",
            "Validation Loss: 0.8045\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Training Loss: 0.7115\n",
            "Validation Loss: 0.7996\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Training Loss: 0.7074\n",
            "Validation Loss: 0.8720\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Training Loss: 0.7039\n",
            "Validation Loss: 0.8628\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Training Loss: 0.6995\n",
            "Validation Loss: 0.7906\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Training Loss: 0.6955\n",
            "Validation Loss: 0.7887\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Training Loss: 0.6942\n",
            "Validation Loss: 0.7810\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Training Loss: 0.6890\n",
            "Validation Loss: 0.7766\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Training Loss: 0.6860\n",
            "Validation Loss: 0.7731\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Training Loss: 0.6838\n",
            "Validation Loss: 0.7698\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Training Loss: 0.6807\n",
            "Validation Loss: 0.7713\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Training Loss: 0.6794\n",
            "Validation Loss: 0.7708\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Training Loss: 0.6770\n",
            "Validation Loss: 0.7666\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "Training Loss: 0.6748\n",
            "Validation Loss: 0.7637\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "Training Loss: 0.6734\n",
            "Validation Loss: 0.7611\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "Training Loss: 0.6717\n",
            "Validation Loss: 0.7589\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "Training Loss: 0.6689\n",
            "Validation Loss: 0.7578\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "Training Loss: 0.6674\n",
            "Validation Loss: 0.7555\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "Training Loss: 0.6652\n",
            "Validation Loss: 0.7539\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "Training Loss: 0.6629\n",
            "Validation Loss: 0.7514\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "Training Loss: 0.6612\n",
            "Validation Loss: 0.7492\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "Training Loss: 0.6595\n",
            "Validation Loss: 0.7510\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "Training Loss: 0.6570\n",
            "Validation Loss: 0.7503\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "Training Loss: 0.6549\n",
            "Validation Loss: 0.7458\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "Training Loss: 0.6526\n",
            "Validation Loss: 0.8227\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "Training Loss: 0.6508\n",
            "Validation Loss: 0.7412\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "Training Loss: 0.6482\n",
            "Validation Loss: 0.7426\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "Training Loss: 0.6488\n",
            "Validation Loss: 0.7374\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "Training Loss: 0.6429\n",
            "Validation Loss: 0.7348\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "Training Loss: 0.6409\n",
            "Validation Loss: 0.7324\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "Training Loss: 0.6380\n",
            "Validation Loss: 0.7388\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "Training Loss: 0.6360\n",
            "Validation Loss: 0.8014\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "Training Loss: 0.6333\n",
            "Validation Loss: 0.7288\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "Training Loss: 0.6389\n",
            "Validation Loss: 0.7243\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "Training Loss: 0.6284\n",
            "Validation Loss: 0.7217\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "Training Loss: 0.6240\n",
            "Validation Loss: 0.7266\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "Training Loss: 0.6215\n",
            "Validation Loss: 0.7173\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "Training Loss: 0.6192\n",
            "Validation Loss: 0.7196\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "Training Loss: 0.6154\n",
            "Validation Loss: 0.7133\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "Training Loss: 0.6142\n",
            "Validation Loss: 0.7141\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "Training Loss: 0.6212\n",
            "Validation Loss: 0.7131\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "Training Loss: 0.6073\n",
            "Validation Loss: 0.7090\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "Training Loss: 0.6049\n",
            "Validation Loss: 0.7056\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "Training Loss: 0.6027\n",
            "Validation Loss: 0.7028\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "Training Loss: 0.5994\n",
            "Validation Loss: 0.7040\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "Training Loss: 0.5971\n",
            "Validation Loss: 0.7040\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "Training Loss: 0.5960\n",
            "Validation Loss: 0.6999\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "Training Loss: 0.5928\n",
            "Validation Loss: 0.7721\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "Training Loss: 0.5918\n",
            "Validation Loss: 0.6966\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "Training Loss: 0.5895\n",
            "Validation Loss: 0.6934\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "Training Loss: 0.5865\n",
            "Validation Loss: 0.6973\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "Training Loss: 0.5848\n",
            "Validation Loss: 0.6917\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "Training Loss: 0.5825\n",
            "Validation Loss: 0.6930\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "Training Loss: 0.5813\n",
            "Validation Loss: 0.7083\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "Training Loss: 0.5819\n",
            "Validation Loss: 0.6913\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "Training Loss: 0.5777\n",
            "Validation Loss: 0.6911\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "Training Loss: 0.5762\n",
            "Validation Loss: 0.6870\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "Training Loss: 0.5746\n",
            "Validation Loss: 0.6880\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "Training Loss: 0.5739\n",
            "Validation Loss: 0.6894\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "Training Loss: 0.5726\n",
            "Validation Loss: 0.6837\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "Training Loss: 0.5712\n",
            "Validation Loss: 0.6872\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "Training Loss: 0.5701\n",
            "Validation Loss: 0.6910\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "Training Loss: 0.5697\n",
            "Validation Loss: 0.6828\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "Training Loss: 0.5677\n",
            "Validation Loss: 0.6824\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "Training Loss: 0.5676\n",
            "Validation Loss: 0.6857\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "Training Loss: 0.5662\n",
            "Validation Loss: 0.6821\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "Training Loss: 0.5647\n",
            "Validation Loss: 0.6849\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "Training Loss: 0.5640\n",
            "Validation Loss: 0.6838\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "Training Loss: 0.5641\n",
            "Validation Loss: 0.6835\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "Training Loss: 0.5625\n",
            "Validation Loss: 0.6824\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "Training Loss: 0.5618\n",
            "Validation Loss: 0.7258\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "Training Loss: 0.5624\n",
            "Validation Loss: 0.6772\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "Training Loss: 0.5616\n",
            "Validation Loss: 0.6798\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "Training Loss: 0.5611\n",
            "Validation Loss: 0.6801\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "Training Loss: 0.5588\n",
            "Validation Loss: 0.6791\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "Training Loss: 0.5592\n",
            "Validation Loss: 0.6752\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "Training Loss: 0.5607\n",
            "Validation Loss: 0.6792\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "Training Loss: 0.5579\n",
            "Validation Loss: 0.6929\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "Training Loss: 0.5572\n",
            "Validation Loss: 0.6731\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "Training Loss: 0.5558\n",
            "Validation Loss: 0.6759\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "Training Loss: 0.5656\n",
            "Validation Loss: 0.6744\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "Training Loss: 0.5544\n",
            "Validation Loss: 0.6750\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "Training Loss: 0.5533\n",
            "Validation Loss: 0.6760\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "Training Loss: 0.5529\n",
            "Validation Loss: 0.6781\n",
            "Epoch 101\n",
            "-------------------------------\n",
            "Training Loss: 0.5520\n",
            "Validation Loss: 0.6713\n",
            "Epoch 102\n",
            "-------------------------------\n",
            "Training Loss: 0.5512\n",
            "Validation Loss: 0.6770\n",
            "Epoch 103\n",
            "-------------------------------\n",
            "Training Loss: 0.5499\n",
            "Validation Loss: 0.6708\n",
            "Epoch 104\n",
            "-------------------------------\n",
            "Training Loss: 0.5499\n",
            "Validation Loss: 0.6728\n",
            "Epoch 105\n",
            "-------------------------------\n",
            "Training Loss: 0.5496\n",
            "Validation Loss: 0.6696\n",
            "Epoch 106\n",
            "-------------------------------\n",
            "Training Loss: 0.5490\n",
            "Validation Loss: 0.6693\n",
            "Epoch 107\n",
            "-------------------------------\n",
            "Training Loss: 0.5485\n",
            "Validation Loss: 0.6716\n",
            "Epoch 108\n",
            "-------------------------------\n",
            "Training Loss: 0.5481\n",
            "Validation Loss: 0.6681\n",
            "Epoch 109\n",
            "-------------------------------\n",
            "Training Loss: 0.5479\n",
            "Validation Loss: 0.6687\n",
            "Epoch 110\n",
            "-------------------------------\n",
            "Training Loss: 0.5471\n",
            "Validation Loss: 0.6693\n",
            "Epoch 111\n",
            "-------------------------------\n",
            "Training Loss: 0.5576\n",
            "Validation Loss: 0.6670\n",
            "Epoch 112\n",
            "-------------------------------\n",
            "Training Loss: 0.5463\n",
            "Validation Loss: 0.6672\n",
            "Epoch 113\n",
            "-------------------------------\n",
            "Training Loss: 0.5517\n",
            "Validation Loss: 0.6718\n",
            "Epoch 114\n",
            "-------------------------------\n",
            "Training Loss: 0.5435\n",
            "Validation Loss: 0.6728\n",
            "Epoch 115\n",
            "-------------------------------\n",
            "Training Loss: 0.5453\n",
            "Validation Loss: 0.6765\n",
            "Epoch 116\n",
            "-------------------------------\n",
            "Training Loss: 0.5520\n",
            "Validation Loss: 0.6749\n",
            "Epoch 117\n",
            "-------------------------------\n",
            "Training Loss: 0.5428\n",
            "Validation Loss: 0.6718\n",
            "Epoch 118\n",
            "-------------------------------\n",
            "Training Loss: 0.5428\n",
            "Validation Loss: 0.6684\n",
            "Epoch 119\n",
            "-------------------------------\n",
            "Training Loss: 0.5420\n",
            "Validation Loss: 0.6702\n",
            "Epoch 120\n",
            "-------------------------------\n",
            "Training Loss: 0.5423\n",
            "Validation Loss: 0.6682\n",
            "Epoch 121\n",
            "-------------------------------\n",
            "Training Loss: 0.5408\n",
            "Validation Loss: 0.6673\n",
            "Epoch 122\n",
            "-------------------------------\n",
            "Training Loss: 0.5422\n",
            "Validation Loss: 0.6656\n",
            "Epoch 123\n",
            "-------------------------------\n",
            "Training Loss: 0.5411\n",
            "Validation Loss: 0.6628\n",
            "Epoch 124\n",
            "-------------------------------\n",
            "Training Loss: 0.5390\n",
            "Validation Loss: 0.6635\n",
            "Epoch 125\n",
            "-------------------------------\n",
            "Training Loss: 0.5391\n",
            "Validation Loss: 0.6667\n",
            "Epoch 126\n",
            "-------------------------------\n",
            "Training Loss: 0.5390\n",
            "Validation Loss: 0.6620\n",
            "Epoch 127\n",
            "-------------------------------\n",
            "Training Loss: 0.5381\n",
            "Validation Loss: 0.6699\n",
            "Epoch 128\n",
            "-------------------------------\n",
            "Training Loss: 0.5386\n",
            "Validation Loss: 0.6625\n",
            "Epoch 129\n",
            "-------------------------------\n",
            "Training Loss: 0.5370\n",
            "Validation Loss: 0.6692\n",
            "Epoch 130\n",
            "-------------------------------\n",
            "Training Loss: 0.5379\n",
            "Validation Loss: 0.6611\n",
            "Epoch 131\n",
            "-------------------------------\n",
            "Training Loss: 0.5367\n",
            "Validation Loss: 0.6604\n",
            "Epoch 132\n",
            "-------------------------------\n",
            "Training Loss: 0.5363\n",
            "Validation Loss: 0.6608\n",
            "Epoch 133\n",
            "-------------------------------\n",
            "Training Loss: 0.5361\n",
            "Validation Loss: 0.6770\n",
            "Epoch 134\n",
            "-------------------------------\n",
            "Training Loss: 0.5356\n",
            "Validation Loss: 0.6620\n",
            "Epoch 135\n",
            "-------------------------------\n",
            "Training Loss: 0.5353\n",
            "Validation Loss: 0.6617\n",
            "Epoch 136\n",
            "-------------------------------\n",
            "Training Loss: 0.5344\n",
            "Validation Loss: 0.6671\n",
            "Epoch 137\n",
            "-------------------------------\n",
            "Training Loss: 0.5353\n",
            "Validation Loss: 0.6642\n",
            "Epoch 138\n",
            "-------------------------------\n",
            "Training Loss: 0.5338\n",
            "Validation Loss: 0.6625\n",
            "Epoch 139\n",
            "-------------------------------\n",
            "Training Loss: 0.5337\n",
            "Validation Loss: 0.6591\n",
            "Epoch 140\n",
            "-------------------------------\n",
            "Training Loss: 0.5323\n",
            "Validation Loss: 0.6591\n",
            "Epoch 141\n",
            "-------------------------------\n",
            "Training Loss: 0.5319\n",
            "Validation Loss: 0.6731\n",
            "Epoch 142\n",
            "-------------------------------\n",
            "Training Loss: 0.5343\n",
            "Validation Loss: 0.6612\n",
            "Epoch 143\n",
            "-------------------------------\n",
            "Training Loss: 0.5321\n",
            "Validation Loss: 0.6577\n",
            "Epoch 144\n",
            "-------------------------------\n",
            "Training Loss: 0.5309\n",
            "Validation Loss: 0.6600\n",
            "Epoch 145\n",
            "-------------------------------\n",
            "Training Loss: 0.5313\n",
            "Validation Loss: 0.6599\n",
            "Epoch 146\n",
            "-------------------------------\n",
            "Training Loss: 0.5301\n",
            "Validation Loss: 0.7272\n",
            "Epoch 147\n",
            "-------------------------------\n",
            "Training Loss: 0.5308\n",
            "Validation Loss: 0.6583\n",
            "Epoch 148\n",
            "-------------------------------\n",
            "Training Loss: 0.5297\n",
            "Validation Loss: 0.6551\n",
            "Epoch 149\n",
            "-------------------------------\n",
            "Training Loss: 0.5291\n",
            "Validation Loss: 0.6630\n",
            "Epoch 150\n",
            "-------------------------------\n",
            "Training Loss: 0.5295\n",
            "Validation Loss: 0.6650\n",
            "Epoch 151\n",
            "-------------------------------\n",
            "Training Loss: 0.5275\n",
            "Validation Loss: 0.6563\n",
            "Epoch 152\n",
            "-------------------------------\n",
            "Training Loss: 0.5278\n",
            "Validation Loss: 0.6550\n",
            "Epoch 153\n",
            "-------------------------------\n",
            "Training Loss: 0.5277\n",
            "Validation Loss: 0.6554\n",
            "Epoch 154\n",
            "-------------------------------\n",
            "Training Loss: 0.5269\n",
            "Validation Loss: 0.6559\n",
            "Epoch 155\n",
            "-------------------------------\n",
            "Training Loss: 0.5271\n",
            "Validation Loss: 0.6532\n",
            "Epoch 156\n",
            "-------------------------------\n",
            "Training Loss: 0.5259\n",
            "Validation Loss: 0.6510\n",
            "Epoch 157\n",
            "-------------------------------\n",
            "Training Loss: 0.5260\n",
            "Validation Loss: 0.6540\n",
            "Epoch 158\n",
            "-------------------------------\n",
            "Training Loss: 0.5253\n",
            "Validation Loss: 0.6554\n",
            "Epoch 159\n",
            "-------------------------------\n",
            "Training Loss: 0.5252\n",
            "Validation Loss: 0.7210\n",
            "Epoch 160\n",
            "-------------------------------\n",
            "Training Loss: 0.5241\n",
            "Validation Loss: 0.6495\n",
            "Epoch 161\n",
            "-------------------------------\n",
            "Training Loss: 0.5236\n",
            "Validation Loss: 0.6527\n",
            "Epoch 162\n",
            "-------------------------------\n",
            "Training Loss: 0.5228\n",
            "Validation Loss: 0.6611\n",
            "Epoch 163\n",
            "-------------------------------\n",
            "Training Loss: 0.5226\n",
            "Validation Loss: 0.6591\n",
            "Epoch 164\n",
            "-------------------------------\n",
            "Training Loss: 0.5240\n",
            "Validation Loss: 0.6583\n",
            "Epoch 165\n",
            "-------------------------------\n",
            "Training Loss: 0.5224\n",
            "Validation Loss: 0.6511\n",
            "Epoch 166\n",
            "-------------------------------\n",
            "Training Loss: 0.5221\n",
            "Validation Loss: 0.6479\n",
            "Epoch 167\n",
            "-------------------------------\n",
            "Training Loss: 0.5205\n",
            "Validation Loss: 0.6520\n",
            "Epoch 168\n",
            "-------------------------------\n",
            "Training Loss: 0.5214\n",
            "Validation Loss: 0.6506\n",
            "Epoch 169\n",
            "-------------------------------\n",
            "Training Loss: 0.5218\n",
            "Validation Loss: 0.6507\n",
            "Epoch 170\n",
            "-------------------------------\n",
            "Training Loss: 0.5207\n",
            "Validation Loss: 0.6503\n",
            "Epoch 171\n",
            "-------------------------------\n",
            "Training Loss: 0.5196\n",
            "Validation Loss: 0.6503\n",
            "Epoch 172\n",
            "-------------------------------\n",
            "Training Loss: 0.5276\n",
            "Validation Loss: 0.6473\n",
            "Epoch 173\n",
            "-------------------------------\n",
            "Training Loss: 0.5190\n",
            "Validation Loss: 0.6460\n",
            "Epoch 174\n",
            "-------------------------------\n",
            "Training Loss: 0.5194\n",
            "Validation Loss: 0.6475\n",
            "Epoch 175\n",
            "-------------------------------\n",
            "Training Loss: 0.5184\n",
            "Validation Loss: 0.6513\n",
            "Epoch 176\n",
            "-------------------------------\n",
            "Training Loss: 0.5189\n",
            "Validation Loss: 0.6534\n",
            "Epoch 177\n",
            "-------------------------------\n",
            "Training Loss: 0.5190\n",
            "Validation Loss: 0.6430\n",
            "Epoch 178\n",
            "-------------------------------\n",
            "Training Loss: 0.5178\n",
            "Validation Loss: 0.6490\n",
            "Epoch 179\n",
            "-------------------------------\n",
            "Training Loss: 0.5238\n",
            "Validation Loss: 0.6492\n",
            "Epoch 180\n",
            "-------------------------------\n",
            "Training Loss: 0.5167\n",
            "Validation Loss: 0.7211\n",
            "Epoch 181\n",
            "-------------------------------\n",
            "Training Loss: 0.5163\n",
            "Validation Loss: 0.6473\n",
            "Epoch 182\n",
            "-------------------------------\n",
            "Training Loss: 0.5162\n",
            "Validation Loss: 0.6433\n",
            "Epoch 183\n",
            "-------------------------------\n",
            "Training Loss: 0.5161\n",
            "Validation Loss: 0.6456\n",
            "Epoch 184\n",
            "-------------------------------\n",
            "Training Loss: 0.5155\n",
            "Validation Loss: 0.6457\n",
            "Epoch 185\n",
            "-------------------------------\n",
            "Training Loss: 0.5163\n",
            "Validation Loss: 0.6455\n",
            "Epoch 186\n",
            "-------------------------------\n",
            "Training Loss: 0.5146\n",
            "Validation Loss: 0.6454\n",
            "Epoch 187\n",
            "-------------------------------\n",
            "Training Loss: 0.5148\n",
            "Validation Loss: 0.6431\n",
            "Epoch 188\n",
            "-------------------------------\n",
            "Training Loss: 0.5142\n",
            "Validation Loss: 0.6511\n",
            "Epoch 189\n",
            "-------------------------------\n",
            "Training Loss: 0.5137\n",
            "Validation Loss: 0.6469\n",
            "Epoch 190\n",
            "-------------------------------\n",
            "Training Loss: 0.5132\n",
            "Validation Loss: 0.6411\n",
            "Epoch 191\n",
            "-------------------------------\n",
            "Training Loss: 0.5124\n",
            "Validation Loss: 0.7160\n",
            "Epoch 192\n",
            "-------------------------------\n",
            "Training Loss: 0.5122\n",
            "Validation Loss: 0.7152\n",
            "Epoch 193\n",
            "-------------------------------\n",
            "Training Loss: 0.5106\n",
            "Validation Loss: 0.6567\n",
            "Epoch 194\n",
            "-------------------------------\n",
            "Training Loss: 0.5124\n",
            "Validation Loss: 0.6434\n",
            "Epoch 195\n",
            "-------------------------------\n",
            "Training Loss: 0.5116\n",
            "Validation Loss: 0.6394\n",
            "Epoch 196\n",
            "-------------------------------\n",
            "Training Loss: 0.5126\n",
            "Validation Loss: 0.6490\n",
            "Epoch 197\n",
            "-------------------------------\n",
            "Training Loss: 0.5108\n",
            "Validation Loss: 0.6527\n",
            "Epoch 198\n",
            "-------------------------------\n",
            "Training Loss: 0.5116\n",
            "Validation Loss: 0.6402\n",
            "Epoch 199\n",
            "-------------------------------\n",
            "Training Loss: 0.5098\n",
            "Validation Loss: 0.6404\n",
            "Epoch 200\n",
            "-------------------------------\n",
            "Training Loss: 0.5095\n",
            "Validation Loss: 0.6470\n",
            "Epoch 201\n",
            "-------------------------------\n",
            "Training Loss: 0.5091\n",
            "Validation Loss: 0.6451\n",
            "Epoch 202\n",
            "-------------------------------\n",
            "Training Loss: 0.5108\n",
            "Validation Loss: 0.6395\n",
            "Epoch 203\n",
            "-------------------------------\n",
            "Training Loss: 0.5082\n",
            "Validation Loss: 0.6435\n",
            "Epoch 204\n",
            "-------------------------------\n",
            "Training Loss: 0.5096\n",
            "Validation Loss: 0.6491\n",
            "Epoch 205\n",
            "-------------------------------\n",
            "Training Loss: 0.5082\n",
            "Validation Loss: 0.6457\n",
            "Epoch 206\n",
            "-------------------------------\n",
            "Training Loss: 0.5102\n",
            "Validation Loss: 0.6439\n",
            "Epoch 207\n",
            "-------------------------------\n",
            "Training Loss: 0.5091\n",
            "Validation Loss: 0.6387\n",
            "Epoch 208\n",
            "-------------------------------\n",
            "Training Loss: 0.5083\n",
            "Validation Loss: 0.6375\n",
            "Epoch 209\n",
            "-------------------------------\n",
            "Training Loss: 0.5080\n",
            "Validation Loss: 0.6425\n",
            "Epoch 210\n",
            "-------------------------------\n",
            "Training Loss: 0.5070\n",
            "Validation Loss: 0.6392\n",
            "Epoch 211\n",
            "-------------------------------\n",
            "Training Loss: 0.5078\n",
            "Validation Loss: 0.6386\n",
            "Epoch 212\n",
            "-------------------------------\n",
            "Training Loss: 0.5059\n",
            "Validation Loss: 0.6415\n",
            "Epoch 213\n",
            "-------------------------------\n",
            "Training Loss: 0.5064\n",
            "Validation Loss: 0.6437\n",
            "Epoch 214\n",
            "-------------------------------\n",
            "Training Loss: 0.5063\n",
            "Validation Loss: 0.6399\n",
            "Epoch 215\n",
            "-------------------------------\n",
            "Training Loss: 0.5048\n",
            "Validation Loss: 0.6372\n",
            "Epoch 216\n",
            "-------------------------------\n",
            "Training Loss: 0.5073\n",
            "Validation Loss: 0.6372\n",
            "Epoch 217\n",
            "-------------------------------\n",
            "Training Loss: 0.5072\n",
            "Validation Loss: 0.6339\n",
            "Epoch 218\n",
            "-------------------------------\n",
            "Training Loss: 0.5036\n",
            "Validation Loss: 0.7136\n",
            "Epoch 219\n",
            "-------------------------------\n",
            "Training Loss: 0.5037\n",
            "Validation Loss: 0.6405\n",
            "Epoch 220\n",
            "-------------------------------\n",
            "Training Loss: 0.5038\n",
            "Validation Loss: 0.6404\n",
            "Epoch 221\n",
            "-------------------------------\n",
            "Training Loss: 0.5043\n",
            "Validation Loss: 0.6386\n",
            "Epoch 222\n",
            "-------------------------------\n",
            "Training Loss: 0.5026\n",
            "Validation Loss: 0.6394\n",
            "Epoch 223\n",
            "-------------------------------\n",
            "Training Loss: 0.5039\n",
            "Validation Loss: 0.6374\n",
            "Epoch 224\n",
            "-------------------------------\n",
            "Training Loss: 0.5026\n",
            "Validation Loss: 0.7112\n",
            "Epoch 225\n",
            "-------------------------------\n",
            "Training Loss: 0.5022\n",
            "Validation Loss: 0.6533\n",
            "Epoch 226\n",
            "-------------------------------\n",
            "Training Loss: 0.5025\n",
            "Validation Loss: 0.6385\n",
            "Epoch 227\n",
            "-------------------------------\n",
            "Training Loss: 0.5035\n",
            "Validation Loss: 0.6421\n",
            "Epoch 228\n",
            "-------------------------------\n",
            "Training Loss: 0.5013\n",
            "Validation Loss: 0.6332\n",
            "Epoch 229\n",
            "-------------------------------\n",
            "Training Loss: 0.5013\n",
            "Validation Loss: 0.6423\n",
            "Epoch 230\n",
            "-------------------------------\n",
            "Training Loss: 0.5011\n",
            "Validation Loss: 0.6888\n",
            "Epoch 231\n",
            "-------------------------------\n",
            "Training Loss: 0.5110\n",
            "Validation Loss: 0.6342\n",
            "Epoch 232\n",
            "-------------------------------\n",
            "Training Loss: 0.5010\n",
            "Validation Loss: 0.6377\n",
            "Epoch 233\n",
            "-------------------------------\n",
            "Training Loss: 0.5006\n",
            "Validation Loss: 0.6417\n",
            "Epoch 234\n",
            "-------------------------------\n",
            "Training Loss: 0.4992\n",
            "Validation Loss: 0.6355\n",
            "Epoch 235\n",
            "-------------------------------\n",
            "Training Loss: 0.4991\n",
            "Validation Loss: 0.6362\n",
            "Epoch 236\n",
            "-------------------------------\n",
            "Training Loss: 0.5009\n",
            "Validation Loss: 0.7148\n",
            "Epoch 237\n",
            "-------------------------------\n",
            "Training Loss: 0.4993\n",
            "Validation Loss: 0.6454\n",
            "Epoch 238\n",
            "-------------------------------\n",
            "Training Loss: 0.5013\n",
            "Validation Loss: 0.6324\n",
            "Epoch 239\n",
            "-------------------------------\n",
            "Training Loss: 0.4977\n",
            "Validation Loss: 0.6707\n",
            "Epoch 240\n",
            "-------------------------------\n",
            "Training Loss: 0.4994\n",
            "Validation Loss: 0.6342\n",
            "Epoch 241\n",
            "-------------------------------\n",
            "Training Loss: 0.4978\n",
            "Validation Loss: 0.6412\n",
            "Epoch 242\n",
            "-------------------------------\n",
            "Training Loss: 0.4983\n",
            "Validation Loss: 0.6370\n",
            "Epoch 243\n",
            "-------------------------------\n",
            "Training Loss: 0.4991\n",
            "Validation Loss: 0.6345\n",
            "Epoch 244\n",
            "-------------------------------\n",
            "Training Loss: 0.4975\n",
            "Validation Loss: 0.6374\n",
            "Epoch 245\n",
            "-------------------------------\n",
            "Training Loss: 0.5014\n",
            "Validation Loss: 0.6312\n",
            "Epoch 246\n",
            "-------------------------------\n",
            "Training Loss: 0.4973\n",
            "Validation Loss: 0.6364\n",
            "Epoch 247\n",
            "-------------------------------\n",
            "Training Loss: 0.4942\n",
            "Validation Loss: 0.6384\n",
            "Epoch 248\n",
            "-------------------------------\n",
            "Training Loss: 0.4971\n",
            "Validation Loss: 0.6450\n",
            "Epoch 249\n",
            "-------------------------------\n",
            "Training Loss: 0.4953\n",
            "Validation Loss: 0.6410\n",
            "Epoch 250\n",
            "-------------------------------\n",
            "Training Loss: 0.4960\n",
            "Validation Loss: 0.6371\n",
            "Epoch 251\n",
            "-------------------------------\n",
            "Training Loss: 0.4957\n",
            "Validation Loss: 0.6329\n",
            "Epoch 252\n",
            "-------------------------------\n",
            "Training Loss: 0.4945\n",
            "Validation Loss: 0.6357\n",
            "Epoch 253\n",
            "-------------------------------\n",
            "Training Loss: 0.4954\n",
            "Validation Loss: 0.6336\n",
            "Epoch 254\n",
            "-------------------------------\n",
            "Training Loss: 0.4955\n",
            "Validation Loss: 0.6319\n",
            "Epoch 255\n",
            "-------------------------------\n",
            "Training Loss: 0.4961\n",
            "Validation Loss: 0.6341\n",
            "Epoch 256\n",
            "-------------------------------\n",
            "Training Loss: 0.4949\n",
            "Validation Loss: 0.6301\n",
            "Epoch 257\n",
            "-------------------------------\n",
            "Training Loss: 0.4956\n",
            "Validation Loss: 0.6456\n",
            "Epoch 258\n",
            "-------------------------------\n",
            "Training Loss: 0.4947\n",
            "Validation Loss: 0.6328\n",
            "Epoch 259\n",
            "-------------------------------\n",
            "Training Loss: 0.4932\n",
            "Validation Loss: 0.6361\n",
            "Epoch 260\n",
            "-------------------------------\n",
            "Training Loss: 0.4961\n",
            "Validation Loss: 0.6350\n",
            "Epoch 261\n",
            "-------------------------------\n",
            "Training Loss: 0.4940\n",
            "Validation Loss: 0.6334\n",
            "Epoch 262\n",
            "-------------------------------\n",
            "Training Loss: 0.4928\n",
            "Validation Loss: 0.6998\n",
            "Epoch 263\n",
            "-------------------------------\n",
            "Training Loss: 0.4923\n",
            "Validation Loss: 0.6303\n",
            "Epoch 264\n",
            "-------------------------------\n",
            "Training Loss: 0.4923\n",
            "Validation Loss: 0.6403\n",
            "Epoch 265\n",
            "-------------------------------\n",
            "Training Loss: 0.4922\n",
            "Validation Loss: 0.6386\n",
            "Epoch 266\n",
            "-------------------------------\n",
            "Training Loss: 0.4941\n",
            "Validation Loss: 0.6379\n",
            "Epoch 267\n",
            "-------------------------------\n",
            "Training Loss: 0.4911\n",
            "Validation Loss: 0.6442\n",
            "Epoch 268\n",
            "-------------------------------\n",
            "Training Loss: 0.4909\n",
            "Validation Loss: 0.6408\n",
            "Epoch 269\n",
            "-------------------------------\n",
            "Training Loss: 0.4917\n",
            "Validation Loss: 0.6295\n",
            "Epoch 270\n",
            "-------------------------------\n",
            "Training Loss: 0.4911\n",
            "Validation Loss: 0.6886\n",
            "Epoch 271\n",
            "-------------------------------\n",
            "Training Loss: 0.4919\n",
            "Validation Loss: 0.6289\n",
            "Epoch 272\n",
            "-------------------------------\n",
            "Training Loss: 0.4907\n",
            "Validation Loss: 0.6288\n",
            "Epoch 273\n",
            "-------------------------------\n",
            "Training Loss: 0.4923\n",
            "Validation Loss: 0.6316\n",
            "Epoch 274\n",
            "-------------------------------\n",
            "Training Loss: 0.4912\n",
            "Validation Loss: 0.6282\n",
            "Epoch 275\n",
            "-------------------------------\n",
            "Training Loss: 0.4904\n",
            "Validation Loss: 0.6339\n",
            "Epoch 276\n",
            "-------------------------------\n",
            "Training Loss: 0.4907\n",
            "Validation Loss: 0.6373\n",
            "Epoch 277\n",
            "-------------------------------\n",
            "Training Loss: 0.4885\n",
            "Validation Loss: 0.6791\n",
            "Epoch 278\n",
            "-------------------------------\n",
            "Training Loss: 0.4903\n",
            "Validation Loss: 0.6405\n",
            "Epoch 279\n",
            "-------------------------------\n",
            "Training Loss: 0.4881\n",
            "Validation Loss: 0.6547\n",
            "Epoch 280\n",
            "-------------------------------\n",
            "Training Loss: 0.4914\n",
            "Validation Loss: 0.6354\n",
            "Epoch 281\n",
            "-------------------------------\n",
            "Training Loss: 0.4882\n",
            "Validation Loss: 0.6431\n",
            "Epoch 282\n",
            "-------------------------------\n",
            "Training Loss: 0.4897\n",
            "Validation Loss: 0.6315\n",
            "Epoch 283\n",
            "-------------------------------\n",
            "Training Loss: 0.4898\n",
            "Validation Loss: 0.6325\n",
            "Epoch 284\n",
            "-------------------------------\n",
            "Training Loss: 0.4879\n",
            "Validation Loss: 0.6402\n",
            "Epoch 285\n",
            "-------------------------------\n",
            "Training Loss: 0.4884\n",
            "Validation Loss: 0.6339\n",
            "Epoch 286\n",
            "-------------------------------\n",
            "Training Loss: 0.4891\n",
            "Validation Loss: 0.6376\n",
            "Epoch 287\n",
            "-------------------------------\n",
            "Training Loss: 0.4881\n",
            "Validation Loss: 0.6401\n",
            "Epoch 288\n",
            "-------------------------------\n",
            "Training Loss: 0.4880\n",
            "Validation Loss: 0.6428\n",
            "Epoch 289\n",
            "-------------------------------\n",
            "Training Loss: 0.4885\n",
            "Validation Loss: 0.6346\n",
            "Epoch 290\n",
            "-------------------------------\n",
            "Training Loss: 0.4875\n",
            "Validation Loss: 0.6331\n",
            "Epoch 291\n",
            "-------------------------------\n",
            "Training Loss: 0.4862\n",
            "Validation Loss: 0.6283\n",
            "Epoch 292\n",
            "-------------------------------\n",
            "Training Loss: 0.4888\n",
            "Validation Loss: 0.6318\n",
            "Epoch 293\n",
            "-------------------------------\n",
            "Training Loss: 0.4861\n",
            "Validation Loss: 0.6334\n",
            "Epoch 294\n",
            "-------------------------------\n",
            "Training Loss: 0.4856\n",
            "Validation Loss: 0.6460\n",
            "Epoch 295\n",
            "-------------------------------\n",
            "Training Loss: 0.4863\n",
            "Validation Loss: 0.6353\n",
            "Epoch 296\n",
            "-------------------------------\n",
            "Training Loss: 0.4857\n",
            "Validation Loss: 0.6358\n",
            "Epoch 297\n",
            "-------------------------------\n",
            "Training Loss: 0.4863\n",
            "Validation Loss: 0.6245\n",
            "Epoch 298\n",
            "-------------------------------\n",
            "Training Loss: 0.4849\n",
            "Validation Loss: 0.6408\n",
            "Epoch 299\n",
            "-------------------------------\n",
            "Training Loss: 0.4849\n",
            "Validation Loss: 0.6844\n",
            "Epoch 300\n",
            "-------------------------------\n",
            "Training Loss: 0.4848\n",
            "Validation Loss: 0.6273\n",
            "Test Loss: 0.4405596852302551\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(12, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 3)  # Adjusted for 3D output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_relu_stack(x)\n",
        "\n",
        "# Assuming 'inputs' and 'labels' are your data\n",
        "# labels should be a list of lists with 3 elements each, for example: [[output1, output2, output3], ...]\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "labels = [[q[0], min(20,q[1]), min(5,q[2])] for q in quality] # cap the exceedingly large values\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.15, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Min-Max Scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_train = min_max_scaler.fit_transform(X_train)\n",
        "X_test = min_max_scaler.transform(X_test)\n",
        "X_val = min_max_scaler.transform(X_val)\n",
        "joblib.dump(min_max_scaler, 'scaler_minmax_hou.pkl')\n",
        "\n",
        "# Standardization Scaling\n",
        "# standard_scaler = StandardScaler()\n",
        "# X_train = standard_scaler.fit_transform(X_train)\n",
        "# X_test = standard_scaler.transform(X_test)\n",
        "# X_val = standard_scaler.transform(X_val)\n",
        "# joblib.dump(min_max_scaler, 'scaler_standard_hou.pkl')\n",
        "\n",
        "# Convert arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = NeuralNetwork()\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "learning_rate = 1e-4\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.MSELoss()  # Mean Squared Error Loss for regression\n",
        "\n",
        "# Training and validation loops\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    total_loss = 0\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def val_loop(dataloader, model, loss_fn):\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Training process\n",
        "epochs = 300\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_loop(train_loader, model, loss_fn, optimizer)\n",
        "    val_loss = val_loop(val_loader, model, loss_fn)\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    print(f\"Training Loss: {train_loss:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_tensor)\n",
        "    test_loss = loss_fn(y_pred, y_test_tensor).item()\n",
        "    print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model_hou.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "2dc5kxM3t_sC",
        "outputId": "39ba3364-5469-4ab7-88f9-d88bb9e9232d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a plot of training and validation losses\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "ax = fig.add_subplot()\n",
        "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\")\n",
        "plt.plot(range(1, epochs + 1), val_losses, label=\"Validation Loss\")\n",
        "ax.set_yscale('log')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Display the plot\n",
        "# plt.show()\n",
        "plt.savefig(\"loss_plot_hou.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR35WBiU1fHn"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create a DataFrame to store epoch, training loss, and validation loss\n",
        "data = {'Epoch': range(1, epochs + 1), 'Training Loss': train_losses, 'Validation Loss': val_losses}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(\"losses_hou.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdeZMTuJt_sD",
        "outputId": "9a107d4a-6eb0-43bd-d3b4-22a79a3301b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True: [1.0637158155441284, 0.0, 0.0], Predicted: [0.7594214677810669, 0.0005486607551574707, -0.06414743512868881]\n",
            "True: [0.013681568205356598, 0.0, 0.0], Predicted: [0.05023910850286484, 0.12527771294116974, 0.2374332845211029]\n",
            "True: [5.738589243264869e-05, 0.0, 0.0], Predicted: [0.07587772607803345, 0.39014172554016113, 1.05942702293396]\n",
            "True: [0.14748062193393707, 0.0, 0.0], Predicted: [0.24927490949630737, 0.08212219178676605, -0.04458225518465042]\n",
            "True: [0.38772258162498474, 0.0, 0.0], Predicted: [0.32027122378349304, 0.004027873277664185, 0.04922395199537277]\n",
            "True: [0.4457491636276245, 0.0, 0.0], Predicted: [0.4339592754840851, 0.00956900417804718, 0.034002386033535004]\n",
            "True: [0.6176474690437317, 0.0, 0.0], Predicted: [0.49725261330604553, 0.03187790513038635, -0.008779950439929962]\n",
            "True: [4.9530585783941206e-06, 0.042345017194747925, 0.21050925552845], Predicted: [0.029035722836852074, 0.15117891132831573, 0.7989487051963806]\n",
            "True: [0.12702248990535736, 0.0, 0.0], Predicted: [0.025737116113305092, 0.04529954493045807, 0.10890430957078934]\n",
            "True: [1.2317031621932983, 0.0, 0.0], Predicted: [1.123948335647583, -0.0029517412185668945, -0.06316722184419632]\n",
            "True: [0.38098132610321045, 0.0, 0.0], Predicted: [0.14901620149612427, 0.03359466791152954, 0.10751910507678986]\n",
            "True: [0.00020629391656257212, 0.0, 0.0], Predicted: [-0.007433644495904446, 0.1426311582326889, 0.6239887475967407]\n",
            "True: [0.33503520488739014, 0.0, 0.0], Predicted: [0.22645153105258942, 0.017084717750549316, 0.048504553735256195]\n",
            "True: [0.0018037863774225116, 0.6196092963218689, 3.079657554626465], Predicted: [-0.10658642649650574, 0.6293084025382996, 2.4050941467285156]\n",
            "True: [1.5708740949630737, 0.0, 0.0], Predicted: [0.9910781979560852, 0.02143833041191101, 0.13311290740966797]\n",
            "True: [0.35918429493904114, 0.0, 0.0], Predicted: [0.3734434247016907, 0.013225898146629333, -0.08186393231153488]\n",
            "True: [0.2543956935405731, 0.0, 0.0], Predicted: [0.46718528866767883, 0.012436509132385254, -0.022625841200351715]\n",
            "True: [0.0004156719078309834, 0.0, 0.0], Predicted: [0.045624881982803345, 0.03982284665107727, 0.07091441750526428]\n",
            "True: [0.4246285557746887, 0.0, 0.0], Predicted: [0.12333858013153076, 0.04116317629814148, 0.1781722605228424]\n",
            "True: [0.04921303689479828, 0.0, 0.0], Predicted: [0.07123971730470657, 0.017967358231544495, 0.029696792364120483]\n",
            "True: [0.439346581697464, 0.0, 0.0], Predicted: [0.40723493695259094, 0.029326915740966797, -0.036949656903743744]\n",
            "True: [1.5142512893362436e-05, 0.34572821855545044, 1.7188130617141724], Predicted: [0.00815565325319767, 0.3645849823951721, 1.4947386980056763]\n",
            "True: [0.06160876154899597, 0.0, 0.0], Predicted: [0.04068756103515625, 0.08980609476566315, 0.26578477025032043]\n",
            "True: [1.2099680134269875e-05, 0.29388731718063354, 1.4565250873565674], Predicted: [0.013023314997553825, 0.22751353681087494, 0.9583465456962585]\n",
            "True: [1.209461970574921e-05, 1.0932201147079468, 5], Predicted: [-0.021985145285725594, 0.3175838589668274, 0.6346328258514404]\n",
            "True: [0.00011914085916941985, 0.321804940700531, 1.5998692512512207], Predicted: [-0.003421405330300331, 0.2329910844564438, 0.8243051171302795]\n",
            "True: [0.0009009662899188697, 0.8264018893241882, 4.108382225036621], Predicted: [-0.024642711505293846, 1.1284754276275635, 2.879293918609619]\n",
            "True: [2.0811621652683243e-05, 0.34344181418418884, 1.707424521446228], Predicted: [0.03838227689266205, 0.14539970457553864, 0.9156539440155029]\n",
            "True: [0.070566825568676, 0.0, 0.0], Predicted: [0.2175750583410263, 0.027277976274490356, 0.09268362820148468]\n",
            "True: [2.6594960689544678, 0.0, 0.0], Predicted: [2.595176935195923, 0.028687894344329834, -0.029644735157489777]\n",
            "True: [9.944945304596331e-06, 0.3537335693836212, 1.7509475946426392], Predicted: [-0.07038767635822296, 0.29938799142837524, 1.4683055877685547]\n",
            "True: [0.0007809962844476104, 0.0, 0.0], Predicted: [0.015294363722205162, 0.17029403150081635, 0.9548236727714539]\n",
            "True: [0.2079194039106369, 0.0, 0.0], Predicted: [0.20718756318092346, -0.0033391714096069336, -0.012168318033218384]\n",
            "True: [1.4191199625201989e-05, 0.25413477420806885, 1.26344895362854], Predicted: [-0.008697699755430222, 0.14216862618923187, 0.7935577630996704]\n",
            "True: [0.11527091264724731, 0.0, 0.0], Predicted: [0.17950022220611572, 0.07685954868793488, -0.04297151416540146]\n",
            "True: [0.9478678703308105, 0.0, 0.0], Predicted: [0.7995256185531616, 0.022289201617240906, 0.012432731688022614]\n",
            "True: [1.1830689907073975, 0.0, 0.0], Predicted: [0.25452500581741333, 0.12389878928661346, 0.10909197479486465]\n",
            "True: [0.0016157792415469885, 0.3373953104019165, 1.6772693395614624], Predicted: [-0.048439785838127136, 0.6924258470535278, 2.5997231006622314]\n",
            "True: [0.14775757491588593, 0.0, 0.0], Predicted: [0.044359318912029266, 0.10770706832408905, 0.24334865808486938]\n",
            "True: [0.05592856928706169, 0.0, 0.0], Predicted: [0.035602256655693054, 0.05769038200378418, 0.22504064440727234]\n",
            "True: [5.0220342018292286e-06, 0.0, 0.0], Predicted: [-0.017010832205414772, 0.25923144817352295, 1.1692739725112915]\n",
            "True: [0.6328005194664001, 0.0, 0.0], Predicted: [0.5113650560379028, 0.026050597429275513, 0.07060699909925461]\n",
            "True: [0.08416064083576202, 0.0, 0.0], Predicted: [0.12293983995914459, 0.1370716542005539, 0.1305612325668335]\n",
            "True: [0.6670218110084534, 0.0, 0.0], Predicted: [0.6462598443031311, -0.023277103900909424, 0.06247619166970253]\n",
            "True: [0.6436207890510559, 0.0, 0.0], Predicted: [0.5004315376281738, 0.062440380454063416, 0.273197740316391]\n",
            "True: [1.0313524007797241, 0.0, 0.0], Predicted: [0.8181020021438599, 0.03950820863246918, 0.06280842423439026]\n",
            "True: [0.00011194492981303483, 0.0, 0.0], Predicted: [0.030031884089112282, 0.06401211023330688, 0.32672688364982605]\n",
            "True: [2.35703182220459, 0.0, 0.0], Predicted: [1.9373921155929565, -0.03596235811710358, -0.03431481868028641]\n",
            "True: [2.0939064025878906, 0.0, 0.0], Predicted: [2.080561399459839, -0.03948521614074707, -0.16028252243995667]\n",
            "True: [0.0011330995475873351, 0.1755286604166031, 0.8725742101669312], Predicted: [0.03304532170295715, 0.21459753811359406, 1.1331350803375244]\n",
            "True: [1.4301701412477996e-05, 0.20323969423770905, 1.0102428197860718], Predicted: [-0.009359867312014103, 0.44988077878952026, 1.397359848022461]\n",
            "True: [0.47877568006515503, 0.0, 0.0], Predicted: [0.5039944648742676, 0.0005317181348800659, 0.015876509249210358]\n",
            "True: [1.2934714555740356, 0.0, 0.0], Predicted: [1.2087260484695435, 0.03382907807826996, 0.06555110216140747]\n",
            "True: [0.0016195793868973851, 0.0, 0.0], Predicted: [0.1593542993068695, 0.0304814875125885, 0.07300934195518494]\n",
            "True: [4.317337879911065e-05, 0.2351386398077011, 1.1689940690994263], Predicted: [0.03377661108970642, 0.586300790309906, 1.6700347661972046]\n",
            "True: [0.4377216398715973, 0.0, 0.0], Predicted: [0.11896587908267975, 0.06619425117969513, 0.37432387471199036]\n",
            "True: [0.5075021386146545, 0.0, 0.0], Predicted: [-0.019608598202466965, 0.3012884259223938, 0.5184979438781738]\n",
            "True: [0.003159879706799984, 3.100484609603882, 5], Predicted: [-0.11676696687936783, 4.7900390625, 4.9200053215026855]\n",
            "True: [1.029862880706787, 0.0, 0.0], Predicted: [0.9177960753440857, -0.004292517900466919, -0.17553827166557312]\n",
            "True: [1.4153259992599487, 0.0, 0.0], Predicted: [0.7165140509605408, 0.0023082196712493896, 0.0049591064453125]\n",
            "True: [0.08146818727254868, 0.0, 0.0], Predicted: [0.04364105314016342, 0.1937299519777298, 0.6907230019569397]\n",
            "True: [0.026515061035752296, 0.0, 0.0], Predicted: [0.1645534336566925, 0.03651922941207886, 0.11457274854183197]\n",
            "True: [0.430856853723526, 0.0, 0.0], Predicted: [0.22450564801692963, 0.01772823929786682, -0.1108129546046257]\n",
            "True: [0.4014361798763275, 0.0, 0.0], Predicted: [0.3233078718185425, 0.003065556287765503, 0.043442241847515106]\n",
            "True: [2.3701408281340264e-05, 0.0, 0.0], Predicted: [-0.018508080393075943, 0.10542182624340057, 0.5520049929618835]\n",
            "True: [0.40053504705429077, 0.0, 0.0], Predicted: [0.3377210795879364, 0.04562389850616455, 0.07682626694440842]\n",
            "True: [2.588771894806996e-05, 0.3187425136566162, 1.584641695022583], Predicted: [-0.0070991478860378265, 0.2846146821975708, 1.2242048978805542]\n",
            "True: [0.4874012768268585, 0.0, 0.0], Predicted: [0.6353675723075867, 0.023319050669670105, 0.01479136198759079]\n",
            "True: [0.022812148556113243, 0.0, 0.0], Predicted: [-0.005971973761916161, 0.05912363529205322, 0.15429836511611938]\n",
            "True: [3.235857730032876e-05, 0.07119719684123993, 0.35395166277885437], Predicted: [0.006113572046160698, 0.2986357808113098, 1.3242712020874023]\n",
            "True: [0.08260390907526016, 0.0, 0.0], Predicted: [0.24549278616905212, -0.011199697852134705, -0.05499177426099777]\n",
            "True: [0.014809338375926018, 0.0, 0.0], Predicted: [-0.022312434390187263, 0.8409255146980286, 1.1203397512435913]\n",
            "True: [0.07953701913356781, 0.0, 0.0], Predicted: [0.18606270849704742, 0.05654539167881012, 0.06541754305362701]\n",
            "True: [0.9151365756988525, 0.0, 0.0], Predicted: [0.4818285405635834, 0.033606693148612976, 0.15739792585372925]\n",
            "True: [1.2992815754842013e-05, 0.37844428420066833, 1.881453514099121], Predicted: [-0.03289220109581947, 0.33095818758010864, 0.98949134349823]\n",
            "True: [1.0242137908935547, 0.0, 0.0], Predicted: [0.9197731614112854, 0.030984967947006226, 0.02774690091609955]\n",
            "True: [8.718674507690594e-06, 0.29792243242263794, 1.4808094501495361], Predicted: [-0.016091935336589813, 0.4116281270980835, 0.8231311440467834]\n",
            "True: [0.4960842728614807, 0.0, 0.0], Predicted: [0.3370695114135742, -0.0018420964479446411, 0.14321310818195343]\n",
            "True: [0.0009731942554935813, 0.0, 0.0], Predicted: [0.024418747052550316, 0.33152544498443604, 0.7639408707618713]\n",
            "True: [0.8906477093696594, 0.0, 0.0], Predicted: [0.3549710810184479, 0.06751556694507599, -0.18278220295906067]\n",
            "True: [1.4190497398376465, 0.0, 0.0], Predicted: [1.463691234588623, -0.011381685733795166, 0.030623197555541992]\n",
            "True: [7.72287166910246e-05, 0.5640607476234436, 2.804245710372925], Predicted: [0.0219144094735384, 0.25485867261886597, 0.8167051076889038]\n",
            "True: [0.9410977363586426, 0.0, 0.0], Predicted: [0.7480149269104004, 0.025571271777153015, 0.07513190060853958]\n",
            "True: [0.06478705257177353, 0.0, 0.0], Predicted: [0.08425076305866241, 0.019154399633407593, 0.03396385908126831]\n",
            "True: [1.1369887590408325, 0.0, 0.0], Predicted: [1.0649217367172241, 0.027196615934371948, 0.0139385387301445]\n",
            "True: [0.38794928789138794, 0.0, 0.0], Predicted: [0.4895332157611847, 0.0004800856113433838, -0.09228111058473587]\n",
            "True: [0.0005396865890361369, 0.29612821340560913, 1.4721671342849731], Predicted: [0.03821633756160736, 0.833738386631012, 2.2904064655303955]\n",
            "True: [0.43382540345191956, 0.0, 0.0], Predicted: [0.4285963773727417, 0.017592400312423706, -0.0006263554096221924]\n",
            "True: [6.485635094577447e-05, 0.45258480310440063, 2.2500252723693848], Predicted: [0.0208099614828825, 0.5132800340652466, 1.6602355241775513]\n",
            "True: [0.28596606850624084, 0.0, 0.0], Predicted: [0.2744092643260956, 0.016968131065368652, 0.04430394619703293]\n",
            "True: [0.27265772223472595, 0.0, 0.0], Predicted: [0.22182178497314453, 0.17185290157794952, 0.013897985219955444]\n",
            "True: [0.24541324377059937, 0.0, 0.0], Predicted: [0.18631254136562347, 0.005595266819000244, 0.05199609696865082]\n",
            "True: [1.3357797797652893e-05, 0.08644977957010269, 0.4297795295715332], Predicted: [-0.04129219800233841, 0.32015806436538696, 1.4219917058944702]\n",
            "True: [1.1913163689314388e-05, 0.2627059519290924, 1.306018352508545], Predicted: [-0.01262713223695755, 0.32337868213653564, 0.9899477362632751]\n",
            "True: [2.8640677555813454e-05, 0.0, 0.0], Predicted: [-0.007296150550246239, 0.19970516860485077, 0.558925986289978]\n",
            "True: [0.4972945749759674, 0.0, 0.0], Predicted: [0.5056774020195007, -0.023126229643821716, -0.04904208332300186]\n",
            "True: [0.0005478126113303006, 0.0, 0.0], Predicted: [-0.009820446372032166, 0.45535194873809814, 1.0533164739608765]\n",
            "True: [0.8450002670288086, 0.0, 0.0], Predicted: [0.7404792904853821, -0.011497795581817627, 0.04277912899851799]\n",
            "True: [7.649173312529456e-06, 0.3506743907928467, 1.7433977127075195], Predicted: [-0.01288185827434063, 0.169515922665596, 0.47623950242996216]\n",
            "True: [0.2353268563747406, 0.0, 0.0], Predicted: [0.16515447199344635, 0.06652481853961945, 0.16465041041374207]\n"
          ]
        }
      ],
      "source": [
        "# Print true and predicted values\n",
        "for true, pred in zip(y_test[:100], y_pred.tolist()[:100]):\n",
        "    print(f\"True: {true}, Predicted: {pred}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8qeBv36fri5L",
        "Dz2YtNA-rmA7"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
