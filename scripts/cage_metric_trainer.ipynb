{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "rZUrHp7UPz4f",
        "NaFecMlwFu0M",
        "8qeBv36fri5L"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Panda Python API\n",
        "# https://projects.saifsidhik.page/panda_robot/index.html\n",
        "# ! pip install panda-robot"
      ],
      "metadata": {
        "id": "t7ZigHs04ZnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import csv\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n"
      ],
      "metadata": {
        "id": "ouxbm40nx9cX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MPPI-generated dataset"
      ],
      "metadata": {
        "id": "rZUrHp7UPz4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing with limit filters\n",
        "filename_input = '/content/states_from_mppi.csv'\n",
        "\n",
        "input = []\n",
        "with open(filename_input, mode='r', newline='') as file:\n",
        "    reader = csv.reader(file)\n",
        "    headers = next(reader)\n",
        "    for row in reader:\n",
        "        input.append([float(r) for r in row])\n",
        "inputs = [input[i][4:] for i in range(len(input))]\n",
        "print(len(inputs))\n",
        "print(len(inputs[0]))\n",
        "print(inputs[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2zT2XJCClON",
        "outputId": "6c8447b4-bb09-4720-e6cc-91d1e8617102"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11378\n",
            "12\n",
            "[5.245803356170654, 4.483570098876953, 0.309131383895874, -1.6232921495884511e-07, -1.7172726074932143e-05, 2.6944117053062655e-05, 4.6867218017578125, 3.708601236343384, -0.0006153479916974902, 0.06261026859283447, -0.14187613129615784, 0.0013632385525852442]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing with limit filters\n",
        "filename_input = '/content/prob_ao_est.csv'\n",
        "label = []\n",
        "with open(filename_input, mode='r', newline='') as file:\n",
        "    reader = csv.reader(file)\n",
        "    headers = next(reader)\n",
        "    for row in reader:\n",
        "        label.append([float(r) for r in row])\n",
        "\n",
        "success_labels = [label[i][-2] for i in range(len(label))]\n",
        "maneuver_labels = [label[i][-1] for i in range(len(label))]\n",
        "print(len(success_labels))\n",
        "print(success_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR62JbxVXM6Y",
        "outputId": "50f75926-8d34-4294-a7b4-64b81b62de8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11378\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# noninf_idx = []\n",
        "# for i,l in enumerate(labels):\n",
        "#     if l != float('inf'): noninf_idx.append(i)\n",
        "\n",
        "# inputs = [inputs[i] for i in noninf_idx]\n",
        "# labels = [labels[i] for i in noninf_idx]\n",
        "# print(len(inputs))\n",
        "# print(len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8x7h4wa-utq",
        "outputId": "f15d6f63-669c-48cd-bb98-57a6f28d546d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9637\n",
            "9637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs = [input[i][4:] for i in range(len(input))]\n",
        "# filter = [[0.0, 10.0],\n",
        "#           [0.0, 10.0],\n",
        "#           [-10.0, 10.0],\n",
        "#           [-10.0, 10.0],\n",
        "#           [-20.0, 20.0],\n",
        "#           [-20.0, 20.0],\n",
        "#           [-math.pi/2, math.pi/2],\n",
        "#           [-5.0, 5.0],\n",
        "#           [-5.0, 5.0],\n",
        "#           [-math.pi/3, math.pi/3],\n",
        "#           ]\n"
      ],
      "metadata": {
        "id": "amFeAi72HdCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# idx = []\n",
        "# for k, data in enumerate(inputs):\n",
        "#     bool_list = [(data[i] > filter[i][0] and data[i] < filter[i][1]) for i in range(len(filter))]\n",
        "#     if False not in bool_list:\n",
        "#         idx.append(k)\n",
        "# filtered_inputs = [[count,]+inputs[i] for count, i in enumerate(idx)]\n",
        "# print(len(filtered_inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr7Ad737MOZV",
        "outputId": "30b56dbd-6360-4f29-b673-47bf7d11d354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save data to a CSV file with headers\n",
        "# headers = ['data_id', 'xo', 'yo', 'vxo', 'vyo', 'xg', 'yg', 'thetag', 'vxg', 'vyg', 'omegag']\n",
        "# filename = 'filtered_states_from_mppi.csv'\n",
        "# with open(filename, mode='w', newline='') as file:\n",
        "#     writer = csv.writer(file)\n",
        "#     writer.writerow(headers)\n",
        "#     writer.writerows(filtered_inputs)"
      ],
      "metadata": {
        "id": "5Q7Ez3fCOpth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xo = [inputs[i][0] for i in range(len(inputs))]\n",
        "# xo = [success_labels[i] for i in range(len(success_labels))]\n",
        "xo = [maneuver_labels[i] for i in range(len(maneuver_labels))]\n",
        "\n",
        "# Create the histogram\n",
        "plt.hist(xo, bins=40, edgecolor='black')  # You can adjust the number of bins\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Float Numbers Between 0 and 5')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "J6Zw-HqRHE69",
        "outputId": "2dfaacdb-54f6-4940-ab8e-403cff57d723"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABUdElEQVR4nO3de1wU1f8/8NdyW64LIsJiIuEdFCUxdVMUL7kimqZm5g0MMw0txbQo856o5S1DqUyw1Ez7WN8SFfFuiZUkaajkBcOSxTuIyv38/ujB/Fy5CBuwwLyej8c8as6cnXnP7AIvZ87MKoQQAkREREQyZmLsAoiIiIiMjYGIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiqxJNPPong4GBjl1HvffDBB2jWrBlMTU3h4+Pzn9Z1+fJlKBQKxMTEVElt9V1MTAwUCgVOnDhh7FJIxoo/h5cvXzZ2KfUOAxGV8Lhf/P7+/mjXrt1/3s6uXbswb968/7weudi7dy9mzZqFbt26ITo6GosXLy6zb3BwMBQKRanTnj17aqzmM2fOYN68eRX+5T1v3jwoFAq4uLjg/v37JZY/+eSTGDhwYBVXWb88+t6bmZnBzc0NI0eOxJkzZwxa5/379zFv3jwcOnSoaoutZf755x+MGDECDg4OUKlUGDx4MC5dumTssgxS/Hu8tEmn0xm7vFrJzNgFUP2QkpICE5PK5etdu3YhMjKSoaiCDhw4ABMTE3z++eewsLB4bH+lUon169eXaO/QoUN1lFeqM2fOYP78+fD398eTTz5Z4dddu3YN69atw4wZM6qvuHrs4fe+oKAAFy9eRFRUFPbs2YMzZ86gcePGlVrf/fv3MX/+fAD//oOoPsrOzkavXr2QmZmJd955B+bm5li5ciV69uyJpKQkNGzY0NglGmTBggXw8PDQa3NwcDBOMbUcAxFVCaVSaewSKu3evXuwsbExdhkVdu3aNVhZWVUoDAGAmZkZxowZU81VVQ8fHx988MEHeO2112BlZWXscmpUVXwuS3vvu3btioEDByI2NhavvPLKf1p/fbR27VqcP38ev/zyC55++mkAQEBAANq1a4fly5eXe0a2NgsICECnTp2MXUadwEtmVCUeHUOUn5+P+fPno2XLlrC0tETDhg3RvXt3xMfHA/j3tH5kZCQA6J3KLXbv3j3MmDEDbm5uUCqVaN26NT788EMIIfS2++DBA7z++utwcnKCnZ0dnnvuOfzzzz9QKBR6Z56KL8WcOXMGo0aNQoMGDdC9e3cAwKlTpxAcHIxmzZrB0tISarUaL7/8Mm7evKm3reJ1/PnnnxgzZgzs7e3RqFEjvPfeexBC4MqVKxg8eDBUKhXUajWWL19eoWNXUFCAhQsXonnz5lAqlXjyySfxzjvvIDc3V+qjUCgQHR2Ne/fuScequsb+HDhwAH5+frCxsYGDgwMGDx6Ms2fP6vX566+/8Nprr6F169awsrJCw4YN8cILL+hdGouJicELL7wAAOjVq5dUd0Uuu8yZMwcZGRlYt25duf0OHTpU6jpLGx8VHBwMW1tbpKWlYeDAgbC1tcUTTzwhfQ5Pnz6N3r17w8bGBu7u7tiyZUup27x//z5effVVNGzYECqVCuPGjcPt27dL9Nu9e7d0HO3s7BAYGIjk5GS9PsU1Xbx4EQMGDICdnR1Gjx4NADh//jyGDRsGtVoNS0tLNGnSBCNHjkRmZubjDl+p1Go1gH/D0sPu3LmDadOmST9rLVq0wNKlS1FUVCQdy0aNGgEA5s+fL72P8+bNw/fffw+FQoFTp05J6/vf//4HhUKBoUOH6m3H09MTL774ol7bpk2b4OvrCysrKzg6OmLkyJG4cuVKidp//vln9O/fH/b29rC2tkbPnj3x008/6fUp/vm8cOECgoOD4eDgAHt7e4wfP77Uy6+P+uabb/D0009LYQgA2rRpgz59+mDbtm2PfX10dDR69+4NZ2dnKJVKeHl5lfr5Lb7s++OPP6Jz586wtLREs2bN8MUXX5Tom5ycjN69e8PKygpNmjTBokWLpPelMu7evYvCwsJKv05ueIaIypSZmYkbN26UaM/Pz3/sa+fNm4eIiAhMmDABnTt3RlZWFk6cOIHffvsNzz77LF599VVcvXoV8fHx+PLLL/VeK4TAc889h4MHDyIkJAQ+Pj6Ii4vDzJkz8c8//2DlypVS3+DgYGzbtg1jx45F165dcfjwYQQGBpZZ1wsvvICWLVti8eLFUriKj4/HpUuXMH78eKjVaiQnJ+PTTz9FcnIyjh8/rhfUAODFF1+Ep6cnlixZgtjYWCxatAiOjo745JNP0Lt3byxduhSbN2/Gm2++iaeffho9evQo91hNmDABGzduxPDhwzFjxgz8/PPPiIiIwNmzZ/Htt98CAL788kt8+umn+OWXX6RLIc8888xj34dH3z9zc3PY29uX2X/fvn0ICAhAs2bNMG/ePDx48ABr1qxBt27d8Ntvv0mXvX799VccO3YMI0eORJMmTXD58mWsW7cO/v7+OHPmDKytrdGjRw+8/vrr+Oijj/DOO+/A09MTAKT/lsfPzw+9e/fGsmXLMHny5Co7S1RYWIiAgAD06NEDy5Ytw+bNmzFlyhTY2Njg3XffxejRozF06FBERUVh3Lhx0Gg0JS43TJkyBQ4ODpg3bx5SUlKwbt06/PXXX1I4A/59v4KCgqDVarF06VLcv38f69atQ/fu3XHy5Em9y4cFBQXQarXo3r07PvzwQ1hbWyMvLw9arRa5ubmYOnUq1Go1/vnnH+zcuRN37twp9z0sVvzeFxYW4tKlS3jrrbfQsGFDvTFY9+/fR8+ePfHPP//g1VdfRdOmTXHs2DGEh4cjPT0dq1atQqNGjbBu3TpMnjwZzz//vBR02rdvjyZNmkChUODIkSNo3749AODo0aMwMTHBjz/+KG3n+vXrOHfuHKZMmSK1vf/++3jvvfcwYsQITJgwAdevX8eaNWvQo0cPnDx5Urqsc+DAAQQEBMDX1xdz586FiYmJFD6OHj2Kzp076+33iBEj4OHhgYiICPz2229Yv349nJ2dsXTp0jKPVVFREU6dOoWXX365xLLOnTtj7969uHv3Luzs7Mpcx7p169C2bVs899xzMDMzww8//IDXXnsNRUVFCA0N1et74cIFDB8+HCEhIQgKCsKGDRsQHBwMX19ftG3bFgCg0+nQq1cvFBQU4O2334aNjQ0+/fTTSv8s9OrVC9nZ2bCwsIBWq8Xy5cvRsmXLSq1DNgTRI6KjowWAcqe2bdvqvcbd3V0EBQVJ8x06dBCBgYHlbic0NFSU9hH87rvvBACxaNEivfbhw4cLhUIhLly4IIQQIjExUQAQ06ZN0+sXHBwsAIi5c+dKbXPnzhUAxEsvvVRie/fv3y/R9tVXXwkA4siRIyXWMXHiRKmtoKBANGnSRCgUCrFkyRKp/fbt28LKykrvmJQmKSlJABATJkzQa3/zzTcFAHHgwAGpLSgoSNjY2JS7vof7lva+9ezZU+qTmpoqAIjo6GipzcfHRzg7O4ubN29Kbb///rswMTER48aNk9pKO2YJCQkCgPjiiy+ktu3btwsA4uDBgxWqu/gYX79+XRw+fFgAECtWrJCWu7u7632uDh48WOr6S9u34mOyePFiqa34fVIoFGLr1q1S+7lz50p8hop/Lnx9fUVeXp7UvmzZMgFA/N///Z8QQoi7d+8KBwcH8corr+jVpNPphL29vV57cU1vv/22Xt+TJ08KAGL79u0VOGr6ynrvn3jiCZGYmKjXd+HChcLGxkb8+eefeu1vv/22MDU1FWlpaUIIIa5fv17ieBRr27atGDFihDTfsWNH8cILLwgA4uzZs0IIIXbs2CEAiN9//10IIcTly5eFqampeP/99/XWdfr0aWFmZia1FxUViZYtWwqtViuKioqkfvfv3xceHh7i2WefldqKPzsvv/yy3jqff/550bBhw3KPWfH+LViwoMSyyMhIAUCcO3eu3HWU9jOh1WpFs2bN9Nrc3d1L/G65du2aUCqVYsaMGVLbtGnTBADx888/6/Wzt7cXAERqamq59Xz99dciODhYbNy4UXz77bdi9uzZwtraWjg5OUnvK+njJTMqU2RkJOLj40tMxf8SLI+DgwOSk5Nx/vz5Sm93165dMDU1xeuvv67XPmPGDAghsHv3bgCQ7pZ67bXX9PpNnTq1zHVPmjSpRNvD/+LKycnBjRs30LVrVwDAb7/9VqL/hAkTpP83NTVFp06dIIRASEiI1O7g4IDWrVs/9g6VXbt2AQDCwsL02osHE8fGxpb7+vJYWlqWeO/Ku4yXnp6OpKQkBAcHw9HRUWpv3749nn32WalWQP+Y5efn4+bNm2jRogUcHBxKPWaG6NGjB3r16oVly5bhwYMHVbJOQP/9K36fbGxsMGLECKm9devWcHBwKPX9mzhxIszNzaX5yZMnw8zMTDo+8fHxuHPnDl566SXcuHFDmkxNTdGlSxccPHiwxDonT56sN198BiguLq5Cl3se9fB7HxcXh08++QS2trYYMGAA/vzzT6nf9u3b4efnhwYNGujV2rdvXxQWFuLIkSOP3Zafnx+OHj0K4N9LM7///jsmTpwIJycnqf3o0aNwcHCQ7k7dsWMHioqKMGLECL3tqtVqtGzZUjpGSUlJOH/+PEaNGoWbN29K/e7du4c+ffrgyJEjJS4hPfoz7ufnh5s3byIrK6vMfSj+fJU2FtLS0lKvT1ke/pkoPrves2dPXLp0qcRlTi8vL/j5+UnzjRo1KvH7YteuXejataveGbBGjRpJl1QfZ8SIEYiOjsa4ceMwZMgQLFy4EHFxcbh58ybef//9Cq1DbnjJjMrUuXPnUgfjFf/yLM+CBQswePBgtGrVCu3atUP//v0xduzYCoWpv/76C40bNy5xerr4Ustff/0l/dfExKTEJY0WLVqUue5H+wLArVu3MH/+fGzduhXXrl3TW1baeI2mTZvqzdvb28PS0hJOTk4l2h8dh/So4n14tGa1Wg0HBwdpXw1hamqKvn37Vrh/8bZat25dYpmnpyfi4uKkAb8PHjxAREQEoqOj8c8//+iN7TJ0jEtp5s2bh549eyIqKgrTp0//z+uztLSUxsMUs7e3ly79PNpe2tigRy832NrawtXVVRo/VfyPgN69e5dag0ql0ps3MzNDkyZN9No8PDwQFhaGFStWYPPmzfDz88Nzzz0njV17nNLe+wEDBqBly5YIDw/H//73P6nWU6dOlTgmxR79eSiNn58foqKicOHCBVy8eBEKhQIajUYKSq+88gqOHj2Kbt26SXeinj9/HkKIMi/dFAfO4mMZFBRU5vYzMzPRoEEDaf7Rn8/iZbdv3y5x7IsVh5mHx+0Vy8nJ0etTlp9++glz585FQkJCiRCbmZmp9749WmNxnQ9/3v766y906dKlRL/Sfj4rqnv37ujSpQv27dtn8DrqMwYiqhY9evTAxYsX8X//93/Yu3cv1q9fj5UrVyIqKkrvX+g1rbRfaiNGjMCxY8cwc+ZM+Pj4wNbWFkVFRejfv3+pAxhNTU0r1AagxCDwsjz6x7i2mzp1KqKjozFt2jRoNBrY29tDoVBg5MiRBg36LEuPHj3g7++PZcuWlXp2r6zjVtYA0rLep//6/j2seP+//PJLaSDzwx4d1KxUKkt9ZMXy5csRHBws/Qy9/vrriIiIwPHjx0sEqIpo0qQJWrdurXfWp6ioCM8++yxmzZpV6mtatWr12PUW35xw5MgRXLp0CR07doSNjQ38/Pzw0UcfITs7GydPntQ7K1FUVASFQoHdu3eXeuxtbW2lfsC/DyQt60GkxX2LGfJeOjo6QqlUIj09vcSy4rbyHlVw8eJF9OnTB23atMGKFSvg5uYGCwsL7Nq1CytXrizxM1GVn7fKcnNzQ0pKSrVvpy5iIKJq4+joiPHjx2P8+PHIzs5Gjx49MG/ePCkQlfXHzN3dHfv27SsxiPHcuXPS8uL/FhUVITU1Ve9fmhcuXKhwjbdv38b+/fsxf/58zJkzR2o35FKfIYr34fz583qDjTMyMnDnzh1pX2uqFgCl/rI8d+4cnJycpNvBv/nmGwQFBeldgsvJycGdO3f0XlcVQW/evHnw9/fHJ598UmJZ8b/+H93ufzmz9jjnz59Hr169pPns7Gykp6djwIABAIDmzZsDAJydnSt1hq403t7e8Pb2xuzZs3Hs2DF069YNUVFRWLRokUHrKygoQHZ2tjTfvHlzZGdnP7bO8t7Hpk2bomnTpjh69CguXbokXQrq0aMHwsLCsH37dhQWFurdXNC8eXMIIeDh4VFu6Co+liqV6j8fy/KYmJjA29u71IfR/vzzz2jWrFm5A6p/+OEH5Obm4vvvv9c7+1Pa5dGKcnd3L/X30H8NM5cuXSrzjKDccQwRVYtHLxXZ2tqiRYsWeqeki/+4PvrHbMCAASgsLMTHH3+s175y5UooFAoEBAQAALRaLYB/nx/ysDVr1lS4zuJ/qT36L7NVq1ZVeB3/RfEf0Ue3t2LFCgAo9465qubq6gofHx9s3LhR7z35448/sHfvXqlW4N/j9ugxW7NmTYkzM2W9x5XRs2dP+Pv7Y+nSpdLli2Lu7u4wNTUtMdbl0c9EVfr000/17rRct24dCgoK9D6XKpUKixcvLvWOzOvXrz92G1lZWSgoKNBr8/b2homJSamXdSrizz//REpKit6DOUeMGIGEhATExcWV6H/nzh2pBmtra6mtNH5+fjhw4AB++eUXKRD5+PjAzs4OS5YsgZWVFXx9faX+Q4cOhampKebPn1/icySEkH5/+Pr6onnz5vjwww/1glyxihzLiho+fDh+/fVXvVCUkpKCAwcOSI+PKEtpv0cyMzMRHR1tcD0DBgzA8ePH8csvv0ht169fx+bNmyv0+tKOza5du5CYmIj+/fsbXFd9xjNEVC28vLzg7+8PX19fODo64sSJE/jmm2/0brst/gX5+uuvQ6vVwtTUFCNHjsSgQYPQq1cvvPvuu7h8+TI6dOiAvXv34v/+7/8wbdo06V+Nvr6+GDZsGFatWoWbN29Kt90XDxqtyNkJlUol3YKdn5+PJ554Anv37kVqamo1HJWSOnTogKCgIHz66ae4c+cOevbsiV9++QUbN27EkCFD9M5E1IQPPvgAAQEB0Gg0CAkJkW67t7e313uu08CBA/Hll1/C3t4eXl5eSEhIwL59+0o8zdfHxwempqZYunQpMjMzoVQqpWe1VMbcuXNLPRb29vZ44YUXsGbNGigUCjRv3hw7d+6s0NgXQ+Xl5aFPnz4YMWIEUlJSsHbtWnTv3h3PPfccgH8/U+vWrcPYsWPRsWNHjBw5Eo0aNUJaWhpiY2PRrVu3EmH/UQcOHMCUKVPwwgsvoFWrVigoKMCXX34JU1NTDBs27LE1FhQUYNOmTQD+vex0+fJlREVFoaioCHPnzpX6zZw5E99//z0GDhwo3fZ97949nD59Gt988w0uX74MJycnWFlZwcvLC19//TVatWoFR0dHtGvXThok7efnh82bN0OhUEiX0ExNTfHMM88gLi4O/v7+eg8Ubd68ORYtWoTw8HBcvnwZQ4YMgZ2dHVJTU/Htt99i4sSJePPNN2FiYoL169cjICAAbdu2xfjx4/HEE0/gn3/+wcGDB6FSqfDDDz9U7g0sw2uvvYbPPvsMgYGBePPNN2Fubo4VK1bAxcXlsU9M79evHywsLDBo0CC8+uqryM7OxmeffQZnZ+dSL8NVxKxZs/Dll1+if//+eOONN6Tb7t3d3fWe+1SWZ555Bk899RQ6deoEe3t7/Pbbb9iwYQPc3NzwzjvvGFRTvWeMW9uodiu+vfjXX38tdXnPnj0fe9v9okWLROfOnYWDg4OwsrISbdq0Ee+//77e7coFBQVi6tSpolGjRkKhUOjdgn/37l0xffp00bhxY2Fubi5atmwpPvjgA71bb4UQ4t69eyI0NFQ4OjoKW1tbMWTIEJGSkiIA6N0G//Dt3I/6+++/xfPPPy8cHByEvb29eOGFF8TVq1fLvHX/0XWUdTt8acepNPn5+WL+/PnCw8NDmJubCzc3NxEeHi5ycnIqtJ3SVKRvabemCyHEvn37RLdu3YSVlZVQqVRi0KBB4syZM3p9bt++LcaPHy+cnJyEra2t0Gq14ty5cyU+B0II8dlnn4lmzZoJU1PTx96CX9771LNnTwGgxOMcrl+/LoYNGyasra1FgwYNxKuvvir++OOPUm+7r8z79Ogt/sU/F4cPHxYTJ04UDRo0ELa2tmL06NF6jykodvDgQaHVaoW9vb2wtLQUzZs3F8HBweLEiROPrenSpUvi5ZdfFs2bNxeWlpbC0dFR9OrVS+zbt6/0A/eQ0m67V6lUok+fPqW+/u7duyI8PFy0aNFCWFhYCCcnJ/HMM8+IDz/8UO/n9dixY8LX11dYWFiU+NlITk4WAISnp6feuhctWiQAiPfee6/UWv/3v/+J7t27CxsbG2FjYyPatGkjQkNDRUpKil6/kydPiqFDh4qGDRsKpVIp3N3dxYgRI8T+/fulPmV9dorft8fdpi6EEFeuXBHDhw8XKpVK2NraioEDB4rz588/9nVCCPH999+L9u3bC0tLS/Hkk0+KpUuXig0bNpTY9qOfq2I9e/bUeyyGEEKcOnVK9OzZU1haWoonnnhCLFy4UHz++ecV2p93331X+Pj4CHt7e2Fubi6aNm0qJk+eLHQ6XYX2R44UQtTAKC6iGpSUlISnnnoKmzZtqvAtqkREJG8cQ0R1WmnPBlm1ahVMTEwe+4RoIiKiYhxDRHXasmXLkJiYiF69esHMzAy7d+/G7t27MXHiRLi5uRm7PCIiqiN4yYzqtPj4eMyfPx9nzpxBdnY2mjZtirFjx+Ldd98t8bwXIiKisjAQERERkexxDBERERHJHgMRERERyR4HWVRAUVERrl69Cjs7uzr3nVNERERyJYTA3bt30bhx41K/M/BhDEQVcPXqVd6xREREVEdduXLlsV+KzEBUAcVf6nflyhWoVCojV0NEREQVkZWVBTc3t3K/nLcYA1EFFF8mU6lUDERERER1TEWGu3BQNREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJnpmxCyAgLS0NN27cqFBfJycnNG3atJorIiIikhcGIiNLS0tD6zaeyHlwv0L9La2skXLuLEMRERFRFWIgMrIbN24g58F9NBw4A+YN3crtm3/zCm7uXI4bN24wEBEREVUhBqJawryhG5TqFsYug4iISJY4qJqIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkr9YEoiVLlkChUGDatGlSW05ODkJDQ9GwYUPY2tpi2LBhyMjI0HtdWloaAgMDYW1tDWdnZ8ycORMFBQV6fQ4dOoSOHTtCqVSiRYsWiImJqYE9IiIiorqiVgSiX3/9FZ988gnat2+v1z59+nT88MMP2L59Ow4fPoyrV69i6NCh0vLCwkIEBgYiLy8Px44dw8aNGxETE4M5c+ZIfVJTUxEYGIhevXohKSkJ06ZNw4QJExAXF1dj+0dERES1m9EDUXZ2NkaPHo3PPvsMDRo0kNozMzPx+eefY8WKFejduzd8fX0RHR2NY8eO4fjx4wCAvXv34syZM9i0aRN8fHwQEBCAhQsXIjIyEnl5eQCAqKgoeHh4YPny5fD09MSUKVMwfPhwrFy50ij7S0RERLWP0QNRaGgoAgMD0bdvX732xMRE5Ofn67W3adMGTZs2RUJCAgAgISEB3t7ecHFxkfpotVpkZWUhOTlZ6vPourVarbQOIiIiIqM+mHHr1q347bff8Ouvv5ZYptPpYGFhAQcHB712FxcX6HQ6qc/DYah4efGy8vpkZWXhwYMHsLKyKrHt3Nxc5ObmSvNZWVmV3zkiIiKqM4x2hujKlSt44403sHnzZlhaWhqrjFJFRETA3t5emtzcyv9KDSIiIqrbjBaIEhMTce3aNXTs2BFmZmYwMzPD4cOH8dFHH8HMzAwuLi7Iy8vDnTt39F6XkZEBtVoNAFCr1SXuOiuef1wflUpV6tkhAAgPD0dmZqY0XblypSp2mYiIiGopowWiPn364PTp00hKSpKmTp06YfTo0dL/m5ubY//+/dJrUlJSkJaWBo1GAwDQaDQ4ffo0rl27JvWJj4+HSqWCl5eX1OfhdRT3KV5HaZRKJVQqld5ERERE9ZfRxhDZ2dmhXbt2em02NjZo2LCh1B4SEoKwsDA4OjpCpVJh6tSp0Gg06Nq1KwCgX79+8PLywtixY7Fs2TLodDrMnj0boaGhUCqVAIBJkybh448/xqxZs/Dyyy/jwIED2LZtG2JjY2t2h4mIiKjWqtXfdr9y5UqYmJhg2LBhyM3NhVarxdq1a6Xlpqam2LlzJyZPngyNRgMbGxsEBQVhwYIFUh8PDw/ExsZi+vTpWL16NZo0aYL169dDq9UaY5eIiIioFqpVgejQoUN685aWloiMjERkZGSZr3F3d8euXbvKXa+/vz9OnjxZFSUSERFRPWT05xARERERGRsDEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREcmeUQPRunXr0L59e6hUKqhUKmg0GuzevVta7u/vD4VCoTdNmjRJbx1paWkIDAyEtbU1nJ2dMXPmTBQUFOj1OXToEDp27AilUokWLVogJiamJnaPiIiI6ggzY268SZMmWLJkCVq2bAkhBDZu3IjBgwfj5MmTaNu2LQDglVdewYIFC6TXWFtbS/9fWFiIwMBAqNVqHDt2DOnp6Rg3bhzMzc2xePFiAEBqaioCAwMxadIkbN68Gfv378eECRPg6uoKrVZbsztMREREtZJRA9GgQYP05t9//32sW7cOx48flwKRtbU11Gp1qa/fu3cvzpw5g3379sHFxQU+Pj5YuHAh3nrrLcybNw8WFhaIioqCh4cHli9fDgDw9PTEjz/+iJUrVzIQEREREYBaNIaosLAQW7duxb1796DRaKT2zZs3w8nJCe3atUN4eDju378vLUtISIC3tzdcXFykNq1Wi6ysLCQnJ0t9+vbtq7ctrVaLhISEMmvJzc1FVlaW3kRERET1l1HPEAHA6dOnodFokJOTA1tbW3z77bfw8vICAIwaNQru7u5o3LgxTp06hbfeegspKSnYsWMHAECn0+mFIQDSvE6nK7dPVlYWHjx4ACsrqxI1RUREYP78+VW+r0RERFQ7GT0QtW7dGklJScjMzMQ333yDoKAgHD58GF5eXpg4caLUz9vbG66urujTpw8uXryI5s2bV1tN4eHhCAsLk+azsrLg5uZWbdsjIiIi4zL6JTMLCwu0aNECvr6+iIiIQIcOHbB69epS+3bp0gUAcOHCBQCAWq1GRkaGXp/i+eJxR2X1UalUpZ4dAgClUind+VY8ERERUf1l9ED0qKKiIuTm5pa6LCkpCQDg6uoKANBoNDh9+jSuXbsm9YmPj4dKpZIuu2k0Guzfv19vPfHx8XrjlIiIiEjejHrJLDw8HAEBAWjatCnu3r2LLVu24NChQ4iLi8PFixexZcsWDBgwAA0bNsSpU6cwffp09OjRA+3btwcA9OvXD15eXhg7diyWLVsGnU6H2bNnIzQ0FEqlEgAwadIkfPzxx5g1axZefvllHDhwANu2bUNsbKwxd52IiIhqEaMGomvXrmHcuHFIT0+Hvb092rdvj7i4ODz77LO4cuUK9u3bh1WrVuHevXtwc3PDsGHDMHv2bOn1pqam2LlzJyZPngyNRgMbGxsEBQXpPbfIw8MDsbGxmD59OlavXo0mTZpg/fr1vOWeiIiIJEYNRJ9//nmZy9zc3HD48OHHrsPd3R27du0qt4+/vz9OnjxZ6fqIiIhIHmrdGCIiIiKimsZARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREsmfUQLRu3Tq0b98eKpUKKpUKGo0Gu3fvlpbn5OQgNDQUDRs2hK2tLYYNG4aMjAy9daSlpSEwMBDW1tZwdnbGzJkzUVBQoNfn0KFD6NixI5RKJVq0aIGYmJia2D0iIiKqI4waiJo0aYIlS5YgMTERJ06cQO/evTF48GAkJycDAKZPn44ffvgB27dvx+HDh3H16lUMHTpUen1hYSECAwORl5eHY8eOYePGjYiJicGcOXOkPqmpqQgMDESvXr2QlJSEadOmYcKECYiLi6vx/SUiIqLaSSGEEMYu4mGOjo744IMPMHz4cDRq1AhbtmzB8OHDAQDnzp2Dp6cnEhIS0LVrV+zevRsDBw7E1atX4eLiAgCIiorCW2+9hevXr8PCwgJvvfUWYmNj8ccff0jbGDlyJO7cuYM9e/ZUqKasrCzY29sjMzMTKpWqSvf3t99+g6+vL9RBq6BUtyi3b67uAnQbpyExMREdO3as0jqIiIjqm8r8/a41Y4gKCwuxdetW3Lt3DxqNBomJicjPz0ffvn2lPm3atEHTpk2RkJAAAEhISIC3t7cUhgBAq9UiKytLOsuUkJCgt47iPsXrICIiIjIzdgGnT5+GRqNBTk4ObG1t8e2338LLywtJSUmwsLCAg4ODXn8XFxfodDoAgE6n0wtDxcuLl5XXJysrCw8ePICVlVWJmnJzc5GbmyvNZ2Vl/ef9JCIiotrL6GeIWrdujaSkJPz888+YPHkygoKCcObMGaPWFBERAXt7e2lyc3Mzaj1ERERUvYweiCwsLNCiRQv4+voiIiICHTp0wOrVq6FWq5GXl4c7d+7o9c/IyIBarQYAqNXqEnedFc8/ro9KpSr17BAAhIeHIzMzU5quXLlSFbtKREREtZTRA9GjioqKkJubC19fX5ibm2P//v3SspSUFKSlpUGj0QAANBoNTp8+jWvXrkl94uPjoVKp4OXlJfV5eB3FfYrXURqlUik9CqB4IiIiovrLqGOIwsPDERAQgKZNm+Lu3bvYsmULDh06hLi4ONjb2yMkJARhYWFwdHSESqXC1KlTodFo0LVrVwBAv3794OXlhbFjx2LZsmXQ6XSYPXs2QkNDoVQqAQCTJk3Cxx9/jFmzZuHll1/GgQMHsG3bNsTGxhpz14mIiKgWMWogunbtGsaNG4f09HTY29ujffv2iIuLw7PPPgsAWLlyJUxMTDBs2DDk5uZCq9Vi7dq10utNTU2xc+dOTJ48GRqNBjY2NggKCsKCBQukPh4eHoiNjcX06dOxevVqNGnSBOvXr4dWq63x/SUiIqLaqdY9h6g24nOIiIiI6p46+RwiIiIiImNhICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItkzKBBdunSpqusgIiIiMhqDAlGLFi3Qq1cvbNq0CTk5OQZvPCIiAk8//TTs7Ozg7OyMIUOGICUlRa+Pv78/FAqF3jRp0iS9PmlpaQgMDIS1tTWcnZ0xc+ZMFBQU6PU5dOgQOnbsCKVSiRYtWiAmJsbguomIiKh+MSgQ/fbbb2jfvj3CwsKgVqvx6quv4pdffqn0eg4fPozQ0FAcP34c8fHxyM/PR79+/XDv3j29fq+88grS09OladmyZdKywsJCBAYGIi8vD8eOHcPGjRsRExODOXPmSH1SU1MRGBiIXr16ISkpCdOmTcOECRMQFxdnyO4TERFRPWNQIPLx8cHq1atx9epVbNiwAenp6ejevTvatWuHFStW4Pr16xVaz549exAcHIy2bduiQ4cOiImJQVpaGhITE/X6WVtbQ61WS5NKpZKW7d27F2fOnMGmTZvg4+ODgIAALFy4EJGRkcjLywMAREVFwcPDA8uXL4enpyemTJmC4cOHY+XKlYbsPhEREdUz/2lQtZmZGYYOHYrt27dj6dKluHDhAt588024ublh3LhxSE9Pr9T6MjMzAQCOjo567Zs3b4aTkxPatWuH8PBw3L9/X1qWkJAAb29vuLi4SG1arRZZWVlITk6W+vTt21dvnVqtFgkJCaXWkZubi6ysLL2JiIiI6q//FIhOnDiB1157Da6urlixYgXefPNNXLx4EfHx8bh69SoGDx5c4XUVFRVh2rRp6NatG9q1aye1jxo1Cps2bcLBgwcRHh6OL7/8EmPGjJGW63Q6vTAEQJrX6XTl9snKysKDBw9K1BIREQF7e3tpcnNzq/B+EBERUd1jZsiLVqxYgejoaKSkpGDAgAH44osvMGDAAJiY/JuvPDw8EBMTgyeffLLC6wwNDcUff/yBH3/8Ua994sSJ0v97e3vD1dUVffr0wcWLF9G8eXNDyn+s8PBwhIWFSfNZWVkMRURERPWYQYFo3bp1ePnllxEcHAxXV9dS+zg7O+Pzzz+v0PqmTJmCnTt34siRI2jSpEm5fbt06QIAuHDhApo3bw61Wl1iQHdGRgYAQK1WS/8tbnu4j0qlgpWVVYltKJVKKJXKCtVOREREdZ9Bgej8+fOP7WNhYYGgoKBy+wghMHXqVHz77bc4dOgQPDw8HrvepKQkAJCCmEajwfvvv49r167B2dkZABAfHw+VSgUvLy+pz65du/TWEx8fD41G89jtERERUf1n0Bii6OhobN++vUT79u3bsXHjxgqvJzQ0FJs2bcKWLVtgZ2cHnU4HnU4njeu5ePEiFi5ciMTERFy+fBnff/89xo0bhx49eqB9+/YAgH79+sHLywtjx47F77//jri4OMyePRuhoaHSWZ5Jkybh0qVLmDVrFs6dO4e1a9di27ZtmD59uiG7T0RERPWMQYEoIiICTk5OJdqdnZ2xePHiCq9n3bp1yMzMhL+/P1xdXaXp66+/BvDvWaZ9+/ahX79+aNOmDWbMmIFhw4bhhx9+kNZhamqKnTt3wtTUFBqNBmPGjMG4ceOwYMECqY+HhwdiY2MRHx+PDh06YPny5Vi/fj20Wq0hu09ERET1jEGXzNLS0kq9vOXu7o60tLQKr0cIUe5yNzc3HD58+LHrcXd3L3FJ7FH+/v44efJkhWsjIiIi+TDoDJGzszNOnTpVov33339Hw4YN/3NRRERERDXJoED00ksv4fXXX8fBgwdRWFiIwsJCHDhwAG+88QZGjhxZ1TUSERERVSuDLpktXLgQly9fRp8+fWBm9u8qioqKMG7cuEqNISIiIiKqDQwKRBYWFvj666+xcOFC/P7777CysoK3tzfc3d2ruj4iIiKiamdQICrWqlUrtGrVqqpqISIiIjIKgwJRYWEhYmJisH//fly7dg1FRUV6yw8cOFAlxRERERHVBIMC0RtvvIGYmBgEBgaiXbt2UCgUVV0XERERUY0xKBBt3boV27Ztw4ABA6q6HiIiIqIaZ9Bt9xYWFmjRokVV10JERERkFAYFohkzZmD16tWPfdI0ERERUV1g0CWzH3/8EQcPHsTu3bvRtm1bmJub6y3fsWNHlRRHREREVBMMCkQODg54/vnnq7oWIiIiIqMwKBBFR0dXdR1ERERERmPQGCIAKCgowL59+/DJJ5/g7t27AICrV68iOzu7yoojIiIiqgkGnSH666+/0L9/f6SlpSE3NxfPPvss7OzssHTpUuTm5iIqKqqq6yQiIiKqNgadIXrjjTfQqVMn3L59G1ZWVlL7888/j/3791dZcUREREQ1waAzREePHsWxY8dgYWGh1/7kk0/in3/+qZLCiIiIiGqKQWeIioqKUFhYWKL977//hp2d3X8uioiIiKgmGRSI+vXrh1WrVknzCoUC2dnZmDt3Lr/Og4iIiOocgy6ZLV++HFqtFl5eXsjJycGoUaNw/vx5ODk54auvvqrqGomIiIiqlUGBqEmTJvj999+xdetWnDp1CtnZ2QgJCcHo0aP1BlkTERER1QUGBSIAMDMzw5gxY6qyFiIiIiKjMCgQffHFF+UuHzdunEHFEBERERmDQYHojTfe0JvPz8/H/fv3YWFhAWtrawYiIiIiqlMMusvs9u3belN2djZSUlLQvXt3DqomIiKiOsfg7zJ7VMuWLbFkyZISZ4+IiIiIarsqC0TAvwOtr169WpWrJCIiIqp2Bo0h+v777/XmhRBIT0/Hxx9/jG7dulVJYUREREQ1xaBANGTIEL15hUKBRo0aoXfv3li+fHlV1EVERERUYwwKREVFRVVdBxEREZHRVOkYIiIiIqK6yKAzRGFhYRXuu2LFijKXRUREYMeOHTh37hysrKzwzDPPYOnSpWjdurXUJycnBzNmzMDWrVuRm5sLrVaLtWvXwsXFReqTlpaGyZMn4+DBg7C1tUVQUBAiIiJgZvb/d+/QoUMICwtDcnIy3NzcMHv2bAQHB1dux4mIiKheMigQnTx5EidPnkR+fr4UXv7880+YmpqiY8eOUj+FQlHueg4fPozQ0FA8/fTTKCgowDvvvIN+/frhzJkzsLGxAQBMnz4dsbGx2L59O+zt7TFlyhQMHToUP/30EwCgsLAQgYGBUKvVOHbsGNLT0zFu3DiYm5tj8eLFAIDU1FQEBgZi0qRJ2Lx5M/bv348JEybA1dUVWq3WkENARERE9YhBgWjQoEGws7PDxo0b0aBBAwD/Pqxx/Pjx8PPzw4wZMyq0nj179ujNx8TEwNnZGYmJiejRowcyMzPx+eefY8uWLejduzcAIDo6Gp6enjh+/Di6du2KvXv34syZM9i3bx9cXFzg4+ODhQsX4q233sK8efNgYWGBqKgoeHh4SAO+PT098eOPP2LlypUMRERERGTYGKLly5cjIiJCCkMA0KBBAyxatOg/3WWWmZkJAHB0dAQAJCYmIj8/H3379pX6tGnTBk2bNkVCQgIAICEhAd7e3nqX0LRaLbKyspCcnCz1eXgdxX2K10FERETyZtAZoqysLFy/fr1E+/Xr13H37l2DCikqKsK0adPQrVs3tGvXDgCg0+lgYWEBBwcHvb4uLi7Q6XRSn4fDUPHy4mXl9cnKysKDBw9gZWWltyw3Nxe5ubnSfFZWlkH7RERERHWDQWeInn/+eYwfPx47duzA33//jb///hv/+9//EBISgqFDhxpUSGhoKP744w9s3brVoNdXpYiICNjb20uTm5ubsUsiIiKiamRQIIqKikJAQABGjRoFd3d3uLu7Y9SoUejfvz/Wrl1b6fVNmTIFO3fuxMGDB9GkSROpXa1WIy8vD3fu3NHrn5GRAbVaLfXJyMgosbx4WXl9VCpVibNDABAeHo7MzExpunLlSqX3iYiIiOoOgwKRtbU11q5di5s3b0p3nN26dQtr166V7g6rCCEEpkyZgm+//RYHDhyAh4eH3nJfX1+Ym5tj//79UltKSgrS0tKg0WgAABqNBqdPn8a1a9ekPvHx8VCpVPDy8pL6PLyO4j7F63iUUqmESqXSm4iIiKj++k8PZkxPT0d6ejpatmwJGxsbCCEq9frQ0FBs2rQJW7ZsgZ2dHXQ6HXQ6HR48eAAAsLe3R0hICMLCwnDw4EEkJiZi/Pjx0Gg06Nq1KwCgX79+8PLywtixY/H7778jLi4Os2fPRmhoKJRKJQBg0qRJuHTpEmbNmoVz585h7dq12LZtG6ZPn/5fdp+IiIjqCYMC0c2bN9GnTx+0atUKAwYMQHp6OgAgJCSkwrfcA8C6deuQmZkJf39/uLq6StPXX38t9Vm5ciUGDhyIYcOGoUePHlCr1dixY4e03NTUFDt37oSpqSk0Gg3GjBmDcePGYcGCBVIfDw8PxMbGIj4+Hh06dMDy5cuxfv163nJPREREAAy8y2z69OkwNzdHWloaPD09pfYXX3wRYWFhFb71viJnlCwtLREZGYnIyMgy+7i7u2PXrl3lrsff3x8nT56sUF1EREQkLwYFor179yIuLk5vADQAtGzZEn/99VeVFEZERERUUwy6ZHbv3j1YW1uXaL9165Y0boeIiIiorjAoEPn5+eGLL76Q5hUKBYqKirBs2TL06tWryoojIiIiqgkGXTJbtmwZ+vTpgxMnTiAvLw+zZs1CcnIybt26JX3pKhEREVFdYdAZonbt2uHPP/9E9+7dMXjwYNy7dw9Dhw7FyZMn0bx586qukYiIiKhaVfoMUX5+Pvr374+oqCi8++671VETERERUY2q9Bkic3NznDp1qjpqISIiIjIKgy6ZjRkzBp9//nlV10JERERkFAYNqi4oKMCGDRuwb98++Pr6lvj+shUrVlRJcUREREQ1oVKB6NKlS3jyySfxxx9/oGPHjgCAP//8U6+PQqGouuqIiIiIakClAlHLli2Rnp6OgwcPAvj3qzo++ugjuLi4VEtxRERERDWhUmOIHv3usd27d+PevXtVWhARERFRTTNoUHWxinw5KxEREVFtV6lApFAoSowR4pghIiIiqusqNYZICIHg4GDpC1xzcnIwadKkEneZ7dixo+oqJCIiIqpmlQpEQUFBevNjxoyp0mKIiIiIjKFSgSg6Orq66iAiIiIymv80qJqIiIioPmAgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZM2ogOnLkCAYNGoTGjRtDoVDgu+++01seHBwMhUKhN/Xv31+vz61btzB69GioVCo4ODggJCQE2dnZen1OnToFPz8/WFpaws3NDcuWLavuXSMiIqI6xKiB6N69e+jQoQMiIyPL7NO/f3+kp6dL01dffaW3fPTo0UhOTkZ8fDx27tyJI0eOYOLEidLyrKws9OvXD+7u7khMTMQHH3yAefPm4dNPP622/SIiIqK6xcyYGw8ICEBAQEC5fZRKJdRqdanLzp49iz179uDXX39Fp06dAABr1qzBgAED8OGHH6Jx48bYvHkz8vLysGHDBlhYWKBt27ZISkrCihUr9IITERERyVetH0N06NAhODs7o3Xr1pg8eTJu3rwpLUtISICDg4MUhgCgb9++MDExwc8//yz16dGjBywsLKQ+Wq0WKSkpuH37dqnbzM3NRVZWlt5ERERE9VetDkT9+/fHF198gf3792Pp0qU4fPgwAgICUFhYCADQ6XRwdnbWe42ZmRkcHR2h0+mkPi4uLnp9iueL+zwqIiIC9vb20uTm5lbVu0ZERES1iFEvmT3OyJEjpf/39vZG+/bt0bx5cxw6dAh9+vSptu2Gh4cjLCxMms/KymIoIiIiqsdq9RmiRzVr1gxOTk64cOECAECtVuPatWt6fQoKCnDr1i1p3JFarUZGRoZen+L5ssYmKZVKqFQqvYmIiIjqrzoViP7++2/cvHkTrq6uAACNRoM7d+4gMTFR6nPgwAEUFRWhS5cuUp8jR44gPz9f6hMfH4/WrVujQYMGNbsDREREVCsZNRBlZ2cjKSkJSUlJAIDU1FQkJSUhLS0N2dnZmDlzJo4fP47Lly9j//79GDx4MFq0aAGtVgsA8PT0RP/+/fHKK6/gl19+wU8//YQpU6Zg5MiRaNy4MQBg1KhRsLCwQEhICJKTk/H1119j9erVepfEiIiISN6MGohOnDiBp556Ck899RQAICwsDE899RTmzJkDU1NTnDp1Cs899xxatWqFkJAQ+Pr64ujRo1AqldI6Nm/ejDZt2qBPnz4YMGAAunfvrveMIXt7e+zduxepqanw9fXFjBkzMGfOHN5yT0RERBKjDqr29/eHEKLM5XFxcY9dh6OjI7Zs2VJun/bt2+Po0aOVro+IiIjkoU6NISIiIiKqDgxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQke0YNREeOHMGgQYPQuHFjKBQKfPfdd3rLhRCYM2cOXF1dYWVlhb59++L8+fN6fW7duoXRo0dDpVLBwcEBISEhyM7O1utz6tQp+Pn5wdLSEm5ubli2bFl17xoRERHVIUYNRPfu3UOHDh0QGRlZ6vJly5bho48+QlRUFH7++WfY2NhAq9UiJydH6jN69GgkJycjPj4eO3fuxJEjRzBx4kRpeVZWFvr16wd3d3ckJibigw8+wLx58/Dpp59W+/4RERFR3WBmzI0HBAQgICCg1GVCCKxatQqzZ8/G4MGDAQBffPEFXFxc8N1332HkyJE4e/Ys9uzZg19//RWdOnUCAKxZswYDBgzAhx9+iMaNG2Pz5s3Iy8vDhg0bYGFhgbZt2yIpKQkrVqzQC05EREQkX7V2DFFqaip0Oh369u0rtdnb26NLly5ISEgAACQkJMDBwUEKQwDQt29fmJiY4Oeff5b69OjRAxYWFlIfrVaLlJQU3L59u4b2hoiIiGozo54hKo9OpwMAuLi46LW7uLhIy3Q6HZydnfWWm5mZwdHRUa+Ph4dHiXUUL2vQoEGJbefm5iI3N1eaz8rK+o97Q0RERLVZrT1DZEwRERGwt7eXJjc3N2OXRERERNWo1gYitVoNAMjIyNBrz8jIkJap1Wpcu3ZNb3lBQQFu3bql16e0dTy8jUeFh4cjMzNTmq5cufLfd4iIiIhqrVp7yczDwwNqtRr79++Hj48PgH8vXf3888+YPHkyAECj0eDOnTtITEyEr68vAODAgQMoKipCly5dpD7vvvsu8vPzYW5uDgCIj49H69atS71cBgBKpRJKpbKa95CIiKh+S0tLw40bNyrU18nJCU2bNq3mispm1ECUnZ2NCxcuSPOpqalISkqCo6MjmjZtimnTpmHRokVo2bIlPDw88N5776Fx48YYMmQIAMDT0xP9+/fHK6+8gqioKOTn52PKlCkYOXIkGjduDAAYNWoU5s+fj5CQELz11lv4448/sHr1aqxcudIYu0xERCQLaWlpaN3GEzkP7leov6WVNVLOnTVaKDJqIDpx4gR69eolzYeFhQEAgoKCEBMTg1mzZuHevXuYOHEi7ty5g+7du2PPnj2wtLSUXrN582ZMmTIFffr0gYmJCYYNG4aPPvpIWm5vb4+9e/ciNDQUvr6+cHJywpw5c3jLPRERUTW6ceMGch7cR8OBM2DesPyxuPk3r+DmzuW4ceOGPAORv78/hBBlLlcoFFiwYAEWLFhQZh9HR0ds2bKl3O20b98eR48eNbhOIiIiMox5Qzco1S2MXcZj1dpB1UREREQ1hYGIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkz8zYBRAREVHdkJaWhhs3blSo79mzZ6u5mqpVqwPRvHnzMH/+fL221q1b49y5cwCAnJwczJgxA1u3bkVubi60Wi3Wrl0LFxcXqX9aWhomT56MgwcPwtbWFkFBQYiIiICZWa3edSIiololLS0Nrdt4IufBfWOXUi1qfSpo27Yt9u3bJ80/HGSmT5+O2NhYbN++Hfb29pgyZQqGDh2Kn376CQBQWFiIwMBAqNVqHDt2DOnp6Rg3bhzMzc2xePHiGt8XIiKiuurGjRvIeXAfDQfOgHlDt8f2f3DpBDKPbqqByqpGrQ9EZmZmUKvVJdozMzPx+eefY8uWLejduzcAIDo6Gp6enjh+/Di6du2KvXv34syZM9i3bx9cXFzg4+ODhQsX4q233sK8efNgYWFR07tDRERUp5k3dINS3eKx/fJvXqmBaqpOrR9Uff78eTRu3BjNmjXD6NGjkZaWBgBITExEfn4++vbtK/Vt06YNmjZtioSEBABAQkICvL299S6habVaZGVlITk5ucxt5ubmIisrS28iIiKi+qtWB6IuXbogJiYGe/bswbp165Camgo/Pz/cvXsXOp0OFhYWcHBw0HuNi4sLdDodAECn0+mFoeLlxcvKEhERAXt7e2lyc3v8qUEiIiKqu2r1JbOAgADp/9u3b48uXbrA3d0d27Ztg5WVVbVtNzw8HGFhYdJ8VlYWQxEREVE9VqvPED3KwcEBrVq1woULF6BWq5GXl4c7d+7o9cnIyJDGHKnVamRkZJRYXrysLEqlEiqVSm8iIiKi+qtOBaLs7GxcvHgRrq6u8PX1hbm5Ofbv3y8tT0lJQVpaGjQaDQBAo9Hg9OnTuHbtmtQnPj4eKpUKXl5eNV4/ERER1U61+pLZm2++iUGDBsHd3R1Xr17F3LlzYWpqipdeegn29vYICQlBWFgYHB0doVKpMHXqVGg0GnTt2hUA0K9fP3h5eWHs2LFYtmwZdDodZs+ejdDQUCiVSiPvHREREdUWtToQ/f3333jppZdw8+ZNNGrUCN27d8fx48fRqFEjAMDKlSthYmKCYcOG6T2YsZipqSl27tyJyZMnQ6PRwMbGBkFBQViwYIGxdomIiIhqoVodiLZu3VrucktLS0RGRiIyMrLMPu7u7ti1a1dVl2ZUFX0cupOTE5o2bVrN1RAREdV9tToQkb7C7NuAQoExY8ZUqL+llTVSzp1lKCIiojJV9PvJ6tp3k1UWA1EdUpSbDQhRocem59+8gps7l+PGjRsMREREVKr6/v1klcFAVAdV9LHpRERE5anM95PVte8mqywGIiIionqmspfBKvIP7br23WSVxUBERERUj/AymGEYiIiIiOoRXgYzDAMRERFRPcTLYJVTp766g4iIiKg68AxRPVeZ50bwQY5ERCRXDET1VGUf4gjwQY5ERCRfDET1VGUe4gjwQY5ERLVZRW+jB+r/E6WrCwNRPceHOBIR1W28jb5mMBARERHVYpW5jR7grfSGYiAiIiKqAyp6xp+30huGgYiIiKiKVGasT25uLpRK5WP7cUxQzWAgIiIiqgKVHuujMAFEUfUWRRXGQERERFSOynxRamW/MoNfr1F7MBCRnoqemuVDHImorqrMZa309HQMG/4CcnMeVHj9lfnKDH69Ru3BQEQAKv8gR6XSEv/73zdwdXV9bF+GJyKqbhUNOYYEHAA8kyMDDEQEoHIPcsz5Oxl3DqzHwIEDK7RuPgGbiKqTIc/pqewt7DyTU/8xEJGeCv/QVzA88QnYRFTdKvOcnsoEHIAhR04YiMhglXkKNr9klogqqzKDmQGOx6H/hoGIqhW/ZJaIDMGvq6CaxkBE1YpfMktED6vOW9iJ/gsGIqoRlf2SWd7+T2Q81fG0ZaD6b2En+i8YiKhW4e3/RMZVE09b5lkfqo0YiKhWqc7b/xmeSM6M/bTlh/vzrA/VRgxEVCtV9e3/1RmeAAaoh1XmcgtQuWNXmXXXxfekuvbPkAHKVf205Yf7E9VGDERU5xk7PAGVC1CVGXNRXX2B6gkMhvzhrehdhZVdd3XerVgdY2wqO76mMp85DlAmejwGIpKVqg5PgAEBqjJjLqqrL6onxFXmDy9QubsKK/PwveL1Hj16FJ6eno+to1oHBlfyfamu0A5wgDJReRiIiMpQqcsAFQxQhnzDdXWM5ajWEIfquauwMg/fq/Tzr6p5YHBVP0G5sqGdZ32IHk9WgSgyMhIffPABdDodOnTogDVr1qBz587GLovqier6hutqG8tRjSGuogx5cGdFVGZwfk0MDK6uMzMcu0NUdWQTiL7++muEhYUhKioKXbp0wapVq6DVapGSkgJnZ2djl0dkFMb+o25IcKkMDgwmooqSTSBasWIFXnnlFYwfPx4AEBUVhdjYWGzYsAFvv/22kasjkjeObSEiYzMxdgE1IS8vD4mJiejbt6/UZmJigr59+yIhIcGIlREREVFtIIszRDdu3EBhYSFcXFz02l1cXHDu3LkS/XNzc5GbmyvNZ2ZmAgCysrKqvLbs7Ox/t6m7gKK8nHL7Fv8Luar7Vue662IdrFledbBmedXBmmtpHbf+BvDv38Sq/FtbvC4hxOM7Cxn4559/BABx7NgxvfaZM2eKzp07l+g/d+5cAYATJ06cOHHiVA+mK1euPDYryOIMkZOTE0xNTZGRkaHXnpGRAbVaXaJ/eHg4wsLCpPmioiLcunULDRs2hEKhqNLasrKy4ObmhitXrkClUlXpuun/43GuGTzONYPHuebwWNeM6jrOQgjcvXsXjRs3fmxfWQQiCwsL+Pr6Yv/+/RgyZAiAf0PO/v37MWXKlBL9lUpliYe0OTg4VGuNKpWKP2w1gMe5ZvA41wwe55rDY10zquM429vbV6ifLAIRAISFhSEoKAidOnVC586dsWrVKty7d0+664yIiIjkSzaB6MUXX8T169cxZ84c6HQ6+Pj4YM+ePSUGWhMREZH8yCYQAcCUKVNKvURmTEqlEnPnzq3Ul3JS5fE41wwe55rB41xzeKxrRm04zgohKnIvGhEREVH9JYsHMxIRERGVh4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GoBkRGRuLJJ5+EpaUlunTpgl9++aXc/tu3b0ebNm1gaWkJb29v7Nq1q4Yqrdsqc5w/++wz+Pn5oUGDBmjQoAH69u372PeF/lXZz3OxrVu3QqFQSA9HpfJV9jjfuXMHoaGhcHV1hVKpRKtWrfi7o4Iqe6xXrVqF1q1bw8rKCm5ubpg+fTpych7/3V5ydeTIEQwaNAiNGzeGQqHAd99999jXHDp0CB07doRSqUSLFi0QExNT7XXK4rvMjGnr1q3CwsJCbNiwQSQnJ4tXXnlFODg4iIyMjFL7//TTT8LU1FQsW7ZMnDlzRsyePVuYm5uL06dP13DldUtlj/OoUaNEZGSkOHnypDh79qwIDg4W9vb24u+//67hyuuWyh7nYqmpqeKJJ54Qfn5+YvDgwTVTbB1W2eOcm5srOnXqJAYMGCB+/PFHkZqaKg4dOiSSkpJquPK6p7LHevPmzUKpVIrNmzeL1NRUERcXJ1xdXcX06dNruPK6Y9euXeLdd98VO3bsEADEt99+W27/S5cuCWtraxEWFibOnDkj1qxZI0xNTcWePXuqtU4GomrWuXNnERoaKs0XFhaKxo0bi4iIiFL7jxgxQgQGBuq1denSRbz66qvVWmddV9nj/KiCggJhZ2cnNm7cWF0l1guGHOeCggLxzDPPiPXr14ugoCAGogqo7HFet26daNasmcjLy6upEuuNyh7r0NBQ0bt3b722sLAw0a1bt2qts76oSCCaNWuWaNu2rV7biy++KLRabTVWJgQvmVWjvLw8JCYmom/fvlKbiYkJ+vbti4SEhFJfk5CQoNcfALRabZn9ybDj/Kj79+8jPz8fjo6O1VVmnWfocV6wYAGcnZ0REhJSE2XWeYYc5++//x4ajQahoaFwcXFBu3btsHjxYhQWFtZU2XWSIcf6mWeeQWJionRZ7dKlS9i1axcGDBhQIzXLgbH+DsrqSdU17caNGygsLCzx9SAuLi44d+5cqa/R6XSl9tfpdNVWZ11nyHF+1FtvvYXGjRuX+CGk/8+Q4/zjjz/i888/R1JSUg1UWD8YcpwvXbqEAwcOYPTo0di1axcuXLiA1157Dfn5+Zg7d25NlF0nGXKsR40ahRs3bqB79+4QQqCgoACTJk3CO++8UxMly0JZfwezsrLw4MEDWFlZVct2eYaIZG/JkiXYunUrvv32W1haWhq7nHrj7t27GDt2LD777DM4OTkZu5x6raioCM7Ozvj000/h6+uLF198Ee+++y6ioqKMXVq9c+jQISxevBhr167Fb7/9hh07diA2NhYLFy40dmn0H/EMUTVycnKCqakpMjIy9NozMjKgVqtLfY1ara5UfzLsOBf78MMPsWTJEuzbtw/t27evzjLrvMoe54sXL+Ly5csYNGiQ1FZUVAQAMDMzQ0pKCpo3b169RddBhnyeXV1dYW5uDlNTU6nN09MTOp0OeXl5sLCwqNaa6ypDjvV7772HsWPHYsKECQAAb29v3Lt3DxMnTsS7774LExOeZ/ivyvo7qFKpqu3sEMAzRNXKwsICvr6+2L9/v9RWVFSE/fv3Q6PRlPoajUaj1x8A4uPjy+xPhh1nAFi2bBkWLlyIPXv2oFOnTjVRap1W2ePcpk0bnD59GklJSdL03HPPoVevXkhKSoKbm1tNll9nGPJ57tatGy5cuCAFTgD4888/4erqyjBUDkOO9f3790uEnuIgKvjVoFXCaH8Hq3XINomtW7cKpVIpYmJixJkzZ8TEiROFg4OD0Ol0Qgghxo4dK95++22p/08//STMzMzEhx9+KM6ePSvmzp3L2+4roLLHecmSJcLCwkJ88803Ij09XZru3r1rrF2oEyp7nB/Fu8wqprLHOS0tTdjZ2YkpU6aIlJQUsXPnTuHs7CwWLVpkrF2oMyp7rOfOnSvs7OzEV199JS5duiT27t0rmjdvLkaMGGGsXaj17t69K06ePClOnjwpAIgVK1aIkydPir/++ksIIcTbb78txo4dK/Uvvu1+5syZ4uzZsyIyMpK33dcXa9asEU2bNhUWFhaic+fO4vjx49Kynj17iqCgIL3+27ZtE61atRIWFhaibdu2IjY2toYrrpsqc5zd3d0FgBLT3Llza77wOqayn+eHMRBVXGWP87Fjx0SXLl2EUqkUzZo1E++//74oKCio4arrpsoc6/z8fDFv3jzRvHlzYWlpKdzc3MRrr70mbt++XfOF1xEHDx4s9fdt8XENCgoSPXv2LPEaHx8fYWFhIZo1ayaio6OrvU6FEDzHR0RERPLGMUREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxERCRb/v7+mDZtmrHLIKJagIGIiOqkQYMGoX///qUuO3r0KBQKBU6dOlXDVRFRXcVARER1UkhICOLj4/H333+XWBYdHY1OnTqhffv2RqiMiOoiBiIiqpMGDhyIRo0aISYmRq89Ozsb27dvx5AhQ/DSSy/hiSeegLW1Nby9vfHVV1+Vu06FQoHvvvtOr83BwUFvG1euXMGIESPg4OAAR0dHDB48GJcvX66anSIio2EgIqI6yczMDOPGjUNMTAwe/krG7du3o7CwEGPGjIGvry9iY2Pxxx9/YOLEiRg7dix++eUXg7eZn58PrVYLOzs7HD16FD/99BNsbW3Rv39/5OXlVcVuEZGRMBARUZ318ssv4+LFizh8+LDUFh0djWHDhsHd3R1vvvkmfHx80KxZM0ydOhX9+/fHtm3bDN7e119/jaKiIqxfvx7e3t7w9PREdHQ00tLScOjQoSrYIyIyFgYiIqqz2rRpg2eeeQYbNmwAAFy4cAFHjx5FSEgICgsLsXDhQnh7e8PR0RG2traIi4tDWlqawdv7/fffceHCBdjZ2cHW1ha2trZwdHRETk4OLl68WFW7RURGYGbsAoiI/ouQkBBMnToVkZGRiI6ORvPmzdGzZ08sXboUq1evxqpVq+Dt7Q0bGxtMmzat3EtbCoVC7/Ib8O9lsmLZ2dnw9fXF5s2bS7y2UaNGVbdTRFTjGIiIqE4bMWIE3njjDWzZsgVffPEFJk+eDIVCgZ9++gmDBw/GmDFjAABFRUX4888/4eXlVea6GjVqhPT0dGn+/PnzuH//vjTfsWNHfP3113B2doZKpaq+nSKiGsdLZkRUp9na2uLFF19EeHg40tPTERwcDABo2bIl4uPjcezYMZw9exavvvoqMjIyyl1X79698fHHH+PkyZM4ceIEJk2aBHNzc2n56NGj4eTkhMGDB+Po0aNITU3FoUOH8Prrr5d6+z8R1R0MRERU54WEhOD27dvQarVo3LgxAGD27Nno2LEjtFot/P39oVarMWTIkHLXs3z5cri5ucHPzw+jRo3Cm2++CWtra2m5tbU1jhw5gqZNm2Lo0KHw9PRESEgIcnJyeMaIqI5TiEcvmBMRERHJDM8QERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7P0/BPKLPhaCOGgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial dataset"
      ],
      "metadata": {
        "id": "NaFecMlwFu0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing\n",
        "filename_input = 'data_points_O.csv'\n",
        "filename_label = 'ao_rrt-12s-varyingGoal.csv'\n",
        "\n",
        "input = [] # 3542\n",
        "with open(filename_input, mode='r', newline='') as file:\n",
        "    reader = csv.reader(file)\n",
        "    headers = next(reader)\n",
        "    for row in reader:\n",
        "        input.append([float(r) for r in row])\n",
        "\n",
        "label = []\n",
        "with open(filename_label, mode='r', newline='') as file:\n",
        "    reader = csv.reader(file)\n",
        "    headers = next(reader)\n",
        "    for row in reader:\n",
        "        label.append([float(r) for r in row])\n",
        "\n",
        "noninf_idx = []\n",
        "cutoff_hres = 4.5\n",
        "for i,l in enumerate(label):\n",
        "    if l[4] != float('inf') and l[4] < cutoff_hres: noninf_idx.append(i)\n",
        "\n",
        "inputs = [input[i][1:] for i in noninf_idx] # 2802*10\n",
        "labels = [label[i][-1] for i in noninf_idx] # 2802"
      ],
      "metadata": {
        "id": "0PNdy2IeyMtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.asarray(inputs)\n",
        "labels = np.asarray(labels)\n",
        "print(inputs.shape)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSAH7MGczgHq",
        "outputId": "277fc087-b6a2-4c7d-be10-dfbd5bb61d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3044, 10)\n",
            "(3044,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create the histogram\n",
        "plt.hist(labels, bins=20, edgecolor='black')  # You can adjust the number of bins\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Float Numbers Between 0 and 5')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "JmRdpIH1W1BC",
        "outputId": "ff74eeea-1895-4193-f9e5-bc603c54a882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TENSORFLOW"
      ],
      "metadata": {
        "id": "8qeBv36fri5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X is your input data and y is your output data\n",
        "labels = [[s,m] for s,m in zip(success_labels, maneuver_labels)]\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Min-Max Scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
        "X_test_minmax = min_max_scaler.transform(X_test)\n",
        "joblib.dump(min_max_scaler, 'scaler_minmax.pkl')\n",
        "\n",
        "# Standardization\n",
        "standard_scaler = StandardScaler()\n",
        "X_train_standard = standard_scaler.fit_transform(X_train)\n",
        "X_test_standard = standard_scaler.transform(X_test)\n",
        "\n",
        "# # Normalize the data\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit(X_train)\n",
        "# X_test = scaler.transform(X_test[:2])"
      ],
      "metadata": {
        "id": "-yi4fyPzkg43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(min_max_scaler, 'scaler_minmax.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZnawUnZkGH5",
        "outputId": "f644e8d7-1e0b-4716-b768-9bf0420583cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler_minmax.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the scaler\n",
        "# scaler0 = joblib.load('my_scaler.pkl')\n",
        "\n",
        "# # Apply the scaler to new data\n",
        "# X_new_transformed = scaler0.transform(X_test[:2])\n",
        "# X_new_transformed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI9KS0OgkaWX",
        "outputId": "cb5472c6-f9a5-43c2-c363-40ec73d83228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.63852813, -0.50929621,  0.08382842, -0.13254498, -1.53643876,\n",
              "        -0.48864586,  0.00356794,  1.42156081,  0.02362815, -0.37003961],\n",
              "       [-1.4017682 , -0.41107987, -0.19069578,  0.03995952, -1.37368982,\n",
              "        -0.38683071,  0.00732365,  1.2256062 ,  0.1998657 ,  0.13719381]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGG6dugcxzEw",
        "outputId": "7a7012c2-aab9-4a4f-e4ad-e665be825fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "65/65 - 2s - loss: 0.8649 - val_loss: 0.5981 - 2s/epoch - 35ms/step\n",
            "Epoch 2/300\n",
            "65/65 - 0s - loss: 0.5417 - val_loss: 0.5303 - 294ms/epoch - 5ms/step\n",
            "Epoch 3/300\n",
            "65/65 - 0s - loss: 0.4823 - val_loss: 0.4703 - 255ms/epoch - 4ms/step\n",
            "Epoch 4/300\n",
            "65/65 - 0s - loss: 0.4376 - val_loss: 0.4331 - 250ms/epoch - 4ms/step\n",
            "Epoch 5/300\n",
            "65/65 - 0s - loss: 0.4111 - val_loss: 0.4090 - 262ms/epoch - 4ms/step\n",
            "Epoch 6/300\n",
            "65/65 - 0s - loss: 0.3882 - val_loss: 0.3820 - 247ms/epoch - 4ms/step\n",
            "Epoch 7/300\n",
            "65/65 - 0s - loss: 0.3647 - val_loss: 0.3586 - 251ms/epoch - 4ms/step\n",
            "Epoch 8/300\n",
            "65/65 - 0s - loss: 0.3376 - val_loss: 0.3466 - 261ms/epoch - 4ms/step\n",
            "Epoch 9/300\n",
            "65/65 - 0s - loss: 0.3149 - val_loss: 0.3181 - 306ms/epoch - 5ms/step\n",
            "Epoch 10/300\n",
            "65/65 - 0s - loss: 0.2921 - val_loss: 0.3065 - 258ms/epoch - 4ms/step\n",
            "Epoch 11/300\n",
            "65/65 - 0s - loss: 0.2702 - val_loss: 0.3079 - 365ms/epoch - 6ms/step\n",
            "Epoch 12/300\n",
            "65/65 - 0s - loss: 0.2528 - val_loss: 0.2541 - 377ms/epoch - 6ms/step\n",
            "Epoch 13/300\n",
            "65/65 - 0s - loss: 0.2378 - val_loss: 0.2461 - 397ms/epoch - 6ms/step\n",
            "Epoch 14/300\n",
            "65/65 - 0s - loss: 0.2206 - val_loss: 0.2379 - 388ms/epoch - 6ms/step\n",
            "Epoch 15/300\n",
            "65/65 - 0s - loss: 0.2079 - val_loss: 0.2212 - 424ms/epoch - 7ms/step\n",
            "Epoch 16/300\n",
            "65/65 - 0s - loss: 0.1967 - val_loss: 0.2304 - 421ms/epoch - 6ms/step\n",
            "Epoch 17/300\n",
            "65/65 - 0s - loss: 0.1879 - val_loss: 0.2054 - 373ms/epoch - 6ms/step\n",
            "Epoch 18/300\n",
            "65/65 - 0s - loss: 0.1802 - val_loss: 0.2107 - 369ms/epoch - 6ms/step\n",
            "Epoch 19/300\n",
            "65/65 - 0s - loss: 0.1786 - val_loss: 0.2091 - 418ms/epoch - 6ms/step\n",
            "Epoch 20/300\n",
            "65/65 - 0s - loss: 0.1737 - val_loss: 0.1832 - 284ms/epoch - 4ms/step\n",
            "Epoch 21/300\n",
            "65/65 - 0s - loss: 0.1654 - val_loss: 0.1985 - 257ms/epoch - 4ms/step\n",
            "Epoch 22/300\n",
            "65/65 - 0s - loss: 0.1587 - val_loss: 0.2069 - 256ms/epoch - 4ms/step\n",
            "Epoch 23/300\n",
            "65/65 - 0s - loss: 0.1539 - val_loss: 0.1742 - 254ms/epoch - 4ms/step\n",
            "Epoch 24/300\n",
            "65/65 - 0s - loss: 0.1479 - val_loss: 0.1726 - 258ms/epoch - 4ms/step\n",
            "Epoch 25/300\n",
            "65/65 - 0s - loss: 0.1473 - val_loss: 0.1896 - 247ms/epoch - 4ms/step\n",
            "Epoch 26/300\n",
            "65/65 - 0s - loss: 0.1412 - val_loss: 0.1852 - 247ms/epoch - 4ms/step\n",
            "Epoch 27/300\n",
            "65/65 - 0s - loss: 0.1378 - val_loss: 0.2029 - 287ms/epoch - 4ms/step\n",
            "Epoch 28/300\n",
            "65/65 - 0s - loss: 0.1360 - val_loss: 0.1785 - 304ms/epoch - 5ms/step\n",
            "Epoch 29/300\n",
            "65/65 - 0s - loss: 0.1337 - val_loss: 0.1562 - 262ms/epoch - 4ms/step\n",
            "Epoch 30/300\n",
            "65/65 - 0s - loss: 0.1319 - val_loss: 0.1718 - 251ms/epoch - 4ms/step\n",
            "Epoch 31/300\n",
            "65/65 - 0s - loss: 0.1250 - val_loss: 0.1688 - 266ms/epoch - 4ms/step\n",
            "Epoch 32/300\n",
            "65/65 - 0s - loss: 0.1220 - val_loss: 0.1624 - 256ms/epoch - 4ms/step\n",
            "Epoch 33/300\n",
            "65/65 - 0s - loss: 0.1277 - val_loss: 0.2058 - 259ms/epoch - 4ms/step\n",
            "Epoch 34/300\n",
            "65/65 - 0s - loss: 0.1255 - val_loss: 0.1559 - 272ms/epoch - 4ms/step\n",
            "Epoch 35/300\n",
            "65/65 - 0s - loss: 0.1192 - val_loss: 0.1464 - 323ms/epoch - 5ms/step\n",
            "Epoch 36/300\n",
            "65/65 - 0s - loss: 0.1210 - val_loss: 0.1522 - 303ms/epoch - 5ms/step\n",
            "Epoch 37/300\n",
            "65/65 - 0s - loss: 0.1148 - val_loss: 0.1477 - 264ms/epoch - 4ms/step\n",
            "Epoch 38/300\n",
            "65/65 - 0s - loss: 0.1116 - val_loss: 0.1493 - 270ms/epoch - 4ms/step\n",
            "Epoch 39/300\n",
            "65/65 - 0s - loss: 0.1149 - val_loss: 0.1510 - 314ms/epoch - 5ms/step\n",
            "Epoch 40/300\n",
            "65/65 - 0s - loss: 0.1119 - val_loss: 0.1526 - 248ms/epoch - 4ms/step\n",
            "Epoch 41/300\n",
            "65/65 - 0s - loss: 0.1060 - val_loss: 0.1445 - 291ms/epoch - 4ms/step\n",
            "Epoch 42/300\n",
            "65/65 - 0s - loss: 0.1107 - val_loss: 0.1482 - 281ms/epoch - 4ms/step\n",
            "Epoch 43/300\n",
            "65/65 - 0s - loss: 0.1043 - val_loss: 0.1501 - 260ms/epoch - 4ms/step\n",
            "Epoch 44/300\n",
            "65/65 - 0s - loss: 0.1035 - val_loss: 0.1382 - 255ms/epoch - 4ms/step\n",
            "Epoch 45/300\n",
            "65/65 - 0s - loss: 0.0980 - val_loss: 0.1353 - 295ms/epoch - 5ms/step\n",
            "Epoch 46/300\n",
            "65/65 - 0s - loss: 0.0982 - val_loss: 0.1744 - 301ms/epoch - 5ms/step\n",
            "Epoch 47/300\n",
            "65/65 - 0s - loss: 0.0977 - val_loss: 0.1501 - 247ms/epoch - 4ms/step\n",
            "Epoch 48/300\n",
            "65/65 - 0s - loss: 0.0974 - val_loss: 0.1497 - 295ms/epoch - 5ms/step\n",
            "Epoch 49/300\n",
            "65/65 - 0s - loss: 0.0938 - val_loss: 0.1805 - 270ms/epoch - 4ms/step\n",
            "Epoch 50/300\n",
            "65/65 - 0s - loss: 0.0986 - val_loss: 0.1592 - 258ms/epoch - 4ms/step\n",
            "Epoch 51/300\n",
            "65/65 - 0s - loss: 0.0918 - val_loss: 0.1361 - 277ms/epoch - 4ms/step\n",
            "Epoch 52/300\n",
            "65/65 - 0s - loss: 0.0895 - val_loss: 0.1317 - 300ms/epoch - 5ms/step\n",
            "Epoch 53/300\n",
            "65/65 - 0s - loss: 0.0951 - val_loss: 0.1417 - 264ms/epoch - 4ms/step\n",
            "Epoch 54/300\n",
            "65/65 - 0s - loss: 0.0923 - val_loss: 0.1400 - 252ms/epoch - 4ms/step\n",
            "Epoch 55/300\n",
            "65/65 - 0s - loss: 0.0873 - val_loss: 0.1426 - 254ms/epoch - 4ms/step\n",
            "Epoch 56/300\n",
            "65/65 - 0s - loss: 0.0900 - val_loss: 0.1407 - 374ms/epoch - 6ms/step\n",
            "Epoch 57/300\n",
            "65/65 - 0s - loss: 0.0843 - val_loss: 0.1365 - 414ms/epoch - 6ms/step\n",
            "Epoch 58/300\n",
            "65/65 - 0s - loss: 0.0851 - val_loss: 0.1262 - 391ms/epoch - 6ms/step\n",
            "Epoch 59/300\n",
            "65/65 - 0s - loss: 0.0804 - val_loss: 0.1342 - 363ms/epoch - 6ms/step\n",
            "Epoch 60/300\n",
            "65/65 - 0s - loss: 0.0852 - val_loss: 0.1474 - 388ms/epoch - 6ms/step\n",
            "Epoch 61/300\n",
            "65/65 - 0s - loss: 0.0811 - val_loss: 0.1391 - 367ms/epoch - 6ms/step\n",
            "Epoch 62/300\n",
            "65/65 - 0s - loss: 0.0786 - val_loss: 0.1302 - 396ms/epoch - 6ms/step\n",
            "Epoch 63/300\n",
            "65/65 - 0s - loss: 0.0810 - val_loss: 0.1505 - 383ms/epoch - 6ms/step\n",
            "Epoch 64/300\n",
            "65/65 - 0s - loss: 0.0807 - val_loss: 0.1371 - 388ms/epoch - 6ms/step\n",
            "Epoch 65/300\n",
            "65/65 - 0s - loss: 0.0773 - val_loss: 0.1339 - 312ms/epoch - 5ms/step\n",
            "Epoch 66/300\n",
            "65/65 - 0s - loss: 0.0775 - val_loss: 0.1238 - 259ms/epoch - 4ms/step\n",
            "Epoch 67/300\n",
            "65/65 - 0s - loss: 0.0777 - val_loss: 0.1539 - 277ms/epoch - 4ms/step\n",
            "Epoch 68/300\n",
            "65/65 - 0s - loss: 0.0827 - val_loss: 0.1303 - 255ms/epoch - 4ms/step\n",
            "Epoch 69/300\n",
            "65/65 - 0s - loss: 0.0741 - val_loss: 0.1339 - 283ms/epoch - 4ms/step\n",
            "Epoch 70/300\n",
            "65/65 - 0s - loss: 0.0745 - val_loss: 0.1576 - 239ms/epoch - 4ms/step\n",
            "Epoch 71/300\n",
            "65/65 - 0s - loss: 0.0779 - val_loss: 0.1333 - 280ms/epoch - 4ms/step\n",
            "Epoch 72/300\n",
            "65/65 - 0s - loss: 0.0750 - val_loss: 0.1441 - 255ms/epoch - 4ms/step\n",
            "Epoch 73/300\n",
            "65/65 - 0s - loss: 0.0736 - val_loss: 0.1359 - 251ms/epoch - 4ms/step\n",
            "Epoch 74/300\n",
            "65/65 - 0s - loss: 0.0683 - val_loss: 0.1484 - 290ms/epoch - 4ms/step\n",
            "Epoch 75/300\n",
            "65/65 - 0s - loss: 0.0695 - val_loss: 0.1323 - 246ms/epoch - 4ms/step\n",
            "Epoch 76/300\n",
            "65/65 - 0s - loss: 0.0673 - val_loss: 0.1255 - 256ms/epoch - 4ms/step\n",
            "Epoch 77/300\n",
            "65/65 - 0s - loss: 0.0662 - val_loss: 0.1475 - 250ms/epoch - 4ms/step\n",
            "Epoch 78/300\n",
            "65/65 - 0s - loss: 0.0648 - val_loss: 0.1268 - 246ms/epoch - 4ms/step\n",
            "Epoch 79/300\n",
            "65/65 - 0s - loss: 0.0688 - val_loss: 0.1226 - 267ms/epoch - 4ms/step\n",
            "Epoch 80/300\n",
            "65/65 - 0s - loss: 0.0655 - val_loss: 0.1256 - 256ms/epoch - 4ms/step\n",
            "Epoch 81/300\n",
            "65/65 - 0s - loss: 0.0661 - val_loss: 0.1260 - 284ms/epoch - 4ms/step\n",
            "Epoch 82/300\n",
            "65/65 - 0s - loss: 0.0622 - val_loss: 0.1318 - 288ms/epoch - 4ms/step\n",
            "Epoch 83/300\n",
            "65/65 - 0s - loss: 0.0709 - val_loss: 0.1313 - 286ms/epoch - 4ms/step\n",
            "Epoch 84/300\n",
            "65/65 - 0s - loss: 0.0648 - val_loss: 0.1188 - 285ms/epoch - 4ms/step\n",
            "Epoch 85/300\n",
            "65/65 - 0s - loss: 0.0640 - val_loss: 0.1352 - 269ms/epoch - 4ms/step\n",
            "Epoch 86/300\n",
            "65/65 - 0s - loss: 0.0622 - val_loss: 0.1245 - 292ms/epoch - 4ms/step\n",
            "Epoch 87/300\n",
            "65/65 - 0s - loss: 0.0658 - val_loss: 0.1255 - 254ms/epoch - 4ms/step\n",
            "Epoch 88/300\n",
            "65/65 - 0s - loss: 0.0612 - val_loss: 0.1272 - 267ms/epoch - 4ms/step\n",
            "Epoch 89/300\n",
            "65/65 - 0s - loss: 0.0633 - val_loss: 0.1544 - 262ms/epoch - 4ms/step\n",
            "Epoch 90/300\n",
            "65/65 - 0s - loss: 0.0587 - val_loss: 0.1278 - 261ms/epoch - 4ms/step\n",
            "Epoch 91/300\n",
            "65/65 - 0s - loss: 0.0623 - val_loss: 0.1312 - 257ms/epoch - 4ms/step\n",
            "Epoch 92/300\n",
            "65/65 - 0s - loss: 0.0595 - val_loss: 0.1279 - 256ms/epoch - 4ms/step\n",
            "Epoch 93/300\n",
            "65/65 - 0s - loss: 0.0597 - val_loss: 0.1400 - 261ms/epoch - 4ms/step\n",
            "Epoch 94/300\n",
            "65/65 - 0s - loss: 0.0616 - val_loss: 0.1231 - 257ms/epoch - 4ms/step\n",
            "Epoch 95/300\n",
            "65/65 - 0s - loss: 0.0568 - val_loss: 0.1226 - 303ms/epoch - 5ms/step\n",
            "Epoch 96/300\n",
            "65/65 - 0s - loss: 0.0579 - val_loss: 0.1183 - 269ms/epoch - 4ms/step\n",
            "Epoch 97/300\n",
            "65/65 - 0s - loss: 0.0598 - val_loss: 0.1263 - 291ms/epoch - 4ms/step\n",
            "Epoch 98/300\n",
            "65/65 - 0s - loss: 0.0549 - val_loss: 0.1302 - 304ms/epoch - 5ms/step\n",
            "Epoch 99/300\n",
            "65/65 - 0s - loss: 0.0543 - val_loss: 0.1313 - 258ms/epoch - 4ms/step\n",
            "Epoch 100/300\n",
            "65/65 - 0s - loss: 0.0524 - val_loss: 0.1312 - 262ms/epoch - 4ms/step\n",
            "Epoch 101/300\n",
            "65/65 - 0s - loss: 0.0520 - val_loss: 0.1678 - 265ms/epoch - 4ms/step\n",
            "Epoch 102/300\n",
            "65/65 - 0s - loss: 0.0641 - val_loss: 0.1358 - 432ms/epoch - 7ms/step\n",
            "Epoch 103/300\n",
            "65/65 - 0s - loss: 0.0515 - val_loss: 0.1257 - 418ms/epoch - 6ms/step\n",
            "Epoch 104/300\n",
            "65/65 - 0s - loss: 0.0530 - val_loss: 0.1276 - 370ms/epoch - 6ms/step\n",
            "Epoch 105/300\n",
            "65/65 - 0s - loss: 0.0520 - val_loss: 0.1202 - 365ms/epoch - 6ms/step\n",
            "Epoch 106/300\n",
            "65/65 - 0s - loss: 0.0517 - val_loss: 0.1307 - 396ms/epoch - 6ms/step\n",
            "Epoch 107/300\n",
            "65/65 - 0s - loss: 0.0488 - val_loss: 0.1290 - 410ms/epoch - 6ms/step\n",
            "Epoch 108/300\n",
            "65/65 - 0s - loss: 0.0506 - val_loss: 0.1236 - 375ms/epoch - 6ms/step\n",
            "Epoch 109/300\n",
            "65/65 - 0s - loss: 0.0507 - val_loss: 0.1301 - 389ms/epoch - 6ms/step\n",
            "Epoch 110/300\n",
            "65/65 - 0s - loss: 0.0479 - val_loss: 0.1249 - 397ms/epoch - 6ms/step\n",
            "Epoch 111/300\n",
            "65/65 - 0s - loss: 0.0535 - val_loss: 0.1242 - 239ms/epoch - 4ms/step\n",
            "Epoch 112/300\n",
            "65/65 - 0s - loss: 0.0527 - val_loss: 0.1207 - 240ms/epoch - 4ms/step\n",
            "Epoch 113/300\n",
            "65/65 - 0s - loss: 0.0453 - val_loss: 0.1224 - 253ms/epoch - 4ms/step\n",
            "Epoch 114/300\n",
            "65/65 - 0s - loss: 0.0503 - val_loss: 0.1212 - 250ms/epoch - 4ms/step\n",
            "Epoch 115/300\n",
            "65/65 - 0s - loss: 0.0503 - val_loss: 0.1219 - 281ms/epoch - 4ms/step\n",
            "Epoch 116/300\n",
            "65/65 - 0s - loss: 0.0497 - val_loss: 0.1149 - 246ms/epoch - 4ms/step\n",
            "Epoch 117/300\n",
            "65/65 - 0s - loss: 0.0440 - val_loss: 0.1183 - 290ms/epoch - 4ms/step\n",
            "Epoch 118/300\n",
            "65/65 - 0s - loss: 0.0487 - val_loss: 0.1121 - 280ms/epoch - 4ms/step\n",
            "Epoch 119/300\n",
            "65/65 - 0s - loss: 0.0444 - val_loss: 0.1122 - 248ms/epoch - 4ms/step\n",
            "Epoch 120/300\n",
            "65/65 - 0s - loss: 0.0434 - val_loss: 0.1331 - 244ms/epoch - 4ms/step\n",
            "Epoch 121/300\n",
            "65/65 - 0s - loss: 0.0474 - val_loss: 0.1171 - 296ms/epoch - 5ms/step\n",
            "Epoch 122/300\n",
            "65/65 - 0s - loss: 0.0438 - val_loss: 0.1189 - 287ms/epoch - 4ms/step\n",
            "Epoch 123/300\n",
            "65/65 - 0s - loss: 0.0448 - val_loss: 0.1305 - 251ms/epoch - 4ms/step\n",
            "Epoch 124/300\n",
            "65/65 - 0s - loss: 0.0438 - val_loss: 0.1120 - 254ms/epoch - 4ms/step\n",
            "Epoch 125/300\n",
            "65/65 - 0s - loss: 0.0506 - val_loss: 0.1168 - 250ms/epoch - 4ms/step\n",
            "Epoch 126/300\n",
            "65/65 - 0s - loss: 0.0489 - val_loss: 0.1255 - 287ms/epoch - 4ms/step\n",
            "Epoch 127/300\n",
            "65/65 - 0s - loss: 0.0404 - val_loss: 0.1463 - 246ms/epoch - 4ms/step\n",
            "Epoch 128/300\n",
            "65/65 - 0s - loss: 0.0473 - val_loss: 0.1156 - 254ms/epoch - 4ms/step\n",
            "Epoch 129/300\n",
            "65/65 - 0s - loss: 0.0434 - val_loss: 0.1290 - 259ms/epoch - 4ms/step\n",
            "Epoch 130/300\n",
            "65/65 - 0s - loss: 0.0409 - val_loss: 0.1214 - 286ms/epoch - 4ms/step\n",
            "Epoch 131/300\n",
            "65/65 - 0s - loss: 0.0382 - val_loss: 0.1157 - 253ms/epoch - 4ms/step\n",
            "Epoch 132/300\n",
            "65/65 - 0s - loss: 0.0383 - val_loss: 0.1258 - 261ms/epoch - 4ms/step\n",
            "Epoch 133/300\n",
            "65/65 - 0s - loss: 0.0404 - val_loss: 0.1218 - 295ms/epoch - 5ms/step\n",
            "Epoch 134/300\n",
            "65/65 - 0s - loss: 0.0475 - val_loss: 0.1191 - 251ms/epoch - 4ms/step\n",
            "Epoch 135/300\n",
            "65/65 - 0s - loss: 0.0399 - val_loss: 0.1175 - 246ms/epoch - 4ms/step\n",
            "Epoch 136/300\n",
            "65/65 - 0s - loss: 0.0406 - val_loss: 0.1221 - 256ms/epoch - 4ms/step\n",
            "Epoch 137/300\n",
            "65/65 - 0s - loss: 0.0403 - val_loss: 0.1140 - 271ms/epoch - 4ms/step\n",
            "Epoch 138/300\n",
            "65/65 - 0s - loss: 0.0391 - val_loss: 0.1175 - 265ms/epoch - 4ms/step\n",
            "Epoch 139/300\n",
            "65/65 - 0s - loss: 0.0425 - val_loss: 0.1290 - 256ms/epoch - 4ms/step\n",
            "Epoch 140/300\n",
            "65/65 - 0s - loss: 0.0401 - val_loss: 0.1187 - 275ms/epoch - 4ms/step\n",
            "Epoch 141/300\n",
            "65/65 - 0s - loss: 0.0390 - val_loss: 0.1143 - 253ms/epoch - 4ms/step\n",
            "Epoch 142/300\n",
            "65/65 - 0s - loss: 0.0375 - val_loss: 0.1168 - 246ms/epoch - 4ms/step\n",
            "Epoch 143/300\n",
            "65/65 - 0s - loss: 0.0404 - val_loss: 0.1365 - 250ms/epoch - 4ms/step\n",
            "Epoch 144/300\n",
            "65/65 - 0s - loss: 0.0419 - val_loss: 0.1215 - 259ms/epoch - 4ms/step\n",
            "Epoch 145/300\n",
            "65/65 - 0s - loss: 0.0382 - val_loss: 0.1255 - 290ms/epoch - 4ms/step\n",
            "Epoch 146/300\n",
            "65/65 - 0s - loss: 0.0369 - val_loss: 0.1229 - 247ms/epoch - 4ms/step\n",
            "Epoch 147/300\n",
            "65/65 - 0s - loss: 0.0399 - val_loss: 0.1166 - 255ms/epoch - 4ms/step\n",
            "Epoch 148/300\n",
            "65/65 - 0s - loss: 0.0396 - val_loss: 0.1263 - 361ms/epoch - 6ms/step\n",
            "Epoch 149/300\n",
            "65/65 - 0s - loss: 0.0429 - val_loss: 0.1275 - 393ms/epoch - 6ms/step\n",
            "Epoch 150/300\n",
            "65/65 - 0s - loss: 0.0397 - val_loss: 0.1193 - 366ms/epoch - 6ms/step\n",
            "Epoch 151/300\n",
            "65/65 - 0s - loss: 0.0385 - val_loss: 0.1160 - 349ms/epoch - 5ms/step\n",
            "Epoch 152/300\n",
            "65/65 - 0s - loss: 0.0352 - val_loss: 0.1160 - 378ms/epoch - 6ms/step\n",
            "Epoch 153/300\n",
            "65/65 - 0s - loss: 0.0341 - val_loss: 0.1166 - 401ms/epoch - 6ms/step\n",
            "Epoch 154/300\n",
            "65/65 - 0s - loss: 0.0339 - val_loss: 0.1165 - 385ms/epoch - 6ms/step\n",
            "Epoch 155/300\n",
            "65/65 - 0s - loss: 0.0393 - val_loss: 0.1202 - 367ms/epoch - 6ms/step\n",
            "Epoch 156/300\n",
            "65/65 - 0s - loss: 0.0366 - val_loss: 0.1225 - 382ms/epoch - 6ms/step\n",
            "Epoch 157/300\n",
            "65/65 - 0s - loss: 0.0375 - val_loss: 0.1121 - 331ms/epoch - 5ms/step\n",
            "Epoch 158/300\n",
            "65/65 - 0s - loss: 0.0344 - val_loss: 0.1140 - 251ms/epoch - 4ms/step\n",
            "Epoch 159/300\n",
            "65/65 - 0s - loss: 0.0346 - val_loss: 0.1384 - 299ms/epoch - 5ms/step\n",
            "Epoch 160/300\n",
            "65/65 - 0s - loss: 0.0368 - val_loss: 0.1074 - 242ms/epoch - 4ms/step\n",
            "Epoch 161/300\n",
            "65/65 - 0s - loss: 0.0336 - val_loss: 0.1129 - 243ms/epoch - 4ms/step\n",
            "Epoch 162/300\n",
            "65/65 - 0s - loss: 0.0380 - val_loss: 0.1329 - 255ms/epoch - 4ms/step\n",
            "Epoch 163/300\n",
            "65/65 - 0s - loss: 0.0414 - val_loss: 0.1329 - 296ms/epoch - 5ms/step\n",
            "Epoch 164/300\n",
            "65/65 - 0s - loss: 0.0422 - val_loss: 0.1213 - 249ms/epoch - 4ms/step\n",
            "Epoch 165/300\n",
            "65/65 - 0s - loss: 0.0325 - val_loss: 0.1196 - 243ms/epoch - 4ms/step\n",
            "Epoch 166/300\n",
            "65/65 - 0s - loss: 0.0316 - val_loss: 0.1151 - 247ms/epoch - 4ms/step\n",
            "Epoch 167/300\n",
            "65/65 - 0s - loss: 0.0347 - val_loss: 0.1156 - 261ms/epoch - 4ms/step\n",
            "Epoch 168/300\n",
            "65/65 - 0s - loss: 0.0332 - val_loss: 0.1176 - 277ms/epoch - 4ms/step\n",
            "Epoch 169/300\n",
            "65/65 - 0s - loss: 0.0319 - val_loss: 0.1159 - 252ms/epoch - 4ms/step\n",
            "Epoch 170/300\n",
            "65/65 - 0s - loss: 0.0312 - val_loss: 0.1344 - 300ms/epoch - 5ms/step\n",
            "Epoch 171/300\n",
            "65/65 - 0s - loss: 0.0413 - val_loss: 0.1142 - 284ms/epoch - 4ms/step\n",
            "Epoch 172/300\n",
            "65/65 - 0s - loss: 0.0355 - val_loss: 0.1174 - 250ms/epoch - 4ms/step\n",
            "Epoch 173/300\n",
            "65/65 - 0s - loss: 0.0302 - val_loss: 0.1153 - 282ms/epoch - 4ms/step\n",
            "Epoch 174/300\n",
            "65/65 - 0s - loss: 0.0301 - val_loss: 0.1108 - 264ms/epoch - 4ms/step\n",
            "Epoch 175/300\n",
            "65/65 - 0s - loss: 0.0326 - val_loss: 0.1126 - 246ms/epoch - 4ms/step\n",
            "Epoch 176/300\n",
            "65/65 - 0s - loss: 0.0341 - val_loss: 0.1180 - 241ms/epoch - 4ms/step\n",
            "Epoch 177/300\n",
            "65/65 - 0s - loss: 0.0363 - val_loss: 0.1332 - 281ms/epoch - 4ms/step\n",
            "Epoch 178/300\n",
            "65/65 - 0s - loss: 0.0327 - val_loss: 0.1357 - 271ms/epoch - 4ms/step\n",
            "Epoch 179/300\n",
            "65/65 - 0s - loss: 0.0332 - val_loss: 0.1174 - 247ms/epoch - 4ms/step\n",
            "Epoch 180/300\n",
            "65/65 - 0s - loss: 0.0317 - val_loss: 0.1240 - 252ms/epoch - 4ms/step\n",
            "Epoch 181/300\n",
            "65/65 - 0s - loss: 0.0303 - val_loss: 0.1151 - 296ms/epoch - 5ms/step\n",
            "Epoch 182/300\n",
            "65/65 - 0s - loss: 0.0339 - val_loss: 0.1118 - 265ms/epoch - 4ms/step\n",
            "Epoch 183/300\n",
            "65/65 - 0s - loss: 0.0330 - val_loss: 0.1160 - 291ms/epoch - 4ms/step\n",
            "Epoch 184/300\n",
            "65/65 - 0s - loss: 0.0310 - val_loss: 0.1137 - 257ms/epoch - 4ms/step\n",
            "Epoch 185/300\n",
            "65/65 - 0s - loss: 0.0301 - val_loss: 0.1062 - 261ms/epoch - 4ms/step\n",
            "Epoch 186/300\n",
            "65/65 - 0s - loss: 0.0312 - val_loss: 0.1071 - 245ms/epoch - 4ms/step\n",
            "Epoch 187/300\n",
            "65/65 - 0s - loss: 0.0304 - val_loss: 0.1136 - 245ms/epoch - 4ms/step\n",
            "Epoch 188/300\n",
            "65/65 - 0s - loss: 0.0294 - val_loss: 0.1189 - 255ms/epoch - 4ms/step\n",
            "Epoch 189/300\n",
            "65/65 - 0s - loss: 0.0307 - val_loss: 0.1058 - 260ms/epoch - 4ms/step\n",
            "Epoch 190/300\n",
            "65/65 - 0s - loss: 0.0324 - val_loss: 0.1165 - 251ms/epoch - 4ms/step\n",
            "Epoch 191/300\n",
            "65/65 - 0s - loss: 0.0289 - val_loss: 0.1143 - 245ms/epoch - 4ms/step\n",
            "Epoch 192/300\n",
            "65/65 - 0s - loss: 0.0291 - val_loss: 0.1158 - 274ms/epoch - 4ms/step\n",
            "Epoch 193/300\n",
            "65/65 - 0s - loss: 0.0307 - val_loss: 0.1124 - 264ms/epoch - 4ms/step\n",
            "Epoch 194/300\n",
            "65/65 - 0s - loss: 0.0305 - val_loss: 0.1083 - 254ms/epoch - 4ms/step\n",
            "Epoch 195/300\n",
            "65/65 - 0s - loss: 0.0286 - val_loss: 0.1089 - 396ms/epoch - 6ms/step\n",
            "Epoch 196/300\n",
            "65/65 - 0s - loss: 0.0272 - val_loss: 0.1083 - 411ms/epoch - 6ms/step\n",
            "Epoch 197/300\n",
            "65/65 - 0s - loss: 0.0274 - val_loss: 0.1112 - 364ms/epoch - 6ms/step\n",
            "Epoch 198/300\n",
            "65/65 - 0s - loss: 0.0291 - val_loss: 0.1234 - 362ms/epoch - 6ms/step\n",
            "Epoch 199/300\n",
            "65/65 - 0s - loss: 0.0312 - val_loss: 0.1045 - 380ms/epoch - 6ms/step\n",
            "Epoch 200/300\n",
            "65/65 - 0s - loss: 0.0360 - val_loss: 0.1136 - 448ms/epoch - 7ms/step\n",
            "Epoch 201/300\n",
            "65/65 - 0s - loss: 0.0286 - val_loss: 0.1015 - 440ms/epoch - 7ms/step\n",
            "Epoch 202/300\n",
            "65/65 - 0s - loss: 0.0274 - val_loss: 0.1219 - 375ms/epoch - 6ms/step\n",
            "Epoch 203/300\n",
            "65/65 - 0s - loss: 0.0293 - val_loss: 0.1076 - 430ms/epoch - 7ms/step\n",
            "Epoch 204/300\n",
            "65/65 - 0s - loss: 0.0270 - val_loss: 0.1103 - 349ms/epoch - 5ms/step\n",
            "Epoch 205/300\n",
            "65/65 - 0s - loss: 0.0291 - val_loss: 0.1134 - 288ms/epoch - 4ms/step\n",
            "Epoch 206/300\n",
            "65/65 - 0s - loss: 0.0367 - val_loss: 0.1022 - 268ms/epoch - 4ms/step\n",
            "Epoch 207/300\n",
            "65/65 - 0s - loss: 0.0281 - val_loss: 0.1051 - 252ms/epoch - 4ms/step\n",
            "Epoch 208/300\n",
            "65/65 - 0s - loss: 0.0279 - val_loss: 0.1084 - 252ms/epoch - 4ms/step\n",
            "Epoch 209/300\n",
            "65/65 - 0s - loss: 0.0325 - val_loss: 0.1083 - 245ms/epoch - 4ms/step\n",
            "Epoch 210/300\n",
            "65/65 - 0s - loss: 0.0299 - val_loss: 0.1043 - 252ms/epoch - 4ms/step\n",
            "Epoch 211/300\n",
            "65/65 - 0s - loss: 0.0265 - val_loss: 0.1121 - 248ms/epoch - 4ms/step\n",
            "Epoch 212/300\n",
            "65/65 - 0s - loss: 0.0286 - val_loss: 0.1151 - 293ms/epoch - 5ms/step\n",
            "Epoch 213/300\n",
            "65/65 - 0s - loss: 0.0268 - val_loss: 0.1021 - 291ms/epoch - 4ms/step\n",
            "Epoch 214/300\n",
            "65/65 - 0s - loss: 0.0253 - val_loss: 0.1166 - 245ms/epoch - 4ms/step\n",
            "Epoch 215/300\n",
            "65/65 - 0s - loss: 0.0246 - val_loss: 0.1173 - 249ms/epoch - 4ms/step\n",
            "Epoch 216/300\n",
            "65/65 - 0s - loss: 0.0252 - val_loss: 0.1107 - 255ms/epoch - 4ms/step\n",
            "Epoch 217/300\n",
            "65/65 - 0s - loss: 0.0273 - val_loss: 0.1191 - 258ms/epoch - 4ms/step\n",
            "Epoch 218/300\n",
            "65/65 - 0s - loss: 0.0259 - val_loss: 0.1174 - 251ms/epoch - 4ms/step\n",
            "Epoch 219/300\n",
            "65/65 - 0s - loss: 0.0250 - val_loss: 0.1068 - 253ms/epoch - 4ms/step\n",
            "Epoch 220/300\n",
            "65/65 - 0s - loss: 0.0251 - val_loss: 0.1077 - 249ms/epoch - 4ms/step\n",
            "Epoch 221/300\n",
            "65/65 - 0s - loss: 0.0265 - val_loss: 0.1091 - 260ms/epoch - 4ms/step\n",
            "Epoch 222/300\n",
            "65/65 - 0s - loss: 0.0257 - val_loss: 0.1113 - 290ms/epoch - 4ms/step\n",
            "Epoch 223/300\n",
            "65/65 - 0s - loss: 0.0266 - val_loss: 0.1157 - 260ms/epoch - 4ms/step\n",
            "Epoch 224/300\n",
            "65/65 - 0s - loss: 0.0265 - val_loss: 0.1163 - 294ms/epoch - 5ms/step\n",
            "Epoch 225/300\n",
            "65/65 - 0s - loss: 0.0257 - val_loss: 0.1152 - 290ms/epoch - 4ms/step\n",
            "Epoch 226/300\n",
            "65/65 - 0s - loss: 0.0243 - val_loss: 0.1104 - 247ms/epoch - 4ms/step\n",
            "Epoch 227/300\n",
            "65/65 - 0s - loss: 0.0255 - val_loss: 0.1140 - 304ms/epoch - 5ms/step\n",
            "Epoch 228/300\n",
            "65/65 - 0s - loss: 0.0249 - val_loss: 0.1329 - 250ms/epoch - 4ms/step\n",
            "Epoch 229/300\n",
            "65/65 - 0s - loss: 0.0278 - val_loss: 0.1035 - 255ms/epoch - 4ms/step\n",
            "Epoch 230/300\n",
            "65/65 - 0s - loss: 0.0240 - val_loss: 0.1139 - 245ms/epoch - 4ms/step\n",
            "Epoch 231/300\n",
            "65/65 - 0s - loss: 0.0254 - val_loss: 0.1129 - 247ms/epoch - 4ms/step\n",
            "Epoch 232/300\n",
            "65/65 - 0s - loss: 0.0237 - val_loss: 0.1174 - 286ms/epoch - 4ms/step\n",
            "Epoch 233/300\n",
            "65/65 - 0s - loss: 0.0214 - val_loss: 0.1085 - 261ms/epoch - 4ms/step\n",
            "Epoch 234/300\n",
            "65/65 - 0s - loss: 0.0228 - val_loss: 0.1177 - 294ms/epoch - 5ms/step\n",
            "Epoch 235/300\n",
            "65/65 - 0s - loss: 0.0233 - val_loss: 0.1180 - 254ms/epoch - 4ms/step\n",
            "Epoch 236/300\n",
            "65/65 - 0s - loss: 0.0223 - val_loss: 0.1086 - 251ms/epoch - 4ms/step\n",
            "Epoch 237/300\n",
            "65/65 - 0s - loss: 0.0244 - val_loss: 0.1203 - 252ms/epoch - 4ms/step\n",
            "Epoch 238/300\n",
            "65/65 - 0s - loss: 0.0239 - val_loss: 0.1046 - 303ms/epoch - 5ms/step\n",
            "Epoch 239/300\n",
            "65/65 - 0s - loss: 0.0253 - val_loss: 0.1121 - 260ms/epoch - 4ms/step\n",
            "Epoch 240/300\n",
            "65/65 - 0s - loss: 0.0244 - val_loss: 0.1067 - 292ms/epoch - 4ms/step\n",
            "Epoch 241/300\n",
            "65/65 - 0s - loss: 0.0241 - val_loss: 0.1156 - 333ms/epoch - 5ms/step\n",
            "Epoch 242/300\n",
            "65/65 - 0s - loss: 0.0257 - val_loss: 0.1148 - 401ms/epoch - 6ms/step\n",
            "Epoch 243/300\n",
            "65/65 - 0s - loss: 0.0258 - val_loss: 0.1082 - 421ms/epoch - 6ms/step\n",
            "Epoch 244/300\n",
            "65/65 - 0s - loss: 0.0274 - val_loss: 0.1110 - 407ms/epoch - 6ms/step\n",
            "Epoch 245/300\n",
            "65/65 - 0s - loss: 0.0244 - val_loss: 0.1262 - 396ms/epoch - 6ms/step\n",
            "Epoch 246/300\n",
            "65/65 - 0s - loss: 0.0250 - val_loss: 0.1173 - 398ms/epoch - 6ms/step\n",
            "Epoch 247/300\n",
            "65/65 - 0s - loss: 0.0273 - val_loss: 0.1075 - 406ms/epoch - 6ms/step\n",
            "Epoch 248/300\n",
            "65/65 - 0s - loss: 0.0241 - val_loss: 0.1306 - 347ms/epoch - 5ms/step\n",
            "Epoch 249/300\n",
            "65/65 - 0s - loss: 0.0249 - val_loss: 0.1181 - 370ms/epoch - 6ms/step\n",
            "Epoch 250/300\n",
            "65/65 - 0s - loss: 0.0218 - val_loss: 0.1089 - 422ms/epoch - 6ms/step\n",
            "Epoch 251/300\n",
            "65/65 - 0s - loss: 0.0214 - val_loss: 0.1112 - 245ms/epoch - 4ms/step\n",
            "Epoch 252/300\n",
            "65/65 - 0s - loss: 0.0202 - val_loss: 0.1101 - 280ms/epoch - 4ms/step\n",
            "Epoch 253/300\n",
            "65/65 - 0s - loss: 0.0204 - val_loss: 0.1123 - 257ms/epoch - 4ms/step\n",
            "Epoch 254/300\n",
            "65/65 - 0s - loss: 0.0230 - val_loss: 0.1200 - 256ms/epoch - 4ms/step\n",
            "Epoch 255/300\n",
            "65/65 - 0s - loss: 0.0259 - val_loss: 0.1307 - 242ms/epoch - 4ms/step\n",
            "Epoch 256/300\n",
            "65/65 - 0s - loss: 0.0254 - val_loss: 0.1092 - 284ms/epoch - 4ms/step\n",
            "Epoch 257/300\n",
            "65/65 - 0s - loss: 0.0222 - val_loss: 0.1278 - 251ms/epoch - 4ms/step\n",
            "Epoch 258/300\n",
            "65/65 - 0s - loss: 0.0227 - val_loss: 0.1105 - 247ms/epoch - 4ms/step\n",
            "Epoch 259/300\n",
            "65/65 - 0s - loss: 0.0197 - val_loss: 0.1146 - 282ms/epoch - 4ms/step\n",
            "Epoch 260/300\n",
            "65/65 - 0s - loss: 0.0240 - val_loss: 0.1142 - 248ms/epoch - 4ms/step\n",
            "Epoch 261/300\n",
            "65/65 - 0s - loss: 0.0198 - val_loss: 0.1134 - 250ms/epoch - 4ms/step\n",
            "Epoch 262/300\n",
            "65/65 - 0s - loss: 0.0205 - val_loss: 0.1198 - 280ms/epoch - 4ms/step\n",
            "Epoch 263/300\n",
            "65/65 - 0s - loss: 0.0204 - val_loss: 0.1120 - 285ms/epoch - 4ms/step\n",
            "Epoch 264/300\n",
            "65/65 - 0s - loss: 0.0202 - val_loss: 0.1050 - 251ms/epoch - 4ms/step\n",
            "Epoch 265/300\n",
            "65/65 - 0s - loss: 0.0231 - val_loss: 0.1121 - 292ms/epoch - 4ms/step\n",
            "Epoch 266/300\n",
            "65/65 - 0s - loss: 0.0228 - val_loss: 0.1082 - 243ms/epoch - 4ms/step\n",
            "Epoch 267/300\n",
            "65/65 - 0s - loss: 0.0212 - val_loss: 0.1067 - 253ms/epoch - 4ms/step\n",
            "Epoch 268/300\n",
            "65/65 - 0s - loss: 0.0232 - val_loss: 0.1150 - 259ms/epoch - 4ms/step\n",
            "Epoch 269/300\n",
            "65/65 - 0s - loss: 0.0239 - val_loss: 0.1125 - 283ms/epoch - 4ms/step\n",
            "Epoch 270/300\n",
            "65/65 - 0s - loss: 0.0229 - val_loss: 0.1090 - 246ms/epoch - 4ms/step\n",
            "Epoch 271/300\n",
            "65/65 - 0s - loss: 0.0189 - val_loss: 0.1119 - 247ms/epoch - 4ms/step\n",
            "Epoch 272/300\n",
            "65/65 - 0s - loss: 0.0245 - val_loss: 0.1179 - 264ms/epoch - 4ms/step\n",
            "Epoch 273/300\n",
            "65/65 - 0s - loss: 0.0222 - val_loss: 0.1129 - 287ms/epoch - 4ms/step\n",
            "Epoch 274/300\n",
            "65/65 - 0s - loss: 0.0209 - val_loss: 0.1067 - 246ms/epoch - 4ms/step\n",
            "Epoch 275/300\n",
            "65/65 - 0s - loss: 0.0205 - val_loss: 0.1083 - 253ms/epoch - 4ms/step\n",
            "Epoch 276/300\n",
            "65/65 - 0s - loss: 0.0200 - val_loss: 0.1324 - 262ms/epoch - 4ms/step\n",
            "Epoch 277/300\n",
            "65/65 - 0s - loss: 0.0206 - val_loss: 0.1083 - 246ms/epoch - 4ms/step\n",
            "Epoch 278/300\n",
            "65/65 - 0s - loss: 0.0201 - val_loss: 0.1112 - 248ms/epoch - 4ms/step\n",
            "Epoch 279/300\n",
            "65/65 - 0s - loss: 0.0209 - val_loss: 0.1185 - 285ms/epoch - 4ms/step\n",
            "Epoch 280/300\n",
            "65/65 - 0s - loss: 0.0221 - val_loss: 0.1065 - 288ms/epoch - 4ms/step\n",
            "Epoch 281/300\n",
            "65/65 - 0s - loss: 0.0234 - val_loss: 0.1107 - 285ms/epoch - 4ms/step\n",
            "Epoch 282/300\n",
            "65/65 - 0s - loss: 0.0192 - val_loss: 0.1082 - 254ms/epoch - 4ms/step\n",
            "Epoch 283/300\n",
            "65/65 - 0s - loss: 0.0211 - val_loss: 0.1048 - 272ms/epoch - 4ms/step\n",
            "Epoch 284/300\n",
            "65/65 - 0s - loss: 0.0197 - val_loss: 0.1252 - 265ms/epoch - 4ms/step\n",
            "Epoch 285/300\n",
            "65/65 - 0s - loss: 0.0193 - val_loss: 0.1061 - 253ms/epoch - 4ms/step\n",
            "Epoch 286/300\n",
            "65/65 - 0s - loss: 0.0166 - val_loss: 0.1124 - 247ms/epoch - 4ms/step\n",
            "Epoch 287/300\n",
            "65/65 - 0s - loss: 0.0180 - val_loss: 0.1118 - 267ms/epoch - 4ms/step\n",
            "Epoch 288/300\n",
            "65/65 - 0s - loss: 0.0183 - val_loss: 0.1198 - 402ms/epoch - 6ms/step\n",
            "Epoch 289/300\n",
            "65/65 - 0s - loss: 0.0208 - val_loss: 0.1220 - 383ms/epoch - 6ms/step\n",
            "Epoch 290/300\n",
            "65/65 - 0s - loss: 0.0187 - val_loss: 0.1084 - 378ms/epoch - 6ms/step\n",
            "Epoch 291/300\n",
            "65/65 - 0s - loss: 0.0193 - val_loss: 0.1158 - 393ms/epoch - 6ms/step\n",
            "Epoch 292/300\n",
            "65/65 - 0s - loss: 0.0203 - val_loss: 0.1083 - 398ms/epoch - 6ms/step\n",
            "Epoch 293/300\n",
            "65/65 - 0s - loss: 0.0173 - val_loss: 0.1179 - 377ms/epoch - 6ms/step\n",
            "Epoch 294/300\n",
            "65/65 - 0s - loss: 0.0181 - val_loss: 0.1086 - 392ms/epoch - 6ms/step\n",
            "Epoch 295/300\n",
            "65/65 - 0s - loss: 0.0181 - val_loss: 0.1143 - 414ms/epoch - 6ms/step\n",
            "Epoch 296/300\n",
            "65/65 - 0s - loss: 0.0181 - val_loss: 0.1073 - 407ms/epoch - 6ms/step\n",
            "Epoch 297/300\n",
            "65/65 - 0s - loss: 0.0175 - val_loss: 0.1196 - 307ms/epoch - 5ms/step\n",
            "Epoch 298/300\n",
            "65/65 - 0s - loss: 0.0201 - val_loss: 0.1235 - 262ms/epoch - 4ms/step\n",
            "Epoch 299/300\n",
            "65/65 - 0s - loss: 0.0198 - val_loss: 0.1057 - 252ms/epoch - 4ms/step\n",
            "Epoch 300/300\n",
            "65/65 - 0s - loss: 0.0213 - val_loss: 0.1101 - 260ms/epoch - 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fd251e62230>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Build the model\n",
        "hidden_layer_neurals = 64\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(hidden_layer_neurals, activation='relu', input_shape=(10,)),\n",
        "    tf.keras.layers.Dense(hidden_layer_neurals, activation='relu'),\n",
        "    tf.keras.layers.Dense(hidden_layer_neurals, activation='relu'),\n",
        "    tf.keras.layers.Dense(hidden_layer_neurals, activation='relu'),\n",
        "    tf.keras.layers.Dense(hidden_layer_neurals, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "# Define your desired learning rate\n",
        "learning_rate = 2e-4\n",
        "adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=adam_optimizer, loss='mean_squared_error')\n",
        "\n",
        "# # Train the model\n",
        "model.fit(X_train_minmax, y_train, validation_split=0.15, epochs=300, batch_size=32, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "\n",
        "test_loss = model.evaluate(X_test_minmax, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hizV8PYg0Zod",
        "outputId": "e8dd3549-5706-4087-812a-414e9a492cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate predictions\n",
        "y_pred = model.predict(X_test_minmax)\n",
        "\n",
        "# Flatten y_pred to ensure it's in the same shape as y_test\n",
        "y_pred = y_pred.flatten()\n",
        "\n",
        "# Print true and predicted values\n",
        "for true, pred in zip(y_test, y_pred):\n",
        "    print(f\"True: {true}, Predicted: {pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ahR0Q4b_b_4",
        "outputId": "040285a8-1f99-4c5f-e32a-74976258cfc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 3ms/step\n",
            "True: 3.0178682662762513, Predicted: 2.9539005756378174\n",
            "True: 0.34011344442588587, Predicted: 0.462912380695343\n",
            "True: 0.4888605092503627, Predicted: 0.46087661385536194\n",
            "True: 0.5187183288106738, Predicted: 0.5197278261184692\n",
            "True: 3.839619957911904, Predicted: 4.492387294769287\n",
            "True: 0.5437148188748948, Predicted: 0.5917494297027588\n",
            "True: 1.8904210069442406, Predicted: 1.8316186666488647\n",
            "True: 0.16692362756604606, Predicted: 0.2620367109775543\n",
            "True: 0.6165579585404503, Predicted: 0.6703601479530334\n",
            "True: 0.4256696180779985, Predicted: 1.259719967842102\n",
            "True: 0.2265400860152856, Predicted: -0.07402719557285309\n",
            "True: 0.3635165964266504, Predicted: 0.457239031791687\n",
            "True: 3.1286093587060138, Predicted: 3.123720645904541\n",
            "True: 0.37906718659229477, Predicted: 0.37145134806632996\n",
            "True: 0.5592932747010888, Predicted: 0.5612027049064636\n",
            "True: 0.9191880242335625, Predicted: 1.0597026348114014\n",
            "True: 0.5398662690392555, Predicted: 0.5737130045890808\n",
            "True: 0.947616845543993, Predicted: 0.8408961892127991\n",
            "True: 0.5976291318793855, Predicted: 0.62075275182724\n",
            "True: 0.5444679227980618, Predicted: 0.5658093690872192\n",
            "True: 0.36442501587431986, Predicted: 0.2361379861831665\n",
            "True: 0.3213966364663681, Predicted: 0.4025286138057709\n",
            "True: 0.39719217855370564, Predicted: 0.42751574516296387\n",
            "True: 0.46339406881878753, Predicted: 0.5141991972923279\n",
            "True: 0.4998711346774508, Predicted: 0.4973873496055603\n",
            "True: 0.6621818370389729, Predicted: 0.5760633945465088\n",
            "True: 0.3466140390859927, Predicted: 0.24018928408622742\n",
            "True: 0.5304353586542719, Predicted: 0.6755796074867249\n",
            "True: 0.6349281278131933, Predicted: 0.6055775284767151\n",
            "True: 4.009078370790966, Predicted: 0.6365982294082642\n",
            "True: 0.15693528156527262, Predicted: 0.13684457540512085\n",
            "True: 0.005760578790451412, Predicted: 0.1725917011499405\n",
            "True: 0.6012484725763904, Predicted: 0.5712727308273315\n",
            "True: 2.550113897264019, Predicted: 2.837585926055908\n",
            "True: 0.5979547634140958, Predicted: 0.4567400813102722\n",
            "True: 0.5147429939518088, Predicted: 0.49170899391174316\n",
            "True: 0.5489264960751795, Predicted: 0.7236393094062805\n",
            "True: 0.4418033158814417, Predicted: 0.5043516755104065\n",
            "True: 0.4124673847122135, Predicted: 0.6174694299697876\n",
            "True: 0.40102232178488234, Predicted: 0.3617843985557556\n",
            "True: 0.42481285414657927, Predicted: 0.24945449829101562\n",
            "True: 0.32066235380614466, Predicted: 0.22441759705543518\n",
            "True: 0.5114085626179508, Predicted: 0.5618292093276978\n",
            "True: 2.8078526311468717, Predicted: 3.1554415225982666\n",
            "True: 0.1745484529195676, Predicted: 0.3025878667831421\n",
            "True: 3.285942394938939, Predicted: 2.981917381286621\n",
            "True: 0.43155547391679716, Predicted: 0.4759776294231415\n",
            "True: 0.5457043260666736, Predicted: 0.5801572799682617\n",
            "True: 3.7029384353296853, Predicted: 2.9861161708831787\n",
            "True: 0.47613036038078593, Predicted: 0.4169211685657501\n",
            "True: 3.902199776495614, Predicted: 4.558155536651611\n",
            "True: 1.8334584544155872, Predicted: 2.377272844314575\n",
            "True: 0.26580122325567723, Predicted: -0.02053128555417061\n",
            "True: 0.5963953520268879, Predicted: 0.67310631275177\n",
            "True: 0.5608153560764636, Predicted: 0.6619210839271545\n",
            "True: 0.8222657677885976, Predicted: 1.0848169326782227\n",
            "True: 0.2652822699803816, Predicted: 0.3244360685348511\n",
            "True: 0.5055572379073607, Predicted: 0.4382801055908203\n",
            "True: 0.5663086327461045, Predicted: 0.507904589176178\n",
            "True: 0.3499933377620261, Predicted: 0.4118845462799072\n",
            "True: 3.114378859658725, Predicted: 3.7408061027526855\n",
            "True: 0.6456398873024529, Predicted: 0.6451042890548706\n",
            "True: 0.3997232724780272, Predicted: 0.28333190083503723\n",
            "True: 0.5703849287756964, Predicted: 0.7441393733024597\n",
            "True: 0.6103283617523672, Predicted: 0.7054727673530579\n",
            "True: 0.9966142010332308, Predicted: 1.2253410816192627\n",
            "True: 0.9691263352627072, Predicted: 1.1038275957107544\n",
            "True: 0.42264960442993743, Predicted: 0.47204020619392395\n",
            "True: 0.5447169992602588, Predicted: 0.26469987630844116\n",
            "True: 0.5752680159344936, Predicted: 0.6169838905334473\n",
            "True: 0.003632533849790467, Predicted: 0.3600457012653351\n",
            "True: 0.006014552492107068, Predicted: 0.050957705825567245\n",
            "True: 0.40956650398751326, Predicted: 0.4964238405227661\n",
            "True: 0.5047437795579498, Predicted: 0.6285306811332703\n",
            "True: 0.5158447086637097, Predicted: 1.3403353691101074\n",
            "True: 0.6887522842245746, Predicted: 0.9127582907676697\n",
            "True: 0.5860988329210595, Predicted: 0.4507445991039276\n",
            "True: 0.5739638359127148, Predicted: 0.6706158518791199\n",
            "True: 0.31614828853927457, Predicted: 0.34707942605018616\n",
            "True: 0.43838793637638185, Predicted: 0.42959946393966675\n",
            "True: 0.5827640311558833, Predicted: 0.535490095615387\n",
            "True: 0.4629608001607466, Predicted: 0.5495949387550354\n",
            "True: 0.5062471112686066, Predicted: 0.5212545990943909\n",
            "True: 0.5760668643206351, Predicted: 0.5818135738372803\n",
            "True: 0.5146541515916518, Predicted: 0.4466070830821991\n",
            "True: 0.630198244235264, Predicted: 0.37563660740852356\n",
            "True: 3.097019043293701, Predicted: 2.9627459049224854\n",
            "True: 1.1693592383058196, Predicted: 1.0876502990722656\n",
            "True: 0.5004326371553228, Predicted: 0.9546458721160889\n",
            "True: 0.5396738572860376, Predicted: 1.3187336921691895\n",
            "True: 0.493212953583548, Predicted: 0.391147255897522\n",
            "True: 0.5291180080024881, Predicted: 0.6199533343315125\n",
            "True: 0.4811047148332485, Predicted: 0.6255080103874207\n",
            "True: 0.3820149566945108, Predicted: 0.3698756694793701\n",
            "True: 0.5560640077799889, Predicted: 0.45821520686149597\n",
            "True: 0.49995782287342827, Predicted: 0.6277008652687073\n",
            "True: 0.6043538411393561, Predicted: 0.5707365274429321\n",
            "True: 0.265581178327119, Predicted: 0.34313732385635376\n",
            "True: 0.4766963441986063, Predicted: 0.3465057909488678\n",
            "True: 0.5674555867814141, Predicted: 0.6158217191696167\n",
            "True: 0.6528894864365454, Predicted: 0.7391430735588074\n",
            "True: 0.06706591656360081, Predicted: 0.3187830448150635\n",
            "True: 0.5905983821662687, Predicted: 0.6013023257255554\n",
            "True: 0.44724779891869043, Predicted: 0.34679239988327026\n",
            "True: 0.004935881579399667, Predicted: 0.18681921064853668\n",
            "True: 0.32330762392429957, Predicted: 0.3987836539745331\n",
            "True: 0.5271019720593643, Predicted: 1.0329885482788086\n",
            "True: 0.6348981782513815, Predicted: 0.420523464679718\n",
            "True: 0.48595428075306696, Predicted: 0.5374298095703125\n",
            "True: 0.5424922242989205, Predicted: 0.7890400290489197\n",
            "True: 0.592971588922771, Predicted: 0.683635950088501\n",
            "True: 0.5586420825204634, Predicted: 0.5279372334480286\n",
            "True: 1.1142485820771038, Predicted: 0.8150177597999573\n",
            "True: 0.3352893391326924, Predicted: 0.33351796865463257\n",
            "True: 3.045423356890952, Predicted: 3.0899369716644287\n",
            "True: 0.5127106140345801, Predicted: 0.3356059491634369\n",
            "True: 0.5584410769679805, Predicted: 0.7528403401374817\n",
            "True: 0.572191263552938, Predicted: 0.59011310338974\n",
            "True: 0.5063630744781207, Predicted: 0.1659659743309021\n",
            "True: 0.5011340068668914, Predicted: 0.8975936770439148\n",
            "True: 0.5525271771455922, Predicted: 0.50509113073349\n",
            "True: 0.25116046661893104, Predicted: 0.012560289353132248\n",
            "True: 0.35531697135750884, Predicted: 0.4086328148841858\n",
            "True: 0.5698185087828924, Predicted: 0.7220752835273743\n",
            "True: 0.4539330672596794, Predicted: 0.7379298806190491\n",
            "True: 0.41705718636424377, Predicted: 0.3625463545322418\n",
            "True: 0.454809004385321, Predicted: 0.6356999278068542\n",
            "True: 0.5090534486983491, Predicted: 0.5823807120323181\n",
            "True: 0.5413102434580368, Predicted: 0.6418117880821228\n",
            "True: 0.007451671921194336, Predicted: 0.38195133209228516\n",
            "True: 0.5439178084168016, Predicted: 0.5966451168060303\n",
            "True: 2.1704656577845727, Predicted: 2.427945613861084\n",
            "True: 0.5671899479207911, Predicted: 0.48613500595092773\n",
            "True: 0.455413790206956, Predicted: 0.42707186937332153\n",
            "True: 0.44365758690689494, Predicted: 0.42808517813682556\n",
            "True: 0.4119664524547543, Predicted: 0.4399811327457428\n",
            "True: 0.5350664435014026, Predicted: 0.5806378126144409\n",
            "True: 0.6187307326434571, Predicted: 0.6631409525871277\n",
            "True: 1.7382992658786716, Predicted: 0.7405110597610474\n",
            "True: 0.5285594844504782, Predicted: 0.5960707664489746\n",
            "True: 0.5633012271351573, Predicted: 0.5418705344200134\n",
            "True: 0.5142505474316261, Predicted: 0.554799497127533\n",
            "True: 0.06415932260159048, Predicted: 0.15703056752681732\n",
            "True: 0.5658981640144848, Predicted: 0.5110117197036743\n",
            "True: 0.5559150979793952, Predicted: 0.4799751043319702\n",
            "True: 1.7385343409415026, Predicted: 2.252531051635742\n",
            "True: 0.4235421969573525, Predicted: 0.33725109696388245\n",
            "True: 0.4764426598290648, Predicted: 0.6656543016433716\n",
            "True: 0.5734915972219224, Predicted: 0.7136861681938171\n",
            "True: 0.4318881193501102, Predicted: 0.44664841890335083\n",
            "True: 0.516779037386176, Predicted: 0.49445417523384094\n",
            "True: 0.46713493394744154, Predicted: 0.48183223605155945\n",
            "True: 0.5305347008950302, Predicted: 0.5470377206802368\n",
            "True: 0.35101555722338845, Predicted: 0.46402308344841003\n",
            "True: 0.5008671264664958, Predicted: 0.47887471318244934\n",
            "True: 0.7176217325329808, Predicted: 0.797036349773407\n",
            "True: 0.9444968281103342, Predicted: 1.8895798921585083\n",
            "True: 1.4905785195246772, Predicted: 1.3977735042572021\n",
            "True: 1.4952519904060333, Predicted: 2.4627814292907715\n",
            "True: 0.5254460199436873, Predicted: 0.6431744694709778\n",
            "True: 1.4217714929342395, Predicted: 1.453420877456665\n",
            "True: 0.5777936451179756, Predicted: 0.3108094334602356\n",
            "True: 0.4096657733642221, Predicted: 0.4442669153213501\n",
            "True: 3.4343159750066334, Predicted: 2.9885611534118652\n",
            "True: 0.33512677843290917, Predicted: 0.34576845169067383\n",
            "True: 0.46721815805939393, Predicted: 0.54450923204422\n",
            "True: 0.5770828951900283, Predicted: 0.06335997581481934\n",
            "True: 0.5960003815985626, Predicted: 0.6212850213050842\n",
            "True: 0.9753516128291212, Predicted: 1.2155399322509766\n",
            "True: 0.1278841712708297, Predicted: 0.2703092694282532\n",
            "True: 0.5413124374571668, Predicted: 0.6421092748641968\n",
            "True: 1.0012355580724621, Predicted: 1.1505988836288452\n",
            "True: 0.4728111656453197, Predicted: 0.47492700815200806\n",
            "True: 3.6424377950700384, Predicted: 3.231081247329712\n",
            "True: 0.26012978798270003, Predicted: 0.37859460711479187\n",
            "True: 0.4776504231547176, Predicted: 0.34254586696624756\n",
            "True: 1.2387867084696458, Predicted: 1.2799458503723145\n",
            "True: 0.3875632720594947, Predicted: 0.2995542883872986\n",
            "True: 0.4450743595453788, Predicted: 0.4462015628814697\n",
            "True: 0.3175030586512923, Predicted: 0.3062497079372406\n",
            "True: 0.08607564735048949, Predicted: 0.049877237528562546\n",
            "True: 0.47224947560154296, Predicted: 0.49522116780281067\n",
            "True: 0.3227890665664677, Predicted: 0.372336745262146\n",
            "True: 0.5076096522723875, Predicted: 0.6994267106056213\n",
            "True: 0.4874685363293496, Predicted: 0.3297099173069\n",
            "True: 0.16031446188002527, Predicted: 0.2771020233631134\n",
            "True: 0.4073320324309529, Predicted: 0.3266630470752716\n",
            "True: 0.05218723056727326, Predicted: 0.10866868495941162\n",
            "True: 0.5123546830578027, Predicted: 0.5209525227546692\n",
            "True: 0.5689551350333061, Predicted: 0.4493134319782257\n",
            "True: 0.31557608142525917, Predicted: 0.45667821168899536\n",
            "True: 0.5143174836404412, Predicted: 0.59116131067276\n",
            "True: 0.5512890776211052, Predicted: 0.49255669116973877\n",
            "True: 4.421803738678234, Predicted: 4.064488887786865\n",
            "True: 0.4164943808263621, Predicted: 0.4104132354259491\n",
            "True: 0.38950308069068074, Predicted: 0.23031337559223175\n",
            "True: 1.1776533542655794, Predicted: 2.0650713443756104\n",
            "True: 0.5619731189756225, Predicted: 0.58343505859375\n",
            "True: 0.5345842097282487, Predicted: 0.5963069796562195\n",
            "True: 3.0680036191982856, Predicted: 3.4633524417877197\n",
            "True: 1.2451634475197089, Predicted: 1.0217498540878296\n",
            "True: 0.5234595505983579, Predicted: 0.5143002271652222\n",
            "True: 0.8636330397856207, Predicted: 0.9322780966758728\n",
            "True: 0.6039996559713253, Predicted: 0.6676198840141296\n",
            "True: 0.5528056262635658, Predicted: 0.63300621509552\n",
            "True: 0.8822395418720328, Predicted: 0.9010770320892334\n",
            "True: 0.42073205896346955, Predicted: 0.5857909321784973\n",
            "True: 0.12608009626470387, Predicted: 0.0936090499162674\n",
            "True: 0.6496401050369173, Predicted: 0.5792980790138245\n",
            "True: 0.46980904567703546, Predicted: 0.5105956196784973\n",
            "True: 0.1517574065910375, Predicted: 0.10840663313865662\n",
            "True: 1.4010140667762543, Predicted: 1.2983124256134033\n",
            "True: 0.5677807306479226, Predicted: 0.7547587752342224\n",
            "True: 0.6251798771489965, Predicted: 0.6257231831550598\n",
            "True: 0.755938902511106, Predicted: 0.8404566645622253\n",
            "True: 0.6238999729143934, Predicted: 0.7027813196182251\n",
            "True: 0.43536542326035116, Predicted: 0.8267373442649841\n",
            "True: 0.41965237075550277, Predicted: 0.6343104839324951\n",
            "True: 0.3574600268477557, Predicted: 0.5213713645935059\n",
            "True: 2.829365370309198, Predicted: 1.7588860988616943\n",
            "True: 0.3881112828730292, Predicted: 0.33272895216941833\n",
            "True: 0.41673140467336933, Predicted: 0.5498165488243103\n",
            "True: 0.580261962568283, Predicted: 0.4775503873825073\n",
            "True: 0.4111934403599161, Predicted: 0.42959272861480713\n",
            "True: 0.7451181751056992, Predicted: 0.6180260181427002\n",
            "True: 0.46271758957111137, Predicted: 0.39372384548187256\n",
            "True: 0.5634257858230397, Predicted: 0.5816939473152161\n",
            "True: 0.8048141194348469, Predicted: 0.7501196265220642\n",
            "True: 0.5016212235471288, Predicted: 0.604103147983551\n",
            "True: 0.558375263402458, Predicted: 0.5326734781265259\n",
            "True: 0.3968243105282249, Predicted: 0.37454068660736084\n",
            "True: 0.495910371677825, Predicted: 0.553673267364502\n",
            "True: 1.6720428240775649, Predicted: 1.9031113386154175\n",
            "True: 0.3498680544181406, Predicted: 0.3556368052959442\n",
            "True: 0.0293155585160025, Predicted: 0.06608043611049652\n",
            "True: 0.005520389526246448, Predicted: 0.09794433414936066\n",
            "True: 0.5754547199987408, Predicted: 0.5452761054039001\n",
            "True: 0.5447100157507454, Predicted: 0.47571292519569397\n",
            "True: 0.3295297231155877, Predicted: 0.5407922267913818\n",
            "True: 0.4011206593634006, Predicted: 0.6660667657852173\n",
            "True: 0.12101355907246902, Predicted: 0.08617204427719116\n",
            "True: 0.41795147858528114, Predicted: 0.47655707597732544\n",
            "True: 1.1878806851389438, Predicted: 0.9182986617088318\n",
            "True: 1.2553674010002056, Predicted: 0.8372998237609863\n",
            "True: 0.0053716631470254, Predicted: 0.30239078402519226\n",
            "True: 0.16526243331380952, Predicted: 0.18518032133579254\n",
            "True: 0.38781247989496304, Predicted: 0.24155890941619873\n",
            "True: 1.7266619786850408, Predicted: 1.707505702972412\n",
            "True: 0.5574733933515582, Predicted: 0.5980014801025391\n",
            "True: 0.8250648732111642, Predicted: 0.7625746130943298\n",
            "True: 0.56966199787398, Predicted: 0.6347293257713318\n",
            "True: 0.5074450376062797, Predicted: 0.5525640845298767\n",
            "True: 0.49399247311342614, Predicted: 0.5635839104652405\n",
            "True: 0.6734506811993722, Predicted: 0.6877236366271973\n",
            "True: 0.36329870198927333, Predicted: 0.47406408190727234\n",
            "True: 0.3965031355849322, Predicted: 0.47640830278396606\n",
            "True: 0.6171975513739832, Predicted: 0.4141731262207031\n",
            "True: 0.586769788741315, Predicted: 0.5888215899467468\n",
            "True: 0.32870773395874064, Predicted: 0.6312790513038635\n",
            "True: 0.3301120582868426, Predicted: 0.20553943514823914\n",
            "True: 0.9212499555013718, Predicted: 0.9225639700889587\n",
            "True: 3.029963087332907, Predicted: 3.5760066509246826\n",
            "True: 0.6524319251569635, Predicted: 0.6549216508865356\n",
            "True: 0.27473797821356094, Predicted: 0.24306538701057434\n",
            "True: 0.5355594641258705, Predicted: 0.8089414238929749\n",
            "True: 0.32405875892246555, Predicted: 0.41860857605934143\n",
            "True: 0.6530161247548498, Predicted: 0.9331390857696533\n",
            "True: 0.4304205555075136, Predicted: 0.4366718828678131\n",
            "True: 0.3445888679950133, Predicted: 0.29275497794151306\n",
            "True: 0.8796005121390759, Predicted: 0.7782304286956787\n",
            "True: 0.9083751608952247, Predicted: 0.858556866645813\n",
            "True: 0.418327051991724, Predicted: 0.28758418560028076\n",
            "True: 0.19418604559285954, Predicted: 0.34131842851638794\n",
            "True: 0.505852034512233, Predicted: 0.5344070792198181\n",
            "True: 0.584108078490298, Predicted: 0.420865923166275\n",
            "True: 0.5722976627703975, Predicted: 0.5071088671684265\n",
            "True: 0.474457677905189, Predicted: 0.7380852699279785\n",
            "True: 0.40973611707906954, Predicted: 0.3452851176261902\n",
            "True: 0.5207149161149576, Predicted: 0.5359952449798584\n",
            "True: 0.5730028915591172, Predicted: 0.4432469308376312\n",
            "True: 0.004136710048815613, Predicted: 0.07042458653450012\n",
            "True: 2.2097515146182864, Predicted: 1.3689316511154175\n",
            "True: 0.32213555471655836, Predicted: 0.33392754197120667\n",
            "True: 0.8093768152981499, Predicted: 0.9432935118675232\n",
            "True: 2.22471054008744, Predicted: 2.481154680252075\n",
            "True: 0.705298910100876, Predicted: 1.1310395002365112\n",
            "True: 0.41342320292718787, Predicted: 0.2511448264122009\n",
            "True: 0.36438957123129845, Predicted: 0.3814355134963989\n",
            "True: 0.9199297464446872, Predicted: 0.5172074437141418\n",
            "True: 0.7846069305127013, Predicted: 0.8308830857276917\n",
            "True: 0.5807892519050166, Predicted: 0.6211600303649902\n",
            "True: 0.7813258864427746, Predicted: 2.337684392929077\n",
            "True: 2.9139098100623824, Predicted: 3.8942174911499023\n",
            "True: 0.27130634068841103, Predicted: 0.20105330646038055\n",
            "True: 2.8799042801008383, Predicted: 3.0207910537719727\n",
            "True: 0.6660771192030668, Predicted: 0.2619078755378723\n",
            "True: 0.5102619710246241, Predicted: 0.5878974199295044\n",
            "True: 0.0027958591789994337, Predicted: 0.6205277442932129\n",
            "True: 0.31302821000370795, Predicted: 0.3007577359676361\n",
            "True: 0.5626152229305537, Predicted: 0.710077702999115\n",
            "True: 0.6806247882133637, Predicted: 0.6372914910316467\n",
            "True: 0.19188758461207694, Predicted: -0.06347277760505676\n",
            "True: 0.6158579378830831, Predicted: 0.6467631459236145\n",
            "True: 0.6141722316858543, Predicted: 0.5234315991401672\n",
            "True: 0.5439247334644753, Predicted: 0.4557035267353058\n",
            "True: 1.5334786536375882, Predicted: 1.2309726476669312\n",
            "True: 1.153617433868687, Predicted: 0.9380078911781311\n",
            "True: 0.37312404859154724, Predicted: 0.42885541915893555\n",
            "True: 0.38717273365063765, Predicted: 0.8852762579917908\n",
            "True: 0.09505126522922763, Predicted: 0.2791026532649994\n",
            "True: 0.5303134591494891, Predicted: 0.6109424233436584\n",
            "True: 0.22389825633537375, Predicted: 0.23741382360458374\n",
            "True: 0.27090045512905503, Predicted: -0.057499561458826065\n",
            "True: 0.35807548903780806, Predicted: 0.4452512860298157\n",
            "True: 0.5458907931246092, Predicted: 0.5969387292861938\n",
            "True: 1.2106073688232672, Predicted: 2.0219767093658447\n",
            "True: 0.48286386629271866, Predicted: 0.38410767912864685\n",
            "True: 0.5177213748955252, Predicted: 0.5024383664131165\n",
            "True: 0.5821739186729791, Predicted: 0.7387872338294983\n",
            "True: 0.5121860107286177, Predicted: 0.47190535068511963\n",
            "True: 0.2998186066581788, Predicted: 0.5403624773025513\n",
            "True: 0.5489467101644766, Predicted: 0.7095787525177002\n",
            "True: 0.6071773030618068, Predicted: 0.9421486258506775\n",
            "True: 0.5978601267729612, Predicted: 0.6015687584877014\n",
            "True: 0.5841359603211388, Predicted: 0.5635645985603333\n",
            "True: 1.1415976883070755, Predicted: 1.2481006383895874\n",
            "True: 0.5582587594133436, Predicted: 0.5501449108123779\n",
            "True: 0.5747693500490207, Predicted: 0.6162101030349731\n",
            "True: 0.543369745920991, Predicted: 0.9105328917503357\n",
            "True: 3.992126885487972, Predicted: 3.880585193634033\n",
            "True: 0.39073461492401773, Predicted: 0.4012530446052551\n",
            "True: 0.6245771921809543, Predicted: 0.5454003810882568\n",
            "True: 1.318379824613935, Predicted: 1.1985719203948975\n",
            "True: 0.7276519770713993, Predicted: 0.6934264898300171\n",
            "True: 0.4255000186520082, Predicted: 0.45944106578826904\n",
            "True: 0.5141292637781116, Predicted: 0.45902779698371887\n",
            "True: 0.3988537303427012, Predicted: 0.4170469045639038\n",
            "True: 2.5961618216314393, Predicted: 2.1416726112365723\n",
            "True: 0.2833853495804853, Predicted: 0.3406858742237091\n",
            "True: 0.5539440687461469, Predicted: 0.5966160893440247\n",
            "True: 3.2672756981650375, Predicted: 3.0760951042175293\n",
            "True: 0.3667323113591937, Predicted: 0.5893036723136902\n",
            "True: 2.37562012452399, Predicted: 2.9311413764953613\n",
            "True: 0.34292130610077287, Predicted: 0.5292340517044067\n",
            "True: 1.063811137041237, Predicted: 1.6892685890197754\n",
            "True: 0.5528027975962169, Predicted: 0.49784231185913086\n",
            "True: 0.7286015586174522, Predicted: 0.7552935481071472\n",
            "True: 0.41785491969415484, Predicted: 0.6041886806488037\n",
            "True: 0.41551423149780414, Predicted: 0.47072672843933105\n",
            "True: 0.5424987741791034, Predicted: 0.6369004845619202\n",
            "True: 0.41012447014271836, Predicted: 0.5440858006477356\n",
            "True: 0.15405166191861103, Predicted: -0.12496200203895569\n",
            "True: 0.42123298223484995, Predicted: 0.37776878476142883\n",
            "True: 0.5116119762542414, Predicted: 0.4751417338848114\n",
            "True: 0.737193512085931, Predicted: 0.7946605086326599\n",
            "True: 0.49935446434116965, Predicted: 0.7587886452674866\n",
            "True: 0.6073158890189307, Predicted: 0.7517766356468201\n",
            "True: 0.616853731822046, Predicted: 0.6327407956123352\n",
            "True: 0.3874500432683276, Predicted: 0.35516148805618286\n",
            "True: 0.35396049106203215, Predicted: 0.46753811836242676\n",
            "True: 2.0791462623551684, Predicted: 2.34997296333313\n",
            "True: 0.4671331473013026, Predicted: 0.540302574634552\n",
            "True: 0.5845496615533631, Predicted: 0.8672379851341248\n",
            "True: 0.5718996945779558, Predicted: 0.6268906593322754\n",
            "True: 0.5421494257576649, Predicted: 0.5987641215324402\n",
            "True: 0.5681457474250358, Predicted: 0.5183797478675842\n",
            "True: 0.3270999286606835, Predicted: 0.2238362431526184\n",
            "True: 0.9094261124303096, Predicted: 1.4664016962051392\n",
            "True: 0.8669224757348308, Predicted: 0.7761871218681335\n",
            "True: 0.5534780082759685, Predicted: 0.5779929161071777\n",
            "True: 0.43780019537514914, Predicted: 0.49072587490081787\n",
            "True: 3.805697053846136, Predicted: 3.6285505294799805\n",
            "True: 0.5682172076372134, Predicted: 0.8366155028343201\n",
            "True: 0.5395508913492147, Predicted: 0.6225999593734741\n",
            "True: 0.5845249304955428, Predicted: 0.5590217709541321\n",
            "True: 0.5787084662869124, Predicted: 0.5068362951278687\n",
            "True: 0.690218181672059, Predicted: 0.38886621594429016\n",
            "True: 0.35308433880249457, Predicted: 0.2718559503555298\n",
            "True: 2.3102164917633994, Predicted: 2.733551263809204\n",
            "True: 1.524294227837417, Predicted: 1.0621681213378906\n",
            "True: 0.48892162925920674, Predicted: 0.4879830479621887\n",
            "True: 0.6487109913435524, Predicted: 0.5592418313026428\n",
            "True: 0.8082491348419513, Predicted: 0.8832906484603882\n",
            "True: 0.33882159582695104, Predicted: 0.1510809361934662\n",
            "True: 0.3358181186142875, Predicted: 0.4723649322986603\n",
            "True: 1.1920327965505453, Predicted: 0.9248912930488586\n",
            "True: 1.1908896007428988, Predicted: 1.5451549291610718\n",
            "True: 0.7469600152016266, Predicted: 0.7402750849723816\n",
            "True: 0.3718849988925145, Predicted: 0.6358886361122131\n",
            "True: 0.3462869249929549, Predicted: 0.2877035439014435\n",
            "True: 0.5586190371548804, Predicted: 0.6174136400222778\n",
            "True: 0.5390845634626795, Predicted: 0.49888113141059875\n",
            "True: 0.5169840374356431, Predicted: 0.6650394201278687\n",
            "True: 0.6190379165105564, Predicted: 0.8759711384773254\n",
            "True: 0.2254158611847807, Predicted: 0.22467532753944397\n",
            "True: 0.7084809839306503, Predicted: 0.9777874946594238\n",
            "True: 1.6147726322010545, Predicted: 1.9340351819992065\n",
            "True: 0.44701035879979956, Predicted: 0.5296630263328552\n",
            "True: 0.6025654476554595, Predicted: 0.5931281447410583\n",
            "True: 0.5309343759772696, Predicted: 0.620378851890564\n",
            "True: 0.6304568534858884, Predicted: 0.5264347791671753\n",
            "True: 0.5584492144049215, Predicted: 0.6263359189033508\n",
            "True: 0.6027132852528538, Predicted: 1.0225918292999268\n",
            "True: 0.40799685183466006, Predicted: 0.6443737149238586\n",
            "True: 0.6351587930393794, Predicted: 0.5686188340187073\n",
            "True: 0.39255237638781343, Predicted: 0.47820690274238586\n",
            "True: 1.1636328534317562, Predicted: 0.9630045294761658\n",
            "True: 0.406580000759409, Predicted: 0.3504100441932678\n",
            "True: 0.3399859260526826, Predicted: 0.3216416835784912\n",
            "True: 3.5792331183445762, Predicted: 3.284034490585327\n",
            "True: 0.5443153090458585, Predicted: 0.5378430485725403\n",
            "True: 0.5648422786754692, Predicted: 0.4955856204032898\n",
            "True: 0.5956192347434321, Predicted: 0.6204070448875427\n",
            "True: 3.98111803780072, Predicted: 4.840734004974365\n",
            "True: 0.5317901108312656, Predicted: 0.636486291885376\n",
            "True: 0.5530233442136157, Predicted: 0.4085354506969452\n",
            "True: 0.005018649712650877, Predicted: 0.05566274747252464\n",
            "True: 0.47334024774266154, Predicted: 0.5401774644851685\n",
            "True: 0.3261808137539814, Predicted: 0.3551784157752991\n",
            "True: 0.5497814895600651, Predicted: 0.5376847982406616\n",
            "True: 0.6869632451901988, Predicted: 0.7522699236869812\n",
            "True: 0.5349457269910716, Predicted: 0.5903544425964355\n",
            "True: 1.2111472607182456, Predicted: 1.3888784646987915\n",
            "True: 1.071220806251477, Predicted: 0.9026190638542175\n",
            "True: 0.16115016480062785, Predicted: 0.17376452684402466\n",
            "True: 0.4704861038996926, Predicted: 0.5815140008926392\n",
            "True: 0.5131818656232503, Predicted: 0.6260650753974915\n",
            "True: 0.6354547690070012, Predicted: 1.0074002742767334\n",
            "True: 1.5802320275005688, Predicted: 2.589759588241577\n",
            "True: 2.1410888612587535, Predicted: 2.117036819458008\n",
            "True: 0.5988361605215892, Predicted: 1.1857160329818726\n",
            "True: 0.4682948039291134, Predicted: 0.6158921122550964\n",
            "True: 0.5182735825034865, Predicted: 0.4252147674560547\n",
            "True: 0.5955890368484735, Predicted: 0.41141414642333984\n",
            "True: 1.0753221066736482, Predicted: 1.0499790906906128\n",
            "True: 0.531027603207394, Predicted: 0.5896134972572327\n",
            "True: 0.7128542354729969, Predicted: 0.8613784909248352\n",
            "True: 4.157204290792338, Predicted: 1.851047158241272\n",
            "True: 0.46984376016996443, Predicted: 0.5282981991767883\n",
            "True: 0.3520168090698665, Predicted: 0.34624332189559937\n",
            "True: 0.0030066338970676275, Predicted: 0.02153293415904045\n",
            "True: 0.5078993740149549, Predicted: 0.5428306460380554\n",
            "True: 0.48547483417278137, Predicted: 0.4013080596923828\n",
            "True: 0.5865718303194678, Predicted: 0.7186529636383057\n",
            "True: 1.3994067089982836, Predicted: 1.0612716674804688\n",
            "True: 2.5529600930906717, Predicted: 2.742025852203369\n",
            "True: 0.5848661340969626, Predicted: 0.42015835642814636\n",
            "True: 1.0738589176505626, Predicted: 0.8763670921325684\n",
            "True: 0.3752594783865661, Predicted: 0.39183923602104187\n",
            "True: 0.40710056826780344, Predicted: 0.26804330945014954\n",
            "True: 0.7111795162434519, Predicted: 0.5708277821540833\n",
            "True: 0.38295129303467557, Predicted: 0.5277159214019775\n",
            "True: 0.5011637471293104, Predicted: 0.5349324941635132\n",
            "True: 0.9853194004049903, Predicted: 1.858600378036499\n",
            "True: 0.34919655527658683, Predicted: 0.2770818769931793\n",
            "True: 0.5043972320592826, Predicted: 0.5138124823570251\n",
            "True: 0.4003664150703572, Predicted: 0.4222702383995056\n",
            "True: 0.5163612245137101, Predicted: 0.5524488091468811\n",
            "True: 0.5203827303302575, Predicted: 0.5649228096008301\n",
            "True: 0.6226265793908854, Predicted: 0.6612246632575989\n",
            "True: 0.6168529250283754, Predicted: 0.7052244544029236\n",
            "True: 0.525541717506945, Predicted: 0.5995456576347351\n",
            "True: 0.6229339376633912, Predicted: 0.6703732013702393\n",
            "True: 0.39693025734745446, Predicted: 0.054670240730047226\n",
            "True: 0.5197546131830914, Predicted: 0.48469632863998413\n",
            "True: 0.46334621518009383, Predicted: 0.43707484006881714\n",
            "True: 0.46849498073678375, Predicted: 0.46259167790412903\n",
            "True: 0.3948369906229112, Predicted: 0.36126092076301575\n",
            "True: 1.1223231051795364, Predicted: 0.9170196056365967\n",
            "True: 0.8923359629371589, Predicted: 0.4288950562477112\n",
            "True: 0.18784592863750443, Predicted: 0.17189282178878784\n",
            "True: 0.34390050945951944, Predicted: 0.3218896985054016\n",
            "True: 0.7354558899037368, Predicted: 0.6725897789001465\n",
            "True: 0.5068303247447268, Predicted: 0.48616549372673035\n",
            "True: 0.6015867051946128, Predicted: 0.5962327122688293\n",
            "True: 3.2138220506180835, Predicted: 1.0478066205978394\n",
            "True: 0.7444095893113067, Predicted: 0.6317458152770996\n",
            "True: 2.8804359914610367, Predicted: 2.231461524963379\n",
            "True: 0.3125670043081603, Predicted: 0.2819049656391144\n",
            "True: 0.1316926070633454, Predicted: 0.28924107551574707\n",
            "True: 0.4760445174475848, Predicted: 0.558339536190033\n",
            "True: 0.521397810691949, Predicted: 0.30433231592178345\n",
            "True: 0.5967962075877945, Predicted: 0.6791606545448303\n",
            "True: 0.7058135724288216, Predicted: 0.8226692080497742\n",
            "True: 0.18735624469349138, Predicted: 0.23808170855045319\n",
            "True: 0.8167587235765217, Predicted: 0.6310052275657654\n",
            "True: 0.7552900914169896, Predicted: 1.3773040771484375\n",
            "True: 0.35460476300199095, Predicted: 0.3500504493713379\n",
            "True: 0.9438723750393884, Predicted: 0.7528076767921448\n",
            "True: 0.475800411007348, Predicted: 0.45532163977622986\n",
            "True: 2.672595340003873, Predicted: 2.895861864089966\n",
            "True: 0.5491008514559714, Predicted: 0.6117991209030151\n",
            "True: 0.3752581014325554, Predicted: 0.3812999129295349\n",
            "True: 0.4596535176894643, Predicted: 0.3778977394104004\n",
            "True: 0.843653446082625, Predicted: 1.0608161687850952\n",
            "True: 3.8914179511566185, Predicted: 3.5030710697174072\n",
            "True: 0.7074752878937729, Predicted: 0.6103914380073547\n",
            "True: 0.19326960269017096, Predicted: 0.14508333802223206\n",
            "True: 0.6654615932144765, Predicted: 0.8209862112998962\n",
            "True: 0.33143294539862306, Predicted: 0.306379497051239\n",
            "True: 0.4608314968530211, Predicted: 0.5609848499298096\n",
            "True: 0.3615708731591389, Predicted: 0.43039005994796753\n",
            "True: 1.1789670649879471, Predicted: 1.015645146369934\n",
            "True: 0.4972549695882965, Predicted: 0.45027485489845276\n",
            "True: 0.47593142811024536, Predicted: 0.44191083312034607\n",
            "True: 0.0054497603380347865, Predicted: 0.08934615552425385\n",
            "True: 0.9102542258816745, Predicted: 0.7050458192825317\n",
            "True: 0.37695138728546324, Predicted: 0.4087868630886078\n",
            "True: 0.6068899561208037, Predicted: 0.783619225025177\n",
            "True: 1.5372976675715955, Predicted: 1.1848833560943604\n",
            "True: 0.6688507021557214, Predicted: 1.708997130393982\n",
            "True: 0.16327224273239482, Predicted: 0.17985281348228455\n",
            "True: 0.448769124197937, Predicted: 0.4602465033531189\n",
            "True: 0.5206520659922663, Predicted: 0.6223415732383728\n",
            "True: 0.5385356120464756, Predicted: 0.6368868947029114\n",
            "True: 0.5962179644015803, Predicted: 0.9119473099708557\n",
            "True: 1.5776933065467718, Predicted: 1.267526626586914\n",
            "True: 0.6554701980476372, Predicted: 0.6014910340309143\n",
            "True: 0.4127350695879768, Predicted: 0.3202959895133972\n",
            "True: 2.7191990263418235, Predicted: 2.969010353088379\n",
            "True: 0.006966256910859557, Predicted: -0.10454273223876953\n",
            "True: 1.9430816754909255, Predicted: 2.7873694896698\n",
            "True: 0.005179657608992576, Predicted: 0.14060544967651367\n",
            "True: 0.4927602398535579, Predicted: 0.5156094431877136\n",
            "True: 0.4077012082073199, Predicted: 0.405938982963562\n",
            "True: 0.5113666826418796, Predicted: 0.4578450322151184\n",
            "True: 0.5234989042682543, Predicted: 0.48957526683807373\n",
            "True: 0.6238556083952549, Predicted: 0.7883885502815247\n",
            "True: 2.8598155652471675, Predicted: 2.8244714736938477\n",
            "True: 0.5726988184307397, Predicted: 0.580230176448822\n",
            "True: 0.891251886208861, Predicted: 0.413531094789505\n",
            "True: 2.197668344040642, Predicted: 2.416792869567871\n",
            "True: 3.5016059982620193, Predicted: 2.978449583053589\n",
            "True: 0.5813322900207085, Predicted: 0.6337288618087769\n",
            "True: 0.448063289759941, Predicted: 0.46863141655921936\n",
            "True: 0.7291589367497857, Predicted: 0.6531623005867004\n",
            "True: 1.476135422053748, Predicted: 1.4145982265472412\n",
            "True: 0.8488120340440543, Predicted: 0.6807827949523926\n",
            "True: 0.9744279467459542, Predicted: 1.0672245025634766\n",
            "True: 0.5962173804977966, Predicted: 0.8792573809623718\n",
            "True: 0.5007403699717118, Predicted: 0.3374480605125427\n",
            "True: 0.5643646963510478, Predicted: 0.6434445977210999\n",
            "True: 0.5673890654957199, Predicted: 0.6279406547546387\n",
            "True: 0.6107577361125615, Predicted: 0.31475213170051575\n",
            "True: 0.3965871881339581, Predicted: 0.3866209387779236\n",
            "True: 0.5989043582801681, Predicted: 0.19622203707695007\n",
            "True: 0.008037997243595892, Predicted: -0.37271928787231445\n",
            "True: 0.006102619577323208, Predicted: 0.3618537187576294\n",
            "True: 0.5784453912958065, Predicted: 0.648620069026947\n",
            "True: 0.4090499589927471, Predicted: 0.4377552270889282\n",
            "True: 3.960113290091421, Predicted: 3.375054121017456\n",
            "True: 0.46026496554561175, Predicted: 0.34689250588417053\n",
            "True: 0.470733526610215, Predicted: 0.4612998366355896\n",
            "True: 0.7264296742449678, Predicted: 0.7413303256034851\n",
            "True: 0.28491284014886736, Predicted: 0.35892802476882935\n",
            "True: 0.0071511361637617565, Predicted: -0.0034322328865528107\n",
            "True: 0.8963499435522967, Predicted: 0.8703394532203674\n",
            "True: 3.538136518325004, Predicted: 3.1326823234558105\n",
            "True: 0.5119412439278836, Predicted: 0.6294732689857483\n",
            "True: 0.5602086375594613, Predicted: 0.6189365386962891\n",
            "True: 0.7267605206197338, Predicted: 0.6161009669303894\n",
            "True: 0.5336038309409923, Predicted: 0.4581730365753174\n",
            "True: 3.682172754719707, Predicted: 4.121590614318848\n",
            "True: 3.301950087110185, Predicted: 3.874753952026367\n",
            "True: 0.3619583903209908, Predicted: 0.23381678760051727\n",
            "True: 0.8797346592753317, Predicted: 0.9947763085365295\n",
            "True: 0.3866075619674395, Predicted: 0.3234596252441406\n",
            "True: 0.44800107858626753, Predicted: 0.5245905518531799\n",
            "True: 0.10821256136601773, Predicted: 0.17160336673259735\n",
            "True: 0.5482439257226331, Predicted: 0.5923544764518738\n",
            "True: 0.5210917933938366, Predicted: 0.5064516067504883\n",
            "True: 0.4800378660747556, Predicted: 0.6113993525505066\n",
            "True: 1.422306654469969, Predicted: 1.3712738752365112\n",
            "True: 1.8127033542235635, Predicted: 1.779198408126831\n",
            "True: 0.5112533074744269, Predicted: 0.6927081346511841\n",
            "True: 0.6271080578807635, Predicted: 0.47767892479896545\n",
            "True: 0.3379623690950358, Predicted: 0.8427460789680481\n",
            "True: 0.4745513989891442, Predicted: 0.6566323041915894\n",
            "True: 0.502074662613169, Predicted: 0.5892260670661926\n",
            "True: 0.5599513322089322, Predicted: 0.589426577091217\n",
            "True: 1.7994781067480479, Predicted: 0.3230852782726288\n",
            "True: 1.489668581198676, Predicted: 1.2858039140701294\n",
            "True: 0.8204007805829351, Predicted: 0.7204580903053284\n",
            "True: 0.72351139792817, Predicted: 0.8472781777381897\n",
            "True: 1.5590491039929246, Predicted: 2.1505978107452393\n",
            "True: 0.3374721493373578, Predicted: 0.18868839740753174\n",
            "True: 0.3658708611084559, Predicted: 0.48406216502189636\n",
            "True: 0.540075001274014, Predicted: 0.5445098876953125\n",
            "True: 2.3925870109568144, Predicted: 2.672912120819092\n",
            "True: 0.2752193289940888, Predicted: 0.10882295668125153\n",
            "True: 0.003450789291310434, Predicted: 0.18602582812309265\n",
            "True: 0.12036224429586317, Predicted: 0.2010709047317505\n",
            "True: 0.6464920172407943, Predicted: 0.5622996091842651\n",
            "True: 0.6908210462593407, Predicted: 0.5442578792572021\n",
            "True: 2.273148037789624, Predicted: 2.3323605060577393\n",
            "True: 0.4945764065327153, Predicted: 0.5890650153160095\n",
            "True: 0.2225576682405711, Predicted: 0.22652938961982727\n",
            "True: 0.5697367273730228, Predicted: 0.16415385901927948\n",
            "True: 0.5454741446870325, Predicted: 0.37571126222610474\n",
            "True: 0.5558939145519897, Predicted: 0.40597835183143616\n",
            "True: 0.4378575896515877, Predicted: 0.35164421796798706\n",
            "True: 0.5151545498184201, Predicted: 0.6070356965065002\n",
            "True: 0.5542778166071753, Predicted: 0.639948844909668\n",
            "True: 0.6599962079721712, Predicted: 0.6297489404678345\n",
            "True: 0.2914887652060093, Predicted: 0.39959877729415894\n",
            "True: 0.5589837038905836, Predicted: 1.0550142526626587\n",
            "True: 0.52843666314775, Predicted: 0.4553813338279724\n",
            "True: 0.8113528750979347, Predicted: 0.8318104147911072\n",
            "True: 1.3869325057956703, Predicted: 1.4160078763961792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_weights('cage_metric_model.ckpt')\n",
        "model.save('model_varyingGoal_cutoffLabels.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jrlkc1pZs9Z",
        "outputId": "b9eb3caa-8baa-4e89-b69a-30c5b539f4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the entire model\n",
        "new_model = load_model('path_to_my_model.h5')\n",
        "\n",
        "# Use the model for inference\n",
        "i = (X_test[0:1]).tolist()\n",
        "print(i)\n",
        "prediction = new_model.predict(i)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEer6ssAafeO",
        "outputId": "f48aaf4e-cb7e-4812-fea4-be9d5e316e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.6385281345710567, -0.5092962134283774, 0.08382842145923423, -0.13254497591122066, -1.5364387572726412, -0.4886458616509667, 0.003567941207741127, 1.4215608118319583, 0.023628152616274812, -0.3700396101036746]]\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "[[1.4909074]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TORCH"
      ],
      "metadata": {
        "id": "Dz2YtNA-rmA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ],
      "metadata": {
        "id": "qsPLUJLtruO8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_size = 128\n",
        "\n",
        "# Training loop\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    total_loss = 0\n",
        "    num_batch = len(dataloader)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y.unsqueeze(1))\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / batch\n",
        "\n",
        "def val_loop(dataloader, model, loss_fn):\n",
        "    num_batch = len(dataloader)\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y.unsqueeze(1))\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / num_batch\n",
        "\n",
        "# Define the model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(12, layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_size, layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_size, layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_size, layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(layer_size, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_relu_stack(x)\n"
      ],
      "metadata": {
        "id": "lWTf4Ml2shTD"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'inputs' and 'labels' are your data\n",
        "# labels = [[s,m] for s,m in zip(success_labels, maneuver_labels)]\n",
        "labels = success_labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.15, random_state=42)\n",
        "\n",
        "# # Min-Max Scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_train = min_max_scaler.fit_transform(X_train)\n",
        "X_test = min_max_scaler.transform(X_test)\n",
        "joblib.dump(min_max_scaler, 'scaler_minmax.pkl')\n",
        "\n",
        "# Standardization\n",
        "# standard_scaler = StandardScaler()\n",
        "# X_train = standard_scaler.fit_transform(X_train)\n",
        "# X_test = standard_scaler.transform(X_test)\n",
        "# joblib.dump(min_max_scaler, 'scaler_standard.pkl')\n"
      ],
      "metadata": {
        "id": "rlv06qozsHQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963e3ea9-1021-4ae3-9cad-9aa9c3431e2a"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler_minmax.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Convert arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = NeuralNetwork()\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "learning_rate = 3e-5\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.MSELoss()\n"
      ],
      "metadata": {
        "id": "bT_W1AD0rpVI"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_loop(train_loader, model, loss_fn, optimizer)\n",
        "    val_loss = val_loop(val_loader, model, loss_fn)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
        "    print(f\"Training Loss: {train_loss:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\\n\")"
      ],
      "metadata": {
        "id": "BuABwP_b_xrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943a6eff-cda7-4ffc-cd5f-e3c62dfe1866"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Training Loss: 0.1227\n",
            "Validation Loss: 0.1010\n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Training Loss: 0.0720\n",
            "Validation Loss: 0.0582\n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Training Loss: 0.0503\n",
            "Validation Loss: 0.0487\n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Training Loss: 0.0421\n",
            "Validation Loss: 0.0404\n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Training Loss: 0.0356\n",
            "Validation Loss: 0.0342\n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Training Loss: 0.0301\n",
            "Validation Loss: 0.0290\n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Training Loss: 0.0259\n",
            "Validation Loss: 0.0253\n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Training Loss: 0.0229\n",
            "Validation Loss: 0.0225\n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Training Loss: 0.0205\n",
            "Validation Loss: 0.0202\n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Training Loss: 0.0185\n",
            "Validation Loss: 0.0186\n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Training Loss: 0.0170\n",
            "Validation Loss: 0.0176\n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Training Loss: 0.0156\n",
            "Validation Loss: 0.0163\n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Training Loss: 0.0145\n",
            "Validation Loss: 0.0151\n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Training Loss: 0.0137\n",
            "Validation Loss: 0.0141\n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Training Loss: 0.0129\n",
            "Validation Loss: 0.0140\n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Training Loss: 0.0122\n",
            "Validation Loss: 0.0130\n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Training Loss: 0.0117\n",
            "Validation Loss: 0.0129\n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Training Loss: 0.0112\n",
            "Validation Loss: 0.0121\n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Training Loss: 0.0108\n",
            "Validation Loss: 0.0117\n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Training Loss: 0.0104\n",
            "Validation Loss: 0.0124\n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Training Loss: 0.0101\n",
            "Validation Loss: 0.0116\n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Training Loss: 0.0099\n",
            "Validation Loss: 0.0110\n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Training Loss: 0.0096\n",
            "Validation Loss: 0.0112\n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Training Loss: 0.0095\n",
            "Validation Loss: 0.0105\n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Training Loss: 0.0092\n",
            "Validation Loss: 0.0104\n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Training Loss: 0.0091\n",
            "Validation Loss: 0.0102\n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Training Loss: 0.0089\n",
            "Validation Loss: 0.0100\n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Training Loss: 0.0087\n",
            "Validation Loss: 0.0099\n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Training Loss: 0.0086\n",
            "Validation Loss: 0.0098\n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "Training Loss: 0.0085\n",
            "Validation Loss: 0.0097\n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "Training Loss: 0.0083\n",
            "Validation Loss: 0.0097\n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "Training Loss: 0.0082\n",
            "Validation Loss: 0.0096\n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "Training Loss: 0.0081\n",
            "Validation Loss: 0.0096\n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "Training Loss: 0.0079\n",
            "Validation Loss: 0.0091\n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "Training Loss: 0.0079\n",
            "Validation Loss: 0.0089\n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "Training Loss: 0.0078\n",
            "Validation Loss: 0.0090\n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "Training Loss: 0.0077\n",
            "Validation Loss: 0.0101\n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "Training Loss: 0.0076\n",
            "Validation Loss: 0.0092\n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "Training Loss: 0.0076\n",
            "Validation Loss: 0.0096\n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "Training Loss: 0.0075\n",
            "Validation Loss: 0.0087\n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "Training Loss: 0.0073\n",
            "Validation Loss: 0.0085\n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "Training Loss: 0.0075\n",
            "Validation Loss: 0.0085\n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "Training Loss: 0.0073\n",
            "Validation Loss: 0.0085\n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "Training Loss: 0.0073\n",
            "Validation Loss: 0.0084\n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "Training Loss: 0.0073\n",
            "Validation Loss: 0.0086\n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "Training Loss: 0.0072\n",
            "Validation Loss: 0.0082\n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "Training Loss: 0.0070\n",
            "Validation Loss: 0.0085\n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "Training Loss: 0.0070\n",
            "Validation Loss: 0.0082\n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "Training Loss: 0.0070\n",
            "Validation Loss: 0.0091\n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "Training Loss: 0.0069\n",
            "Validation Loss: 0.0081\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a plot of training and validation losses\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "ax = fig.add_subplot()\n",
        "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\")\n",
        "plt.plot(range(1, epochs + 1), val_losses, label=\"Validation Loss\")\n",
        "ax.set_yscale('log')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "4GmZLaGWd4mv",
        "outputId": "83608497-a048-4fb7-e9ff-0424736fd2e2"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_tensor)\n",
        "    test_loss = loss_fn(y_pred, y_test_tensor).item()\n",
        "    print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model_11k.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOQLkQuuygek",
        "outputId": "f0c09c38-9b3d-4feb-9932-91984a05e953"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.2334563136100769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1707])) that is different to the input size (torch.Size([1707, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print true and predicted values\n",
        "for true, pred in zip(y_test[:100], y_pred.tolist()[:100]):\n",
        "    print(f\"True: {true}, Predicted: {pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jsimULgsfGF",
        "outputId": "86cdc87c-4e01-4e4e-d042-c3263b5901d3"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True: 0.09501648334557618, Predicted: [0.12087370455265045]\n",
            "True: 1.1702300156168265e-11, Predicted: [-0.010196041315793991]\n",
            "True: 0.0, Predicted: [-0.0067215003073215485]\n",
            "True: 4.720007476675832e-05, Predicted: [-0.003118019551038742]\n",
            "True: 0.023287717772783965, Predicted: [0.03565071150660515]\n",
            "True: 0.0, Predicted: [-0.051439907401800156]\n",
            "True: 0.0, Predicted: [-0.018868248909711838]\n",
            "True: 0.0, Predicted: [-0.00734793022274971]\n",
            "True: 4.03199003735671e-11, Predicted: [-0.008567478507757187]\n",
            "True: 3.821138289710384e-08, Predicted: [-0.007883157581090927]\n",
            "True: 0.763437781905207, Predicted: [0.5751135349273682]\n",
            "True: 0.0, Predicted: [-0.005150366574525833]\n",
            "True: 0.5044446776319355, Predicted: [0.4770084619522095]\n",
            "True: 7.440086685681769e-09, Predicted: [-0.033794548362493515]\n",
            "True: 0.04272308665047889, Predicted: [0.11257430911064148]\n",
            "True: 0.3059998462526766, Predicted: [0.10276058316230774]\n",
            "True: 0.0, Predicted: [0.04548525810241699]\n",
            "True: 0.08782566794397852, Predicted: [0.02412785217165947]\n",
            "True: 0.4459828155837875, Predicted: [0.20400550961494446]\n",
            "True: 0.9927122802735966, Predicted: [0.8732120990753174]\n",
            "True: 6.273156657473323e-13, Predicted: [-0.009450387209653854]\n",
            "True: 3.0752935501895727e-10, Predicted: [-0.007818277925252914]\n",
            "True: 5.5030820031391356e-05, Predicted: [0.006713036447763443]\n",
            "True: 0.0, Predicted: [-0.009676557034254074]\n",
            "True: 0.19726192659762015, Predicted: [0.09189246594905853]\n",
            "True: 0.0, Predicted: [-0.005211357027292252]\n",
            "True: 1.5895842833726834e-09, Predicted: [-0.006789427250623703]\n",
            "True: 0.0, Predicted: [-0.0016156546771526337]\n",
            "True: 0.1881199662331589, Predicted: [0.1530844122171402]\n",
            "True: 0.0007474235343835579, Predicted: [-0.0013736598193645477]\n",
            "True: 0.0, Predicted: [0.0031419433653354645]\n",
            "True: 6.855759259440951e-10, Predicted: [-0.011166464537382126]\n",
            "True: 0.041672338992536744, Predicted: [0.0778454840183258]\n",
            "True: 8.918497978324385e-05, Predicted: [-0.05018879100680351]\n",
            "True: 0.0, Predicted: [0.003337562084197998]\n",
            "True: 0.8434170240517614, Predicted: [0.8542272448539734]\n",
            "True: 0.5576049275738598, Predicted: [0.4667954444885254]\n",
            "True: 0.4116017093057395, Predicted: [0.4093371033668518]\n",
            "True: 0.0, Predicted: [-0.00651409849524498]\n",
            "True: 0.0, Predicted: [-0.028776686638593674]\n",
            "True: 0.0, Predicted: [-0.02527136728167534]\n",
            "True: 0.0, Predicted: [0.004429135471582413]\n",
            "True: 0.0, Predicted: [-0.005004283040761948]\n",
            "True: 0.832968684479052, Predicted: [0.8489643335342407]\n",
            "True: 2.1114038047805258e-05, Predicted: [-0.02947458252310753]\n",
            "True: 1.5568706371708436e-11, Predicted: [-0.007620837539434433]\n",
            "True: 0.0, Predicted: [-0.005763348191976547]\n",
            "True: 0.0, Predicted: [-0.00539768859744072]\n",
            "True: 0.1970437724296573, Predicted: [0.305654913187027]\n",
            "True: 0.0, Predicted: [-0.007087152451276779]\n",
            "True: 0.9230158843440479, Predicted: [0.8249533176422119]\n",
            "True: 8.014042275936572e-10, Predicted: [-0.007097315043210983]\n",
            "True: 0.8943215940877989, Predicted: [0.6253154277801514]\n",
            "True: 8.843342539588638e-07, Predicted: [-0.0017648674547672272]\n",
            "True: 0.9470057718750919, Predicted: [0.5845175385475159]\n",
            "True: 0.9088446856686554, Predicted: [0.8183942437171936]\n",
            "True: 0.9196342609272897, Predicted: [0.8627683520317078]\n",
            "True: 2.557894704260794e-10, Predicted: [-0.009190570563077927]\n",
            "True: 0.8470476601021638, Predicted: [0.8102831840515137]\n",
            "True: 2.6577499650083632e-09, Predicted: [-0.007663648575544357]\n",
            "True: 0.0, Predicted: [-0.007320243865251541]\n",
            "True: 1.0, Predicted: [0.8936652541160583]\n",
            "True: 0.6322808202792254, Predicted: [0.40743646025657654]\n",
            "True: 6.839102340385514e-11, Predicted: [-0.0062949322164058685]\n",
            "True: 0.7808161489720525, Predicted: [0.7083143591880798]\n",
            "True: 1.5738556080976766e-15, Predicted: [-0.00468951091170311]\n",
            "True: 7.285546974731237e-07, Predicted: [-0.0033331625163555145]\n",
            "True: 4.677544983455982e-10, Predicted: [-0.013089250773191452]\n",
            "True: 0.0, Predicted: [-0.008752752095460892]\n",
            "True: 7.183954367872837e-10, Predicted: [-0.004699084907770157]\n",
            "True: 4.347512207938431e-05, Predicted: [0.002508174628019333]\n",
            "True: 0.0, Predicted: [-0.006377425044775009]\n",
            "True: 0.002444301193501627, Predicted: [0.1638817936182022]\n",
            "True: 0.9110259881442452, Predicted: [0.7538881897926331]\n",
            "True: 0.0016181084829003732, Predicted: [0.024963077157735825]\n",
            "True: 2.6425309522472287e-06, Predicted: [-0.002365242689847946]\n",
            "True: 4.065128279816067e-11, Predicted: [-0.009746532887220383]\n",
            "True: 0.2345435383661267, Predicted: [0.1599721908569336]\n",
            "True: 0.9651956217903385, Predicted: [0.8118435740470886]\n",
            "True: 1.1403786755861632e-10, Predicted: [-0.009178902953863144]\n",
            "True: 0.12277797467698265, Predicted: [0.107784703373909]\n",
            "True: 0.0, Predicted: [-0.01012241467833519]\n",
            "True: 0.0, Predicted: [0.0363704152405262]\n",
            "True: 4.1346826258813295e-05, Predicted: [-0.0024491436779499054]\n",
            "True: 1.0738949416860704e-10, Predicted: [-0.013401631265878677]\n",
            "True: 0.0, Predicted: [-0.005374085158109665]\n",
            "True: 2.190486094524266e-09, Predicted: [-0.008518021553754807]\n",
            "True: 0.8371657105042054, Predicted: [0.861146092414856]\n",
            "True: 9.55440523378409e-09, Predicted: [-0.0066741593182086945]\n",
            "True: 0.0, Predicted: [-0.0071114785969257355]\n",
            "True: 0.5665149777640033, Predicted: [0.7829747796058655]\n",
            "True: 0.8020793829821066, Predicted: [0.4209415912628174]\n",
            "True: 0.3260935758970891, Predicted: [0.3097994327545166]\n",
            "True: 0.009242887696115552, Predicted: [0.018854402005672455]\n",
            "True: 0.8474421421948678, Predicted: [0.9503524899482727]\n",
            "True: 0.0, Predicted: [-0.006410133093595505]\n",
            "True: 1.1110081837803273e-05, Predicted: [-0.01013566181063652]\n",
            "True: 1.1862449292267323e-05, Predicted: [-0.012510668486356735]\n",
            "True: 0.0, Predicted: [-0.0036566145718097687]\n",
            "True: 0.09378353921943548, Predicted: [0.1541980654001236]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2D Output Torch"
      ],
      "metadata": {
        "id": "dsSn7wnjgVOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "\n",
        "# Define the model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(12, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2)  # Output layer for 2D output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_relu_stack(x)\n",
        "\n",
        "# Assuming 'inputs' and 'labels' are your data\n",
        "# labels should be a list of lists with 2 elements each, for example: [[output1, output2], ...]\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "labels = [[s,m] for s,m in zip(success_labels, maneuver_labels)]\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.15, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Min-Max Scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_train = min_max_scaler.fit_transform(X_train)\n",
        "X_test = min_max_scaler.transform(X_test)\n",
        "X_val = min_max_scaler.transform(X_val)\n",
        "joblib.dump(min_max_scaler, 'scaler_minmax.pkl')\n",
        "\n",
        "# Convert arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = NeuralNetwork()\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "learning_rate = 1e-4  # Adjusted learning rate\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.MSELoss()  # Mean Squared Error Loss for regression\n",
        "\n",
        "# Training and validation loops\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    total_loss = 0\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def val_loop(dataloader, model, loss_fn):\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Training process\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_loop(train_loader, model, loss_fn, optimizer)\n",
        "    val_loss = val_loop(val_loader, model, loss_fn)\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    print(f\"Training Loss: {train_loss:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_tensor)\n",
        "    test_loss = loss_fn(y_pred, y_test_tensor).item()\n",
        "    print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model_12d_2d_outputs.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-Mpc_EogXsX",
        "outputId": "b5250bf4-8e4f-4d76-f15b-515cad10ccd0"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Training Loss: 0.1810\n",
            "Validation Loss: 0.1279\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Training Loss: 0.1146\n",
            "Validation Loss: 0.1066\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Training Loss: 0.1004\n",
            "Validation Loss: 0.0978\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Training Loss: 0.0941\n",
            "Validation Loss: 0.0926\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Training Loss: 0.0901\n",
            "Validation Loss: 0.0891\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Training Loss: 0.0872\n",
            "Validation Loss: 0.0863\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Training Loss: 0.0847\n",
            "Validation Loss: 0.0848\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Training Loss: 0.0827\n",
            "Validation Loss: 0.0826\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Training Loss: 0.0810\n",
            "Validation Loss: 0.0810\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Training Loss: 0.0792\n",
            "Validation Loss: 0.0793\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Training Loss: 0.0775\n",
            "Validation Loss: 0.0774\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Training Loss: 0.0756\n",
            "Validation Loss: 0.0760\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Training Loss: 0.0740\n",
            "Validation Loss: 0.0744\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Training Loss: 0.0723\n",
            "Validation Loss: 0.0724\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Training Loss: 0.0705\n",
            "Validation Loss: 0.0708\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Training Loss: 0.0689\n",
            "Validation Loss: 0.0700\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Training Loss: 0.0672\n",
            "Validation Loss: 0.0691\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Training Loss: 0.0658\n",
            "Validation Loss: 0.0668\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Training Loss: 0.0641\n",
            "Validation Loss: 0.0654\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Training Loss: 0.0626\n",
            "Validation Loss: 0.0638\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Training Loss: 0.0610\n",
            "Validation Loss: 0.0632\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Training Loss: 0.0598\n",
            "Validation Loss: 0.0612\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Training Loss: 0.0585\n",
            "Validation Loss: 0.0600\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Training Loss: 0.0572\n",
            "Validation Loss: 0.0591\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Training Loss: 0.0561\n",
            "Validation Loss: 0.0573\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Training Loss: 0.0550\n",
            "Validation Loss: 0.0571\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Training Loss: 0.0539\n",
            "Validation Loss: 0.0559\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Training Loss: 0.0530\n",
            "Validation Loss: 0.0549\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Training Loss: 0.0524\n",
            "Validation Loss: 0.0548\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "Training Loss: 0.0513\n",
            "Validation Loss: 0.0539\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "Training Loss: 0.0504\n",
            "Validation Loss: 0.0529\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "Training Loss: 0.0496\n",
            "Validation Loss: 0.0519\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "Training Loss: 0.0489\n",
            "Validation Loss: 0.0512\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "Training Loss: 0.0481\n",
            "Validation Loss: 0.0508\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "Training Loss: 0.0476\n",
            "Validation Loss: 0.0500\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "Training Loss: 0.0467\n",
            "Validation Loss: 0.0492\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "Training Loss: 0.0462\n",
            "Validation Loss: 0.0485\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "Training Loss: 0.0455\n",
            "Validation Loss: 0.0484\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "Training Loss: 0.0450\n",
            "Validation Loss: 0.0482\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "Training Loss: 0.0444\n",
            "Validation Loss: 0.0470\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "Training Loss: 0.0439\n",
            "Validation Loss: 0.0467\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "Training Loss: 0.0435\n",
            "Validation Loss: 0.0458\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "Training Loss: 0.0430\n",
            "Validation Loss: 0.0457\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "Training Loss: 0.0425\n",
            "Validation Loss: 0.0454\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "Training Loss: 0.0420\n",
            "Validation Loss: 0.0449\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "Training Loss: 0.0416\n",
            "Validation Loss: 0.0446\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "Training Loss: 0.0412\n",
            "Validation Loss: 0.0439\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "Training Loss: 0.0407\n",
            "Validation Loss: 0.0436\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "Training Loss: 0.0403\n",
            "Validation Loss: 0.0428\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "Training Loss: 0.0400\n",
            "Validation Loss: 0.0424\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "Training Loss: 0.0397\n",
            "Validation Loss: 0.0421\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "Training Loss: 0.0392\n",
            "Validation Loss: 0.0421\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "Training Loss: 0.0390\n",
            "Validation Loss: 0.0411\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "Training Loss: 0.0385\n",
            "Validation Loss: 0.0409\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "Training Loss: 0.0382\n",
            "Validation Loss: 0.0403\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "Training Loss: 0.0376\n",
            "Validation Loss: 0.0407\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "Training Loss: 0.0374\n",
            "Validation Loss: 0.0396\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "Training Loss: 0.0370\n",
            "Validation Loss: 0.0394\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "Training Loss: 0.0367\n",
            "Validation Loss: 0.0390\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "Training Loss: 0.0364\n",
            "Validation Loss: 0.0383\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "Training Loss: 0.0361\n",
            "Validation Loss: 0.0380\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "Training Loss: 0.0358\n",
            "Validation Loss: 0.0377\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "Training Loss: 0.0355\n",
            "Validation Loss: 0.0380\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "Training Loss: 0.0351\n",
            "Validation Loss: 0.0372\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "Training Loss: 0.0349\n",
            "Validation Loss: 0.0369\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "Training Loss: 0.0345\n",
            "Validation Loss: 0.0364\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "Training Loss: 0.0344\n",
            "Validation Loss: 0.0371\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "Training Loss: 0.0340\n",
            "Validation Loss: 0.0363\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "Training Loss: 0.0338\n",
            "Validation Loss: 0.0356\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "Training Loss: 0.0335\n",
            "Validation Loss: 0.0356\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "Training Loss: 0.0334\n",
            "Validation Loss: 0.0350\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "Training Loss: 0.0330\n",
            "Validation Loss: 0.0349\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "Training Loss: 0.0329\n",
            "Validation Loss: 0.0349\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "Training Loss: 0.0328\n",
            "Validation Loss: 0.0346\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "Training Loss: 0.0325\n",
            "Validation Loss: 0.0342\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "Training Loss: 0.0321\n",
            "Validation Loss: 0.0339\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "Training Loss: 0.0319\n",
            "Validation Loss: 0.0336\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "Training Loss: 0.0318\n",
            "Validation Loss: 0.0334\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "Training Loss: 0.0315\n",
            "Validation Loss: 0.0333\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "Training Loss: 0.0312\n",
            "Validation Loss: 0.0330\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "Training Loss: 0.0310\n",
            "Validation Loss: 0.0325\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "Training Loss: 0.0308\n",
            "Validation Loss: 0.0323\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "Training Loss: 0.0305\n",
            "Validation Loss: 0.0332\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "Training Loss: 0.0303\n",
            "Validation Loss: 0.0322\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "Training Loss: 0.0303\n",
            "Validation Loss: 0.0323\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "Training Loss: 0.0301\n",
            "Validation Loss: 0.0315\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "Training Loss: 0.0297\n",
            "Validation Loss: 0.0314\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "Training Loss: 0.0296\n",
            "Validation Loss: 0.0313\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "Training Loss: 0.0294\n",
            "Validation Loss: 0.0311\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "Training Loss: 0.0292\n",
            "Validation Loss: 0.0308\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "Training Loss: 0.0290\n",
            "Validation Loss: 0.0314\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "Training Loss: 0.0291\n",
            "Validation Loss: 0.0306\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "Training Loss: 0.0287\n",
            "Validation Loss: 0.0309\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "Training Loss: 0.0287\n",
            "Validation Loss: 0.0301\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "Training Loss: 0.0283\n",
            "Validation Loss: 0.0300\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "Training Loss: 0.0284\n",
            "Validation Loss: 0.0298\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "Training Loss: 0.0282\n",
            "Validation Loss: 0.0297\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "Training Loss: 0.0281\n",
            "Validation Loss: 0.0294\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "Training Loss: 0.0278\n",
            "Validation Loss: 0.0296\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "Training Loss: 0.0276\n",
            "Validation Loss: 0.0297\n",
            "Test Loss: 0.029725832864642143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print true and predicted values\n",
        "for true, pred in zip(y_test[:100], y_pred.tolist()[:100]):\n",
        "    print(f\"True: {true}, Predicted: {pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3iWCmYQhIvw",
        "outputId": "4b3df316-f1e5-439f-d514-4d6c426ff16c"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True: [0.09501648334557618, 0.0012889564494493744], Predicted: [0.15320418775081635, 0.07646520435810089]\n",
            "True: [1.1702300156168265e-11, 3.317802932389924e-06], Predicted: [0.015720367431640625, -0.14048835635185242]\n",
            "True: [0.0, 0.019683619611884917], Predicted: [0.006691277027130127, 0.03609835356473923]\n",
            "True: [4.720007476675832e-05, 0.9631333004290005], Predicted: [0.004870429635047913, 0.8843719959259033]\n",
            "True: [0.023287717772783965, 0.0001713807219289043], Predicted: [0.075232595205307, -0.1660510152578354]\n",
            "True: [0.0, 0.0012074386599433273], Predicted: [-0.029554422944784164, 0.050232455134391785]\n",
            "True: [0.0, 0.024980503732990877], Predicted: [0.018257275223731995, 0.5167405009269714]\n",
            "True: [0.0, 0.9374072105461859], Predicted: [-0.013145670294761658, 0.5447877645492554]\n",
            "True: [4.03199003735671e-11, 0.9373963963658175], Predicted: [0.00012404471635818481, 0.5831563472747803]\n",
            "True: [3.821138289710384e-08, 0.7571510999348037], Predicted: [-0.004897505044937134, 0.5815176963806152]\n",
            "True: [0.763437781905207, 0.03264843294401698], Predicted: [0.6060771346092224, 0.13956782221794128]\n",
            "True: [0.0, 0.035287463400019536], Predicted: [-0.0005955547094345093, 0.10372859984636307]\n",
            "True: [0.5044446776319355, 4.145911960262705e-05], Predicted: [0.5099803805351257, -0.029437504708766937]\n",
            "True: [7.440086685681769e-09, 0.0], Predicted: [0.018830493092536926, -0.17943021655082703]\n",
            "True: [0.04272308665047889, 3.435204711299544e-05], Predicted: [0.132859468460083, -0.021866604685783386]\n",
            "True: [0.3059998462526766, 0.5931760099196344], Predicted: [0.10409614443778992, 0.8359329104423523]\n",
            "True: [0.0, 3.681743116312752e-05], Predicted: [0.08438482880592346, 0.01448550820350647]\n",
            "True: [0.08782566794397852, 0.9494021084699926], Predicted: [0.05379171669483185, 0.9056153297424316]\n",
            "True: [0.4459828155837875, 0.7853850024350078], Predicted: [0.3929438591003418, 0.5368260145187378]\n",
            "True: [0.9927122802735966, 0.9919106065309453], Predicted: [0.9507205486297607, 0.8360663056373596]\n",
            "True: [6.273156657473323e-13, 0.05665914719495868], Predicted: [0.002990156412124634, 0.14659345149993896]\n",
            "True: [3.0752935501895727e-10, 0.019795452015148762], Predicted: [-0.0008658692240715027, 0.1031971126794815]\n",
            "True: [5.5030820031391356e-05, 0.8886608179862963], Predicted: [0.034281790256500244, 0.7698927521705627]\n",
            "True: [0.0, 0.947079036636839], Predicted: [0.009004287421703339, 0.8025401830673218]\n",
            "True: [0.19726192659762015, 0.0018596972855243754], Predicted: [0.1506320685148239, 0.0003781616687774658]\n",
            "True: [0.0, 4.3894735726968115e-05], Predicted: [0.017493106424808502, -0.17190642654895782]\n",
            "True: [1.5895842833726834e-09, 8.457603842226824e-05], Predicted: [0.01856706291437149, -0.151719868183136]\n",
            "True: [0.0, 0.03110760631448639], Predicted: [0.0019431933760643005, 0.16817772388458252]\n",
            "True: [0.1881199662331589, 0.193883110929012], Predicted: [0.1437169909477234, 0.25719189643859863]\n",
            "True: [0.0007474235343835579, 0.47657373902254263], Predicted: [-0.0016491562128067017, 0.7570732831954956]\n",
            "True: [0.0, 0.0003450070272094097], Predicted: [0.022576019167900085, -0.017217345535755157]\n",
            "True: [6.855759259440951e-10, 0.8281907770260047], Predicted: [0.015636049211025238, 0.6808396577835083]\n",
            "True: [0.041672338992536744, 0.0747055585655998], Predicted: [0.06314946711063385, 0.1296437382698059]\n",
            "True: [8.918497978324385e-05, 0.8467550374112], Predicted: [-0.02202805131673813, 0.5687115788459778]\n",
            "True: [0.0, 0.0011961152075864456], Predicted: [0.02345152199268341, -0.014607250690460205]\n",
            "True: [0.8434170240517614, 0.09640634217166866], Predicted: [0.8920440077781677, 0.4375193119049072]\n",
            "True: [0.5576049275738598, 7.09889691731247e-05], Predicted: [0.5105183124542236, -0.03744620829820633]\n",
            "True: [0.4116017093057395, 3.811502113926224e-09], Predicted: [0.32411009073257446, 0.07084223628044128]\n",
            "True: [0.0, 0.010882127325500646], Predicted: [-0.007314279675483704, 0.35877108573913574]\n",
            "True: [0.0, 0.006170726776798974], Predicted: [-0.04006465524435043, 0.22181876003742218]\n",
            "True: [0.0, 0.0], Predicted: [-0.04753471165895462, 0.2463730126619339]\n",
            "True: [0.0, 0.0], Predicted: [0.02564554661512375, 0.07165481150150299]\n",
            "True: [0.0, 0.0005423964223346678], Predicted: [0.016585588455200195, -0.11010026931762695]\n",
            "True: [0.832968684479052, 0.0], Predicted: [0.8621593117713928, -0.0502299889922142]\n",
            "True: [2.1114038047805258e-05, 0.25474056724962624], Predicted: [-0.002864733338356018, 0.43965256214141846]\n",
            "True: [1.5568706371708436e-11, 0.06545978418375831], Predicted: [-0.018419992178678513, 0.11760799586772919]\n",
            "True: [0.0, 0.22146041997742527], Predicted: [-0.004675649106502533, 0.13147121667861938]\n",
            "True: [0.0, 0.1840689987505172], Predicted: [-0.0016913414001464844, 0.28297731280326843]\n",
            "True: [0.1970437724296573, 0.9144831494021083], Predicted: [0.3167901039123535, 0.8592756390571594]\n",
            "True: [0.0, 0.0], Predicted: [0.008770033717155457, 0.03845828026533127]\n",
            "True: [0.9230158843440479, 0.9965573564467856], Predicted: [0.8732799291610718, 0.6163952946662903]\n",
            "True: [8.014042275936572e-10, 4.2259277577283427e-07], Predicted: [0.008947782218456268, 0.04084315896034241]\n",
            "True: [0.8943215940877989, 0.07221215822185234], Predicted: [0.6633326411247253, 0.24715487658977509]\n",
            "True: [8.843342539588638e-07, 0.7102975384812179], Predicted: [0.026657909154891968, 0.5424861311912537]\n",
            "True: [0.9470057718750919, 0.8065121502189625], Predicted: [0.7420713305473328, 0.6442552804946899]\n",
            "True: [0.9088446856686554, 0.03931490735809717], Predicted: [0.9477609395980835, 0.3589344620704651]\n",
            "True: [0.9196342609272897, 0.9950500094987139], Predicted: [0.9153497219085693, 0.7714797854423523]\n",
            "True: [2.557894704260794e-10, 0.01617464649910194], Predicted: [-0.004548072814941406, 0.2898954153060913]\n",
            "True: [0.8470476601021638, 0.7299197248108257], Predicted: [0.7837461829185486, 0.29217034578323364]\n",
            "True: [2.6577499650083632e-09, 0.04483601684874561], Predicted: [-0.007785573601722717, 0.0619824156165123]\n",
            "True: [0.0, 0.0003113469670860125], Predicted: [0.007636494934558868, 0.037715308368206024]\n",
            "True: [1.0, 0.9969176640000887], Predicted: [0.9722063541412354, 0.7575315237045288]\n",
            "True: [0.6322808202792254, 0.9337280505585241], Predicted: [0.4985581040382385, 0.9745916724205017]\n",
            "True: [6.839102340385514e-11, 0.0], Predicted: [0.011370867490768433, 0.011247925460338593]\n",
            "True: [0.7808161489720525, 0.8691753052138398], Predicted: [0.8074578642845154, 0.9263013005256653]\n",
            "True: [1.5738556080976766e-15, 7.65384143508463e-07], Predicted: [-4.32431697845459e-05, -0.05700092762708664]\n",
            "True: [7.285546974731237e-07, 0.0], Predicted: [0.018083497881889343, -0.1138605922460556]\n",
            "True: [4.677544983455982e-10, 0.0], Predicted: [-0.001347467303276062, 0.3218967318534851]\n",
            "True: [0.0, 0.7171300285205288], Predicted: [0.00775599479675293, 0.45003730058670044]\n",
            "True: [7.183954367872837e-10, 0.05597423275576463], Predicted: [-0.00020744651556015015, 0.2634735107421875]\n",
            "True: [4.347512207938431e-05, 0.8121677404876149], Predicted: [0.003573000431060791, 0.796091616153717]\n",
            "True: [0.0, 0.005404918980269957], Predicted: [0.007991276681423187, 0.024116478860378265]\n",
            "True: [0.002444301193501627, 0.5635819213649262], Predicted: [0.23389621078968048, 0.6085319519042969]\n",
            "True: [0.9110259881442452, 0.9931103897983421], Predicted: [0.7932595014572144, 0.9840192198753357]\n",
            "True: [0.0016181084829003732, 0.46151525093255463], Predicted: [0.01370643824338913, 0.8464449644088745]\n",
            "True: [2.6425309522472287e-06, 0.0347581878741261], Predicted: [0.004587680101394653, 0.4375927448272705]\n",
            "True: [4.065128279816067e-11, 0.45063962922246426], Predicted: [-0.016272127628326416, 0.2061062455177307]\n",
            "True: [0.2345435383661267, 0.8669474922668108], Predicted: [0.29043442010879517, 0.9048448801040649]\n",
            "True: [0.9651956217903385, 0.02736059212422004], Predicted: [0.8781169056892395, 0.13544858992099762]\n",
            "True: [1.1403786755861632e-10, 0.0023484967205334994], Predicted: [-0.011369392275810242, 0.07605867087841034]\n",
            "True: [0.12277797467698265, 0.00033358045255849067], Predicted: [0.1349801868200302, -0.032372429966926575]\n",
            "True: [0.0, 0.006402552343165335], Predicted: [-0.015880946069955826, 0.13387268781661987]\n",
            "True: [0.0, 0.0013882418706373523], Predicted: [0.07233873009681702, -0.010151185095310211]\n",
            "True: [4.1346826258813295e-05, 0.5187708806677297], Predicted: [0.005606487393379211, 0.49725019931793213]\n",
            "True: [1.0738949416860704e-10, 0.7769799189838241], Predicted: [-0.01339072734117508, 0.8536856174468994]\n",
            "True: [0.0, 0.3573470743272814], Predicted: [-0.0017439201474189758, 0.11435145884752274]\n",
            "True: [2.190486094524266e-09, 0.6881292413190666], Predicted: [-0.009195655584335327, 0.5586539506912231]\n",
            "True: [0.8371657105042054, 0.9825456239259133], Predicted: [0.8814429044723511, 0.7585038542747498]\n",
            "True: [9.55440523378409e-09, 0.0], Predicted: [0.01793457567691803, -0.11165322363376617]\n",
            "True: [0.0, 0.03924730323301484], Predicted: [-0.0032938197255134583, 0.07937127351760864]\n",
            "True: [0.5665149777640033, 0.11093560574986794], Predicted: [0.8399180769920349, 0.5751653909683228]\n",
            "True: [0.8020793829821066, 0.9673382356506715], Predicted: [0.5508051514625549, 1.0034884214401245]\n",
            "True: [0.3260935758970891, 0.8292042311250072], Predicted: [0.4876279830932617, 0.7579578757286072]\n",
            "True: [0.009242887696115552, 0.6607513821360657], Predicted: [0.04245315492153168, 0.8007011413574219]\n",
            "True: [0.8474421421948678, 0.005403620088902605], Predicted: [0.9707591533660889, 0.3423522114753723]\n",
            "True: [0.0, 0.08278155451818658], Predicted: [-0.00522855669260025, 0.14376741647720337]\n",
            "True: [1.1110081837803273e-05, 0.032772185632139905], Predicted: [0.007961474359035492, 0.3438851833343506]\n",
            "True: [1.1862449292267323e-05, 0.50183662272019], Predicted: [0.005343519151210785, 0.7896259427070618]\n",
            "True: [0.0, 3.979095857475912e-06], Predicted: [0.017897799611091614, -0.11414766311645508]\n",
            "True: [0.09378353921943548, 0.0], Predicted: [0.17237453162670135, 0.294871985912323]\n"
          ]
        }
      ]
    }
  ]
}